{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09204ced",
   "metadata": {},
   "source": [
    "### Making wrapper for QM9 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfee9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_36910/2732476931.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.file_address)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train-set, task: homo, source: ./QM9_data/QM9_data.pt, length: 100000\n",
      "MINIBATCH\n",
      "Graph(num_nodes=578, num_edges=10216,\n",
      "      ndata_schemes={'x': Scheme(shape=(3,), dtype=torch.float32), 'f': Scheme(shape=(6, 1), dtype=torch.float32)}\n",
      "      edata_schemes={'d': Scheme(shape=(3,), dtype=torch.float32), 'w': Scheme(shape=(5,), dtype=torch.float32)})\n",
      "torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/dgl/heterograph.py:92: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning(\n",
      "/tmp/ipykernel_36910/2732476931.py:204: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  return batched_graph, torch.tensor(y)\n"
     ]
    }
   ],
   "source": [
    "# QM9 -> dgl\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy.constants import physical_constants\n",
    "\n",
    "hartree2eV = physical_constants['hartree-electron volt relationship'][0]\n",
    "DTYPE = np.float32\n",
    "DTYPE_INT = np.int32\n",
    "\n",
    "class QM9Dataset(Dataset):\n",
    "    \"\"\"QM9 dataset.\"\"\"\n",
    "    num_bonds = 4\n",
    "    atom_feature_size = 6 \n",
    "    input_keys = ['mol_id', 'num_atoms', 'num_bonds', 'x', 'one_hot', \n",
    "                  'atomic_numbers', 'edge']\n",
    "    unit_conversion = {'mu': 1.0,\n",
    "                       'alpha': 1.0,\n",
    "                       'homo': hartree2eV,\n",
    "                       'lumo': hartree2eV,\n",
    "                       'gap': hartree2eV, \n",
    "                       'r2': 1.0, \n",
    "                       'zpve': hartree2eV, \n",
    "                       'u0': hartree2eV, \n",
    "                       'u298': hartree2eV, \n",
    "                       'h298': hartree2eV,\n",
    "                       'g298': hartree2eV,\n",
    "                       'cv': 1.0} \n",
    "\n",
    "    def __init__(self, file_address: str, task: str, mode: str='train', \n",
    "            transform=None, fully_connected: bool=False): \n",
    "        \"\"\"Create a dataset object\n",
    "\n",
    "        Args:\n",
    "            file_address: path to data\n",
    "            task: target task [\"homo\", ...]\n",
    "            mode: [train/val/test] mode\n",
    "            transform: data augmentation functions\n",
    "            fully_connected: return a fully connected graph\n",
    "        \"\"\"\n",
    "        self.file_address = file_address\n",
    "        self.task = task\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.fully_connected = fully_connected\n",
    "\n",
    "        # Encode and extra bond type for fully connected graphs\n",
    "        self.num_bonds += fully_connected\n",
    "\n",
    "        self.load_data()\n",
    "        self.len = len(self.targets)\n",
    "        print(f\"Loaded {mode}-set, task: {task}, source: {self.file_address}, length: {len(self)}\")\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "    def load_data(self):\n",
    "        # Load dict and select train/valid/test split\n",
    "        data = torch.load(self.file_address)\n",
    "        data = data[self.mode]\n",
    "    \n",
    "        # Filter out the inputs\n",
    "        self.inputs = {key: data[key] for key in self.input_keys}\n",
    "\n",
    "        # Filter out the targets and population stats\n",
    "        self.targets = data[self.task]\n",
    "\n",
    "        # TODO: use the training stats unlike the other papers\n",
    "        self.mean = np.mean(self.targets)\n",
    "        self.std = np.std(self.targets)\n",
    "\n",
    "\n",
    "    def get_target(self, idx, normalize=True):\n",
    "        target = self.targets[idx]\n",
    "        if normalize:\n",
    "            target = (target - self.mean) / self.std\n",
    "        return target\n",
    "\n",
    "\n",
    "    def norm2units(self, x, denormalize=True, center=True):\n",
    "        # Convert from normalized to QM9 representation\n",
    "        if denormalize:\n",
    "            x = x * self.std\n",
    "            # Add the mean: not necessary for error computations\n",
    "            if not center:\n",
    "                x += self.mean\n",
    "        x = self.unit_conversion[self.task] * x\n",
    "        return x\n",
    "\n",
    "\n",
    "    def to_one_hot(self, data, num_classes):\n",
    "        one_hot = np.zeros(list(data.shape) + [num_classes])\n",
    "        one_hot[np.arange(len(data)),data] = 1\n",
    "        return one_hot\n",
    "\n",
    "\n",
    "    def _get_adjacency(self, n_atoms):\n",
    "        # Adjust adjacency structure\n",
    "        seq = np.arange(n_atoms)\n",
    "        src = seq[:,None] * np.ones((1,n_atoms), dtype=np.int32)\n",
    "        dst = src.T\n",
    "        ## Remove diagonals and reshape\n",
    "        src[seq, seq] = -1\n",
    "        dst[seq, seq] = -1\n",
    "        src, dst = src.reshape(-1), dst.reshape(-1)\n",
    "        src, dst = src[src > -1], dst[dst > -1]\n",
    "            \n",
    "        return src, dst\n",
    "\n",
    "\n",
    "    def get(self, key, idx):\n",
    "        return self.inputs[key][idx]\n",
    "\n",
    "\n",
    "    def connect_fully(self, edges, num_atoms):\n",
    "        \"\"\"Convert to a fully connected graph\"\"\"\n",
    "        # Initialize all edges: no self-edges\n",
    "        adjacency = {}\n",
    "        for i in range(num_atoms):\n",
    "            for j in range(num_atoms):\n",
    "                if i != j:\n",
    "                    # assigning new type of connection if originally not connected\n",
    "                    adjacency[(i, j)] = self.num_bonds - 1 \n",
    "\n",
    "        # Add bonded edges\n",
    "        for idx in range(edges.shape[0]):\n",
    "            adjacency[(edges[idx,0], edges[idx,1])] = edges[idx,2]\n",
    "            adjacency[(edges[idx,1], edges[idx,0])] = edges[idx,2]\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        src = []\n",
    "        dst = []\n",
    "        w = []\n",
    "        for edge, weight in adjacency.items():\n",
    "            src.append(edge[0])\n",
    "            dst.append(edge[1])\n",
    "            w.append(weight)\n",
    "\n",
    "        return np.array(src), np.array(dst), np.array(w)\n",
    "\n",
    "\n",
    "    def connect_partially(self, edge):\n",
    "        src = np.concatenate([edge[:,0], edge[:,1]])\n",
    "        dst = np.concatenate([edge[:,1], edge[:,0]])\n",
    "        w = np.concatenate([edge[:,2], edge[:,2]])\n",
    "        return src, dst, w\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load node features\n",
    "        num_atoms = self.get('num_atoms', idx) # number of atoms\n",
    "        x = self.get('x', idx)[:num_atoms].astype(DTYPE) # coordinates of atoms\n",
    "        one_hot = self.get('one_hot', idx)[:num_atoms].astype(DTYPE)\n",
    "        atomic_numbers = self.get('atomic_numbers', idx)[:num_atoms].astype(DTYPE)\n",
    "\n",
    "        # Load edge features\n",
    "        num_bonds = self.get('num_bonds', idx)\n",
    "        edge = self.get('edge', idx)[:num_bonds]\n",
    "        edge = np.asarray(edge, dtype=DTYPE_INT)\n",
    "\n",
    "        # Load target\n",
    "        y = self.get_target(idx, normalize=True).astype(DTYPE)\n",
    "        y = np.array([y])\n",
    "\n",
    "        # Augmentation on the coordinates\n",
    "        if self.transform:\n",
    "            x = self.transform(x).astype(DTYPE)\n",
    "\n",
    "        # Create nodes\n",
    "        if self.fully_connected:\n",
    "            src, dst, w = self.connect_fully(edge, num_atoms)\n",
    "        else:\n",
    "            src, dst, w = self.connect_partially(edge)\n",
    "        w = self.to_one_hot(w, self.num_bonds).astype(DTYPE)\n",
    "\n",
    "        # Create graph\n",
    "        G = dgl.DGLGraph((src, dst))\n",
    "\n",
    "        # Add node features to graph\n",
    "        G.ndata['x'] = torch.tensor(x) #[num_atoms,3]\n",
    "        G.ndata['f'] = torch.tensor(np.concatenate([one_hot, atomic_numbers], -1)[...,None]) #[num_atoms,6,1]\n",
    "\n",
    "        # Add edge features to graph\n",
    "        G.edata['d'] = torch.tensor(x[dst] - x[src]) #[num_atoms,3]\n",
    "        G.edata['w'] = torch.tensor(w) #[num_atoms,4]\n",
    "\n",
    "        return G, y\n",
    "\n",
    "\n",
    "\n",
    "def collate(samples):\n",
    "    graphs, y = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.tensor(y)\n",
    "\n",
    "dataset = QM9Dataset('./QM9_data/QM9_data.pt', \"homo\", mode='train', fully_connected=True)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "\n",
    "iter_dataloader = iter(dataloader) # so I can use next\n",
    "for i in range(1):\n",
    "    data = next(iter_dataloader)\n",
    "    print(\"MINIBATCH\")\n",
    "    print(data[0]) \n",
    "    print(data[1].shape) # batch size -> connected graph of size batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b05cb2-a9dc-4b11-bdd5-671ec059e063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38a1438-fd3c-4b5f-9980-54b1fa451dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa590534-6c05-4802-a2a5-1aa984e5aac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0537c631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9]),\n",
       " array([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 3, 4,\n",
       "        5, 6, 7, 8, 9, 0, 1, 2, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 5, 6, 7, 8,\n",
       "        9, 0, 1, 2, 3, 4, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 7, 8, 9, 0, 1, 2,\n",
       "        3, 4, 5, 6, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 9, 0, 1, 2, 3, 4, 5, 6,\n",
       "        7, 8]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_adjacency(n_atoms):\n",
    "    # Adjust adjacency structure\n",
    "    seq = np.arange(n_atoms)\n",
    "    src = seq[:,None] * np.ones((1,n_atoms), dtype=np.int32)\n",
    "    dst = src.T\n",
    "    ## Remove diagonals and reshape\n",
    "    src[seq, seq] = -1\n",
    "    dst[seq, seq] = -1\n",
    "    src, dst = src.reshape(-1), dst.reshape(-1)\n",
    "    src, dst = src[src > -1], dst[dst > -1]\n",
    "\n",
    "    return src, dst\n",
    "\n",
    "_get_adjacency(10) # from src to dst fully connected in this case, no self connections\n",
    "\n",
    "# all the connections are represented in the form\n",
    "# src[0]   src[1]   ...\n",
    "# dst[0]   dst[1]   ...\n",
    "# w[0]     w[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa0e36a",
   "metadata": {},
   "source": [
    "### DGL example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74c45e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2392,  1.4881,  0.2661],\n",
      "        [ 1.4275,  0.2036,  0.4451],\n",
      "        [ 0.0255,  0.4926,  1.0069],\n",
      "        ...,\n",
      "        [-3.6696, -2.1889,  1.4669],\n",
      "        [-1.9926, -0.5895,  2.1120],\n",
      "        [-2.6884,  0.5919,  0.9935]])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
      "torch.Size([10216, 3])\n",
      "tensor([[[0.0659, 0.3030, 0.0830, 0.8960],\n",
      "         [0.3863, 0.3936, 0.8248, 0.2080],\n",
      "         [0.7071, 0.7043, 0.1502, 0.6449]],\n",
      "\n",
      "        [[0.2645, 0.0623, 0.9719, 0.9570],\n",
      "         [0.0563, 0.4997, 0.2362, 0.1928],\n",
      "         [0.7543, 0.1337, 0.2231, 0.4120]],\n",
      "\n",
      "        [[0.1998, 0.9555, 0.1817, 0.8563],\n",
      "         [0.5072, 0.1255, 0.4433, 0.7703],\n",
      "         [0.2985, 0.0438, 0.2162, 0.8691]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0809, 0.1698, 0.4604, 0.2824],\n",
      "         [0.8588, 0.7872, 0.5493, 0.8961],\n",
      "         [0.6366, 0.1307, 0.8874, 0.5576]],\n",
      "\n",
      "        [[0.7255, 0.5195, 0.6014, 0.8832],\n",
      "         [0.9675, 0.5408, 0.1442, 0.8980],\n",
      "         [0.4008, 0.4067, 0.1021, 0.0420]],\n",
      "\n",
      "        [[0.2691, 0.9785, 0.9441, 0.5939],\n",
      "         [0.2173, 0.5376, 0.5907, 0.8005],\n",
      "         [0.9845, 0.7052, 0.0861, 0.0555]]], dtype=torch.float64)\n",
      "torch.Size([10216, 1])\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "\n",
    "\n",
    "dataset = data\n",
    "\n",
    "\n",
    "\n",
    "# initialize dgl graph\n",
    "G = dataset[0]\n",
    "\n",
    "ntype = 'x'\n",
    "# ndata is a dict\n",
    "# retrieve data from all nodes labels ntype (position example)\n",
    "print(G.ndata[ntype]) \n",
    "\n",
    "d = 5\n",
    "G.ndata[f'out{d}'] = torch.tensor(np.zeros((len(G.ndata['x']), 5)))\n",
    "# retrieve output features of type d from node data\n",
    "print(G.ndata[f'out{d}']) \n",
    "\n",
    "\n",
    "etype = 'd'\n",
    "# retrive data from all edges labeled etype\n",
    "print(G.edata[etype].shape)\n",
    "\n",
    "di = 'd'\n",
    "do = 'w'\n",
    "G.edata[f'({di},{do})'] = torch.tensor(np.random.rand(G.edata[etype].shape[0], 3, 4))\n",
    "# retrive edge kernels that transform from type di to type di\n",
    "print(G.edata[f'({di},{do})'])\n",
    "\n",
    "e = 'd' # edge feature (distance)\n",
    "v = 'x' # node features (cartesian vector)\n",
    "m = 'm' # output message on the edge\n",
    "# calling built in dgl fubction e_dot_v that computes a message on\n",
    "# edge by performing element-wise dot between features of e and v\n",
    "# and stores it as edge message labeled 'm'\n",
    "f = fn.e_dot_v(e, v, m)\n",
    "\n",
    "# applies the function f to update the features of the edges with function\n",
    "G.apply_edges(f)\n",
    "\n",
    "print(G.edata['m'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfed102",
   "metadata": {},
   "source": [
    "### Fibers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "871dcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.utils_profiling import * # load before other local modules\n",
    "try:\n",
    "    profile\n",
    "except NameError:\n",
    "    def profile(func):\n",
    "        return func\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "class Fiber(object):\n",
    "    \"\"\"A Handy Data Structure for Fibers\"\"\"\n",
    "    def __init__(self, num_degrees: int=None, num_channels: int=None,\n",
    "                 structure: List[Tuple[int,int]]=None, dictionary=None):\n",
    "        \"\"\"\n",
    "        define fiber structure; use one num_degrees & num_channels OR structure\n",
    "        OR dictionary\n",
    "\n",
    "        :param num_degrees: degrees will be [0, ..., num_degrees-1]\n",
    "        :param num_channels: number of channels, same for each degree\n",
    "        :param structure: e.g. [(32, 0),(16, 1),(16,2)]\n",
    "        :param dictionary: e.g. {0:32, 1:16, 2:16}\n",
    "        \n",
    "        Structure in the form: List[(Tuple[int, int])]. In particular Features[(num_channels, feature_degree)]\n",
    "        \"\"\"\n",
    "        \n",
    "        if structure:\n",
    "            self.structure = structure\n",
    "        elif dictionary:\n",
    "            self.structure = [(dictionary[o], o) for o in sorted(dictionary.keys())]\n",
    "        else:\n",
    "            self.structure = [(num_channels, i) for i in range(num_degrees)]\n",
    "\n",
    "            \n",
    "        # assigning to dict format and computing cummulative variables\n",
    "        self.multiplicities, self.degrees = zip(*self.structure)\n",
    "        self.max_degree = max(self.degrees)\n",
    "        self.min_degree = min(self.degrees)\n",
    "        self.structure_dict = {k: v for v, k in self.structure}\n",
    "        self.dict = self.structure_dict\n",
    "        self.n_features = np.sum([i[0] * (2*i[1]+1) for i in self.structure])\n",
    "\n",
    "        \n",
    "        # Mapping to vec() case. f = [...] with starting ind saved in feature ind dict\n",
    "        # feature_ind = {degree: starting ind}\n",
    "        self.feature_indices = {}\n",
    "        idx = 0\n",
    "        for (num_channels, d) in self.structure:\n",
    "            length = num_channels * (2*d + 1)\n",
    "            self.feature_indices[d] = (idx, idx + length)\n",
    "            idx += length\n",
    "\n",
    "    def copy_me(self, multiplicity: int=None):\n",
    "        s = copy.deepcopy(self.structure)\n",
    "        if multiplicity is not None:\n",
    "            # overwrite multiplicities\n",
    "            s = [(multiplicity, o) for m, o in s]\n",
    "        return Fiber(structure=s)\n",
    "\n",
    "    @staticmethod\n",
    "    def combine(f1, f2):\n",
    "        new_dict = copy.deepcopy(f1.structure_dict)\n",
    "        for k, m in f2.structure_dict.items():\n",
    "            if k in new_dict.keys():\n",
    "                new_dict[k] += m\n",
    "            else:\n",
    "                new_dict[k] = m\n",
    "        structure = [(new_dict[k], k) for k in sorted(new_dict.keys())]\n",
    "        return Fiber(structure=structure)\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_max(f1, f2):\n",
    "        new_dict = copy.deepcopy(f1.structure_dict)\n",
    "        for k, m in f2.structure_dict.items():\n",
    "            if k in new_dict.keys():\n",
    "                new_dict[k] = max(m, new_dict[k])\n",
    "            else:\n",
    "                new_dict[k] = m\n",
    "        structure = [(new_dict[k], k) for k in sorted(new_dict.keys())]\n",
    "        return Fiber(structure=structure)\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_selectively(f1, f2):\n",
    "        # only use orders which occur in fiber f1\n",
    "\n",
    "        new_dict = copy.deepcopy(f1.structure_dict)\n",
    "        for k in f1.degrees:\n",
    "            if k in f2.degrees:\n",
    "                new_dict[k] += f2.structure_dict[k]\n",
    "        structure = [(new_dict[k], k) for k in sorted(new_dict.keys())]\n",
    "        return Fiber(structure=structure)\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_fibers(val1, struc1, val2, struc2):\n",
    "        \"\"\"\n",
    "        combine two fibers\n",
    "\n",
    "        :param val1/2: fiber tensors in dictionary form\n",
    "        :param struc1/2: structure of fiber\n",
    "        :return: fiber tensor in dictionary form\n",
    "        \"\"\"\n",
    "        struc_out = Fiber.combine(struc1, struc2)\n",
    "        val_out = {}\n",
    "        for k in struc_out.degrees:\n",
    "            if k in struc1.degrees:\n",
    "                if k in struc2.degrees:\n",
    "                    val_out[k] = torch.cat([val1[k], val2[k]], -2)\n",
    "                else:\n",
    "                    val_out[k] = val1[k]\n",
    "            else:\n",
    "                val_out[k] = val2[k]\n",
    "                \n",
    "            # number of channels is the second dimenstion from the end I guess\n",
    "            # might look like [tensor_axis = degree, channel axis, tensor-component axis]\n",
    "            assert val_out[k].shape[-2] == struc_out.structure_dict[k]\n",
    "        return val_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.structure}\"\n",
    "\n",
    "\n",
    "\n",
    "def get_fiber_dict(F, struc, mask=None, return_struc=False):\n",
    "    if mask is None: mask = struc\n",
    "    index = 0\n",
    "    fiber_dict = {}\n",
    "    first_dims = F.shape[:-1]\n",
    "    masked_dict = {}\n",
    "    for o, m in struc.structure_dict.items():\n",
    "        length = m * (2*o + 1)\n",
    "        if o in mask.degrees:\n",
    "            masked_dict[o] = m\n",
    "            fiber_dict[o] = F[...,index:index + length].view(list(first_dims) + [m, 2*o + 1])\n",
    "        index += length\n",
    "    assert F.shape[-1] == index\n",
    "    if return_struc:\n",
    "        return fiber_dict, Fiber(dictionary=masked_dict)\n",
    "    return fiber_dict\n",
    "\n",
    "\n",
    "def get_fiber_tensor(F, struc):\n",
    "    some_entry = tuple(F.values())[0]\n",
    "    first_dims = some_entry.shape[:-2]\n",
    "    res = some_entry.new_empty([*first_dims, struc.n_features])\n",
    "    index = 0\n",
    "    for o, m in struc.structure_dict.items():\n",
    "        length = m * (2*o + 1)\n",
    "        res[..., index: index + length] = F[o].view(*first_dims, length)\n",
    "        index += length\n",
    "    assert index == res.shape[-1]\n",
    "    return res\n",
    "\n",
    "\n",
    "def fiber2tensor(F, structure, squeeze=False):\n",
    "    if squeeze:\n",
    "        fibers = [F[f'{i}'].view(*F[f'{i}'].shape[:-2], -1) for i in structure.degrees]\n",
    "        fibers = torch.cat(fibers, -1)\n",
    "    else:\n",
    "        fibers = [F[f'{i}'].view(*F[f'{i}'].shape[:-2], -1, 1) for i in structure.degrees]\n",
    "        fibers = torch.cat(fibers, -2)\n",
    "    return fibers\n",
    "\n",
    "\n",
    "# Reduce fibers into single tensor cell h (I guess)\n",
    "def fiber2head(F, h, structure, squeeze=False):\n",
    "    if squeeze:\n",
    "        fibers = [F[f'{i}'].view(*F[f'{i}'].shape[:-2], h, -1) for i in structure.degrees]\n",
    "        fibers = torch.cat(fibers, -1)\n",
    "    else:\n",
    "        fibers = [F[f'{i}'].view(*F[f'{i}'].shape[:-2], h, -1, 1) for i in structure.degrees]\n",
    "        fibers = torch.cat(fibers, -2)\n",
    "    return fibers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15238cd4",
   "metadata": {},
   "source": [
    "### Basis transformation matrixes and irreducable representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e44a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cache in files\n",
    "'''\n",
    "from functools import wraps, lru_cache\n",
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import fcntl\n",
    "\n",
    "\n",
    "class FileSystemMutex:\n",
    "    '''\n",
    "    Mutual exclusion of different **processes** using the file system\n",
    "    '''\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.handle = None\n",
    "        self.filename = filename\n",
    "\n",
    "    def acquire(self):\n",
    "        '''\n",
    "        Locks the mutex\n",
    "        if it is already locked, it waits (blocking function)\n",
    "        '''\n",
    "        self.handle = open(self.filename, 'w')\n",
    "        fcntl.lockf(self.handle, fcntl.LOCK_EX)\n",
    "        self.handle.write(\"{}\\n\".format(os.getpid()))\n",
    "        self.handle.flush()\n",
    "\n",
    "    def release(self):\n",
    "        '''\n",
    "        Unlock the mutex\n",
    "        '''\n",
    "        if self.handle is None:\n",
    "            raise RuntimeError()\n",
    "        fcntl.lockf(self.handle, fcntl.LOCK_UN)\n",
    "        self.handle.close()\n",
    "        self.handle = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.acquire()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.release()\n",
    "\n",
    "\n",
    "def cached_dirpklgz(dirname, maxsize=128):\n",
    "    '''\n",
    "    Cache a function with a directory\n",
    "\n",
    "    :param dirname: the directory path\n",
    "    :param maxsize: maximum size of the RAM cache (there is no limit for the directory cache)\n",
    "    '''\n",
    "\n",
    "    def decorator(func):\n",
    "        '''\n",
    "        The actual decorator\n",
    "        '''\n",
    "\n",
    "        @lru_cache(maxsize=maxsize)\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            '''\n",
    "            The wrapper of the function\n",
    "            '''\n",
    "            try:\n",
    "                os.makedirs(dirname)\n",
    "            except FileExistsError:\n",
    "                pass\n",
    "\n",
    "            indexfile = os.path.join(dirname, \"index.pkl\")\n",
    "            mutexfile = os.path.join(dirname, \"mutex\")\n",
    "\n",
    "            with FileSystemMutex(mutexfile):\n",
    "                try:\n",
    "                    with open(indexfile, \"rb\") as file:\n",
    "                        index = pickle.load(file)\n",
    "                except FileNotFoundError:\n",
    "                    index = {}\n",
    "\n",
    "                key = (args, frozenset(kwargs), func.__defaults__)\n",
    "\n",
    "                try:\n",
    "                    filename = index[key]\n",
    "                except KeyError:\n",
    "                    index[key] = filename = \"{}.pkl.gz\".format(len(index))\n",
    "                    with open(indexfile, \"wb\") as file:\n",
    "                        pickle.dump(index, file)\n",
    "\n",
    "            filepath = os.path.join(dirname, filename)\n",
    "\n",
    "            try:\n",
    "                with FileSystemMutex(mutexfile):\n",
    "                    with gzip.open(filepath, \"rb\") as file:\n",
    "                        result = pickle.load(file)\n",
    "            except FileNotFoundError:\n",
    "                print(\"compute {}... \".format(filename), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "                result = func(*args, **kwargs)\n",
    "                print(\"save {}... \".format(filename), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "                with FileSystemMutex(mutexfile):\n",
    "                    with gzip.open(filepath, \"wb\") as file:\n",
    "                        pickle.dump(result, file)\n",
    "                print(\"done\")\n",
    "            return result\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bec4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class torch_default_dtype:\n",
    "\n",
    "    def __init__(self, dtype):\n",
    "        self.saved_dtype = None\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.saved_dtype = torch.get_default_dtype()\n",
    "        torch.set_default_dtype(self.dtype)\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        torch.set_default_dtype(self.saved_dtype)\n",
    "        \n",
    "\n",
    "\n",
    "def irr_repr(order, alpha, beta, gamma, dtype=None):\n",
    "    \"\"\"\n",
    "    irreducible representation of SO3\n",
    "    - compatible with compose and spherical_harmonics\n",
    "    \"\"\"\n",
    "    # from from_lielearn_SO3.wigner_d import wigner_D_matrix\n",
    "    from lie_learn.representations.SO3.wigner_d import wigner_D_matrix\n",
    "    # if order == 1:\n",
    "    #     # change of basis to have vector_field[x, y, z] = [vx, vy, vz]\n",
    "    #     A = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])\n",
    "    #     return A @ wigner_D_matrix(1, alpha, beta, gamma) @ A.T\n",
    "\n",
    "    # TODO (non-essential): try to do everything in torch\n",
    "    # return torch.tensor(wigner_D_matrix(torch.tensor(order), alpha, beta, gamma), dtype=torch.get_default_dtype() if dtype is None else dtype)\n",
    "    return torch.tensor(wigner_D_matrix(order, np.array(alpha), np.array(beta), np.array(gamma)), dtype=torch.get_default_dtype() if dtype is None else dtype)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a9e14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4093, -0.1068, -0.9061],\n",
       "        [ 0.1283, -0.9900,  0.0587],\n",
       "        [-0.9033, -0.0922,  0.4189]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### example for irrep\n",
    "# Weigner_D matrix\n",
    "irr_repr(1, 4., 3., 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7202349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# @profile\n",
    "def kron(a, b):\n",
    "    \"\"\"\n",
    "    A part of the pylabyk library: numpytorch.py at https://github.com/yulkang/pylabyk\n",
    "\n",
    "    Kronecker product of matrices a and b with leading batch dimensions.\n",
    "    Batch dimensions are broadcast. The number of them mush\n",
    "    :type a: torch.Tensor\n",
    "    :type b: torch.Tensor\n",
    "    :rtype: torch.Tensor\n",
    "    \"\"\"\n",
    "    siz1 = torch.Size(torch.tensor(a.shape[-2:]) * torch.tensor(b.shape[-2:]))\n",
    "    res = a.unsqueeze(-1).unsqueeze(-3) * b.unsqueeze(-2).unsqueeze(-4)\n",
    "    siz0 = res.shape[:-4]\n",
    "    return res.reshape(siz0 + siz1)\n",
    "\n",
    "################################################################################\n",
    "# Solving the constraint coming from the stabilizer of 0 and e\n",
    "################################################################################\n",
    "\n",
    "# Get's eigenvectors for eigvalue equel close by eps to zero\n",
    "def get_matrix_kernel(A, eps=1e-10):\n",
    "    '''\n",
    "    Compute an orthonormal basis of the kernel (x_1, x_2, ...)\n",
    "    A x_i = 0\n",
    "    scalar_product(x_i, x_j) = delta_ij\n",
    "\n",
    "    :param A: matrix\n",
    "    :return: matrix where each row is a basis vector of the kernel of A\n",
    "    '''\n",
    "    _u, s, v = torch.svd(A)\n",
    "\n",
    "    # A = u @ torch.diag(s) @ v.t()\n",
    "    kernel = v.t()[s < eps]\n",
    "    return kernel\n",
    "\n",
    "\n",
    "# Stacks the matrix to big matrix and does the same as previous function\n",
    "def get_matrices_kernel(As, eps=1e-10):\n",
    "    '''\n",
    "    Computes the commun kernel of all the As matrices\n",
    "    '''\n",
    "    return get_matrix_kernel(torch.cat(As, dim=0), eps)\n",
    "\n",
    "\n",
    "@cached_dirpklgz(\"cache/trans_Q\")\n",
    "def _basis_transformation_Q_J(J, order_in, order_out, version=3):  # pylint: disable=W0613\n",
    "    \"\"\"\n",
    "    :param J: order of the spherical harmonics\n",
    "    :param order_in: order of the input representation\n",
    "    :param order_out: order of the output representation\n",
    "    :return: one part of the Q^-1 matrix of the article\n",
    "    \"\"\"\n",
    "    with torch_default_dtype(torch.float64):\n",
    "        def _R_tensor(a, b, c): return kron(irr_repr(order_out, a, b, c), irr_repr(order_in, a, b, c))\n",
    "\n",
    "        def _sylvester_submatrix(J, a, b, c):\n",
    "            ''' generate Kronecker product matrix for solving the Sylvester equation in subspace J '''\n",
    "            R_tensor = _R_tensor(a, b, c)  # [m_out * m_in, m_out * m_in]\n",
    "            R_irrep_J = irr_repr(J, a, b, c)  # [m, m]\n",
    "            return kron(R_tensor, torch.eye(R_irrep_J.size(0))) - \\\n",
    "                kron(torch.eye(R_tensor.size(0)), R_irrep_J.t())  # [(m_out * m_in) * m, (m_out * m_in) * m]\n",
    "        \n",
    "        # some random angles to enshure equivariance\n",
    "        random_angles = [\n",
    "            [4.41301023, 5.56684102, 4.59384642],\n",
    "            [4.93325116, 6.12697327, 4.14574096],\n",
    "            [0.53878964, 4.09050444, 5.36539036],\n",
    "            [2.16017393, 3.48835314, 5.55174441],\n",
    "            [2.52385107, 0.2908958, 3.90040975]\n",
    "        ]\n",
    "        null_space = get_matrices_kernel([_sylvester_submatrix(J, a, b, c) for a, b, c in random_angles])\n",
    "        assert null_space.size(0) == 1, null_space.size()  # unique subspace solution\n",
    "        Q_J = null_space[0]  # [(m_out * m_in) * m]\n",
    "        Q_J = Q_J.view((2 * order_out + 1) * (2 * order_in + 1), 2 * J + 1)  # [m_out * m_in, m]\n",
    "        assert all(torch.allclose(_R_tensor(a, b, c) @ Q_J, Q_J @ irr_repr(J, a, b, c)) for a, b, c in torch.rand(4, 3))\n",
    "\n",
    "    assert Q_J.dtype == torch.float64\n",
    "    return Q_J  # [m_out * m_in, m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0954874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " _basis_transformation_Q_J(1, 1, 1, version=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf9e9a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l tensor shape torch.Size([3, 3])\n",
      "k tensor shape torch.Size([5, 5])\n",
      "Kron shape torch.Size([15, 15])\n"
     ]
    }
   ],
   "source": [
    "# some code deconstruction of Q^lk_j^{-1}\n",
    "# helper function that calculates the Kronecker product between\n",
    "# type-k and type-l Wigner-D matrices for rotations a, b, c\n",
    "def _R_tensor(a, b, c):\n",
    "    # kron calculates the kroneker product between two matrices\n",
    "    # irr_repr returns the irrep from (type, alpha, beta, gamma)\n",
    "    # Remember the order A x B = kron(B, A)\n",
    "    return kron(irr_repr(l, a, b, c), irr_repr(k, a, b, c))\n",
    "\n",
    "l = 1\n",
    "k = 2\n",
    "a = 4.; b = 3.; c = 2.;\n",
    "\n",
    "print(\"l tensor shape\", irr_repr(l, a, b, c).shape)\n",
    "print(\"k tensor shape\", irr_repr(k, a, b, c).shape)\n",
    "print(\"Kron shape\", _R_tensor(a, b, c).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09be0911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105, 105])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computes submatrix to solve sylvester equation\n",
    "# AX - XB = 0\n",
    "# same as (I x A - B^T x I) vec(X) = 0\n",
    "def _sylvester_submatrix(J, a, b, c):\n",
    "    # Calculates the Kroneker product between type-l and type-k\n",
    "    # Wigner-D matrices for rotation angles a, b, c\n",
    "    R_tensor = _R_tensor(a, b, c) # [(2l + 1)*(2k + 1), (2l + 1)*(2k + 1)]\n",
    "    # Calculates type-J Wigner-D matrix for same rotation\n",
    "    R_irrep_J = irr_repr(J, a, b, c) # [2J + 1, 2J + 1]\n",
    "    # .reshape(9).reshape(3, 3) Annoying stuff due to some torch bug with data placement in memory\n",
    "    return kron(R_tensor, torch.eye(R_irrep_J.size(0))) - kron(torch.eye(R_tensor.size(0)), R_irrep_J.t())\n",
    "\n",
    "J = 3\n",
    "\n",
    "_sylvester_submatrix(J, a, b, c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff9c828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on random angles\n",
    "with torch_default_dtype(torch.float64): # !!! Important otherwise zero\n",
    "    # some random angles to enshure equivariance\n",
    "    random_angles = [\n",
    "        [4.41301023, 5.56684102, 4.59384642],\n",
    "        [4.93325116, 6.12697327, 4.14574096],\n",
    "        [0.53878964, 4.09050444, 5.36539036],\n",
    "        [2.16017393, 3.48835314, 5.55174441],\n",
    "        [2.52385107, 0.2908958, 3.90040975]\n",
    "    ]\n",
    "    # Calculate the vector that is solution of the homogeneous equation\n",
    "    # for all sets of angles\n",
    "    null_space = get_matrices_kernel([_sylvester_submatrix(J, a, b, c)\n",
    "                                      for a, b, c in random_angles])\n",
    "    # confirm that the solution is unique\n",
    "    assert null_space.size(0) == 1, null_space.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "522936ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Q^lk_J compute and reshape to (2 * l + 1) * (2 * k + 1) * (2 * J + 1)\n",
    "with torch_default_dtype(torch.float64): # !!! Important otherwise zero\n",
    "    Q_J = null_space[0] # only one vector\n",
    "    Q_J = Q_J.view((2 * l + 1) * (2 * k + 1), 2 * J + 1) # unvectorize\n",
    "    assert all(torch.allclose(_R_tensor(a, b, c) @ Q_J, Q_J @ irr_repr(J, a, b, c)) \n",
    "               for a, b, c in torch.rand(4, 3)) # sanity check that is a solution\n",
    "    \n",
    "Q_J.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b728c8ab",
   "metadata": {},
   "source": [
    "### Spherical harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5891367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import lpmv as lpmv_scipy\n",
    "\n",
    "\n",
    "def semifactorial(x):\n",
    "    \"\"\"Compute the semifactorial function x!!.\n",
    "\n",
    "    x!! = x * (x-2) * (x-4) *...\n",
    "\n",
    "    Args:\n",
    "        x: positive int\n",
    "    Returns:\n",
    "        float for x!!\n",
    "    \"\"\"\n",
    "    y = 1.\n",
    "    for n in range(x, 1, -2):\n",
    "        y *= n\n",
    "    return y\n",
    "\n",
    "\n",
    "def pochhammer(x, k):\n",
    "    \"\"\"Compute the pochhammer symbol (x)_k.\n",
    "\n",
    "    (x)_k = x * (x+1) * (x+2) *...* (x+k-1)\n",
    "\n",
    "    Args:\n",
    "        x: positive int\n",
    "    Returns:\n",
    "        float for (x)_k\n",
    "    \"\"\"\n",
    "    xf = float(x)\n",
    "    for n in range(x+1, x+k):\n",
    "        xf *= n\n",
    "    return xf\n",
    "\n",
    "def lpmv(l, m, x):\n",
    "    \"\"\"Associated Legendre function including Condon-Shortley phase.\n",
    "\n",
    "    Args:\n",
    "        m: int order \n",
    "        l: int degree\n",
    "        x: float argument tensor\n",
    "    Returns:\n",
    "        tensor of x-shape\n",
    "    \"\"\"\n",
    "    m_abs = abs(m)\n",
    "    \n",
    "    # P^m_J = 0 forall m > J\n",
    "    if m_abs > l:\n",
    "        return torch.zeros_like(x)\n",
    "\n",
    "    # Compute P_m^m\n",
    "    # P_m^m = (-1)^J (1 - x^2)^(J/2) (2J - 1)!!\n",
    "    yold = ((-1)**m_abs * semifactorial(2*m_abs-1)) * torch.pow(1-x*x, m_abs/2)\n",
    "    \n",
    "    # Compute P_{m+1}^m\n",
    "    # P_m+1^m = x (2 m + 1) P^m_m\n",
    "    if m_abs != l:\n",
    "        y = x * (2*m_abs+1) * yold\n",
    "    else:\n",
    "        y = yold\n",
    "\n",
    "    # Compute P_{l}^m from recursion in P_{l-1}^m and P_{l-2}^m\n",
    "    # P_l^m (x) = [(2 l - 1 ) / ( l - m )] P^m_{l - 1} (x) - [(l + m - 1) / (l - m)] P^m_{l - 2} (x)\n",
    "    for i in range(m_abs+2, l+1):\n",
    "        tmp = y\n",
    "        # Inplace speedup\n",
    "        y = ((2*i-1) / (i-m_abs)) * x * y\n",
    "        y -= ((i+m_abs-1)/(i-m_abs)) * yold\n",
    "        yold = tmp\n",
    "\n",
    "    # P^-m_l (x) = (-1)^m (l - m)!/(l + m)! P^m_l (x)\n",
    "    if m < 0:\n",
    "        y *= ((-1)**m / pochhammer(l+m+1, -2*m))\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23fc766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg = {}\n",
    "J = 10\n",
    "m = 5\n",
    "x = torch.Tensor([0.5, 0.1, 0.2])\n",
    "ans_1 = lpmv(J, m, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73b4b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphericalHarmonics(object):\n",
    "    def __init__(self):\n",
    "        self.leg = {}\n",
    "\n",
    "    def clear(self):\n",
    "        self.leg = {}\n",
    "\n",
    "    def negative_lpmv(self, l, m, y):\n",
    "        \"\"\"Compute negative order coefficients\"\"\"\n",
    "        if m < 0:\n",
    "            y *= ((-1)**m / pochhammer(l+m+1, -2*m))\n",
    "        return y\n",
    "\n",
    "    def lpmv(self, l, m, x):\n",
    "        \"\"\"Associated Legendre function including Condon-Shortley phase.\n",
    "\n",
    "        Args:\n",
    "            m: int order \n",
    "            l: int degree\n",
    "            x: float argument tensor\n",
    "        Returns:\n",
    "            tensor of x-shape\n",
    "        \"\"\"\n",
    "        # Check memoized versions\n",
    "        m_abs = abs(m)\n",
    "        if (l,m) in self.leg:\n",
    "            return self.leg[(l,m)]\n",
    "        elif m_abs > l:\n",
    "            return None\n",
    "        elif l == 0:\n",
    "            self.leg[(l,m)] = torch.ones_like(x)\n",
    "            return self.leg[(l,m)]\n",
    "        \n",
    "        # Check if on boundary else recurse solution down to boundary\n",
    "        if m_abs == l:\n",
    "            # Compute P_m^m\n",
    "            y = (-1)**m_abs * semifactorial(2*m_abs-1)\n",
    "            y *= torch.pow(1-x*x, m_abs/2)\n",
    "            self.leg[(l,m)] = self.negative_lpmv(l, m, y)\n",
    "            return self.leg[(l,m)]\n",
    "        else:\n",
    "            # Recursively precompute lower degree harmonics\n",
    "            self.lpmv(l-1, m, x)\n",
    "\n",
    "        # Compute P_{l}^m from recursion in P_{l-1}^m and P_{l-2}^m\n",
    "        # Inplace speedup\n",
    "        y = ((2*l-1) / (l-m_abs)) * x * self.lpmv(l-1, m_abs, x)\n",
    "        if l - m_abs > 1:\n",
    "            y -= ((l+m_abs-1)/(l-m_abs)) * self.leg[(l-2, m_abs)]\n",
    "        #self.leg[(l, m_abs)] = y\n",
    "        \n",
    "        if m < 0:\n",
    "            y = self.negative_lpmv(l, m, y)\n",
    "        self.leg[(l,m)] = y\n",
    "\n",
    "        return self.leg[(l,m)]\n",
    "\n",
    "    def get_element(self, l, m, theta, phi):\n",
    "        \"\"\"Tesseral spherical harmonic with Condon-Shortley phase.\n",
    "\n",
    "        The Tesseral spherical harmonics are also known as the real spherical\n",
    "        harmonics.\n",
    "\n",
    "        Args:\n",
    "            l: int for degree\n",
    "            m: int for order, where -l <= m < l\n",
    "            theta: collatitude or polar angle\n",
    "            phi: longitude or azimuth\n",
    "        Returns:\n",
    "            tensor of shape theta\n",
    "        \"\"\"\n",
    "        assert abs(m) <= l, \"absolute value of order m must be <= degree l\"\n",
    "\n",
    "        N = np.sqrt((2*l+1) / (4*np.pi))\n",
    "        leg = self.lpmv(l, abs(m), torch.cos(theta))\n",
    "        if m == 0:\n",
    "            return N*leg\n",
    "        elif m > 0:\n",
    "            Y = torch.cos(m*phi) * leg\n",
    "        else:\n",
    "            Y = torch.sin(abs(m)*phi) * leg\n",
    "        N *= np.sqrt(2. / pochhammer(l-abs(m)+1, 2*abs(m)))\n",
    "        Y *= N\n",
    "        return Y\n",
    "\n",
    "    def get(self, l, theta, phi, refresh=True):\n",
    "        \"\"\"Tesseral harmonic with Condon-Shortley phase.\n",
    "\n",
    "        The Tesseral spherical harmonics are also known as the real spherical\n",
    "        harmonics.\n",
    "\n",
    "        Args:\n",
    "            l: int for degree\n",
    "            theta: collatitude or polar angle\n",
    "            phi: longitude or azimuth\n",
    "        Returns:\n",
    "            tensor of shape [*theta.shape, 2*l+1]\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        if refresh:\n",
    "            self.clear()\n",
    "        for m in range(-l, l+1):\n",
    "            results.append(self.get_element(l, m, theta, phi))\n",
    "        return torch.stack(results, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80d7bc",
   "metadata": {},
   "source": [
    "### My own implementation from spherical harmonics from the blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73018331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will implement ALP (Associated Legandre Polynomials)\n",
    "\n",
    "# function analagous to pochammer function in the SE(3) Transformer\n",
    "# (J - m)!/(J + m)!\n",
    "def falling_factorial(J, m):\n",
    "    # computes (J + m)*(J+m - 1)*...(J-m+1)\n",
    "    f = 1.\n",
    "    for n in range(J + m, J - m, -1):\n",
    "        f *= n\n",
    "    return f\n",
    "\n",
    "\n",
    "def semifactorial(x):\n",
    "    \"\"\"Compute the semifactorial function x!!.\n",
    "\n",
    "    x!! = x * (x-2) * (x-4) *...\n",
    "\n",
    "    Args:\n",
    "        x: positive int\n",
    "    Returns:\n",
    "        float for x!!\n",
    "    \"\"\"\n",
    "    y = 1.\n",
    "    for n in range(x, 1, -2):\n",
    "        y *= n\n",
    "    return y\n",
    "\n",
    "# y: Legendre polynimil for the absolute value of m\n",
    "# P_J^{-m} (x) = (-1)^m (J - m)!/(J + m)! P_J^m(x)\n",
    "def negative_lpmv(J, m, y):\n",
    "    # check if m is negative\n",
    "    if m < 0:\n",
    "        # multiply y with the coefficient containing the falling \n",
    "        # factorial\n",
    "        y *= ((-1)**m / falling_factorial(J, m))\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b35f218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3628800.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falling_factorial(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c6b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursive implementation of APL\n",
    "def lpmv(J, m, x):\n",
    "    # get the absolute value of m\n",
    "    m_abs = abs(m)\n",
    "    # check if the polynomial has already been computed\n",
    "    if (J, m) in leg:\n",
    "        return leg[(J, m)]\n",
    "    # check if m is out of range -J to J\n",
    "    elif m_abs > J:\n",
    "        return None\n",
    "    # if J = 0, the associated Legendre polynomial is equal to 1\n",
    "    elif J == 0:\n",
    "        # return tensor of 1s with the same shape as x\n",
    "        leg[(l, m)] = torch.ones_like(x)\n",
    "        return leg[(l, m)]\n",
    "    \n",
    "    # if |m| = J, compute the polynomial using the equation from step 1\n",
    "    if m_abs == J:\n",
    "        # P^J_J (x) = (-1)^J (1 - x^2)^(J/2) (2J - 1)!!\n",
    "        # calculate coefficient term\n",
    "        y = (-1)**J * semifactorial(2*J - 1)\n",
    "        # multiply by the term dependent on x\n",
    "        y *= torch.pow(1 - x*x, m_abs/2)\n",
    "        # negative_lpmv returns y if m is positive and y multiplied by \n",
    "        # the negative coefficient defined in step 4 if m is negative\n",
    "        leg[(l, m)] = negative_lpmv(l, m, y)\n",
    "        return leg[(l, m)]\n",
    "    else:\n",
    "        # retursive call to compute lower degree polynomials up to\n",
    "        # boundary m = J\n",
    "        lpmv(J - 1, m, x)\n",
    "        \n",
    "    # if m is not on the boundary, first compute the first term of the relation\n",
    "    # defined in step 3\n",
    "    # P^J-1_J (x) = x (2J + 1) P^m_(J - 1) (x)\n",
    "    # if m_abs = J - 1, then this calculates the relation defined in step 2\n",
    "    y = ((2*J - 1)/(J - m_abs)) * x * lpmv(J - 1, m_abs, x)\n",
    "    \n",
    "    # P_J^m(x) = (2J - 1)/(J - m) x P^m_{J - 1}(x) - (J + m - 1)/(J - m) P^m_{J - 2} (x)\n",
    "    # check if m_abs != J - 1, then add the second term defined in step 3\n",
    "    if l - m_abs > 1:\n",
    "        y -= ((l + m_abs -1)/(l - m_abs)) * leg[(l - 2, m_abs)]\n",
    "        \n",
    "    # if m is negative, return the polynomial for m_abs scaled by the \n",
    "    # negative coefficient\n",
    "    if m < 0:\n",
    "        y = negative_lpmv(l, m, y)\n",
    "        \n",
    "    leg[(l, m)] = y\n",
    "    \n",
    "    return leg[(l, m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ff945e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m ans_2 \u001b[38;5;241m=\u001b[39m \u001b[43mlpmv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 31\u001b[0m, in \u001b[0;36mlpmv\u001b[0;34m(J, m, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leg[(l, m)]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# retursive call to compute lower degree polynomials up to\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# boundary m = J\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mlpmv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# if m is not on the boundary, first compute the first term of the relation\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# defined in step 3\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# P^J-1_J (x) = x (2J + 1) P^m_(J - 1) (x)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# if m_abs = J - 1, then this calculates the relation defined in step 2\u001b[39;00m\n\u001b[1;32m     37\u001b[0m y \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mJ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m(J \u001b[38;5;241m-\u001b[39m m_abs)) \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m*\u001b[39m lpmv(J \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, m_abs, x)\n",
      "Cell \u001b[0;32mIn[16], line 31\u001b[0m, in \u001b[0;36mlpmv\u001b[0;34m(J, m, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leg[(l, m)]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# retursive call to compute lower degree polynomials up to\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# boundary m = J\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mlpmv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# if m is not on the boundary, first compute the first term of the relation\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# defined in step 3\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# P^J-1_J (x) = x (2J + 1) P^m_(J - 1) (x)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# if m_abs = J - 1, then this calculates the relation defined in step 2\u001b[39;00m\n\u001b[1;32m     37\u001b[0m y \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mJ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m(J \u001b[38;5;241m-\u001b[39m m_abs)) \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m*\u001b[39m lpmv(J \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, m_abs, x)\n",
      "    \u001b[0;31m[... skipping similar frames: lpmv at line 31 (2 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[16], line 31\u001b[0m, in \u001b[0;36mlpmv\u001b[0;34m(J, m, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leg[(l, m)]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# retursive call to compute lower degree polynomials up to\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# boundary m = J\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mlpmv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# if m is not on the boundary, first compute the first term of the relation\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# defined in step 3\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# P^J-1_J (x) = x (2J + 1) P^m_(J - 1) (x)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# if m_abs = J - 1, then this calculates the relation defined in step 2\u001b[39;00m\n\u001b[1;32m     37\u001b[0m y \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mJ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m(J \u001b[38;5;241m-\u001b[39m m_abs)) \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m*\u001b[39m lpmv(J \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, m_abs, x)\n",
      "Cell \u001b[0;32mIn[16], line 26\u001b[0m, in \u001b[0;36mlpmv\u001b[0;34m(J, m, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     y \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m*\u001b[39mx, m_abs\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# negative_lpmv returns y if m is positive and y multiplied by \u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# the negative coefficient defined in step 4 if m is negative\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     leg[(l, m)] \u001b[38;5;241m=\u001b[39m negative_lpmv(\u001b[43ml\u001b[49m, m, y)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leg[(l, m)]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# retursive call to compute lower degree polynomials up to\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# boundary m = J\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "leg = {}\n",
    "J = 10\n",
    "m = 5\n",
    "x = torch.Tensor([0.5, 0.1, 0.2])\n",
    "ans_2 = lpmv(J, m, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2257006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 30086.1719, -21961.9492, -26591.5078])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a51da14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ans_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mans_2\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ans_2' is not defined"
     ]
    }
   ],
   "source": [
    "ans_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ba7b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spherical harmonics\n",
    "\n",
    "def get_element(J, m, theta, phi):\n",
    "    assert abs(m) <= J, \"m must be in the range -J to J\"\n",
    "    \n",
    "    # calculates the first fraction in the square root\n",
    "    N = np.sqrt((2*J + 1) / (4 * np.pi))\n",
    "    # stores the ALP term in leg\n",
    "    leg = lpmv(J, abs(m), torch.cos(theta))\n",
    "    \n",
    "    # multiply by the phi dependent term depending on the value of m\n",
    "    if m == 0:\n",
    "        # when m = 0 the other fraction in the square root cancels \n",
    "        # and the phi dependent term is 1\n",
    "        return N * leg\n",
    "    elif m > 0:\n",
    "        Y = torch.cos(m*phi) * leg\n",
    "    else:\n",
    "        #print(phi.shape, leg.shape)\n",
    "        Y = torch.sin(abs(m) * phi) * leg\n",
    "        \n",
    "    # multiply by a square root of the inverse falling factorial\n",
    "    # which is the same as in the ALP\n",
    "    N *= np.sqrt(2. / falling_factorial(J, abs(m)))\n",
    "    # multiplies the coefficient with angle-dependent term\n",
    "    Y *= N\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d148a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Y_J^m, m in {-J, J}\n",
    "def get(J, theta, phi, refresh = True):\n",
    "    # initialize tensor\n",
    "    results = []\n",
    "    \n",
    "    # loop over all possible values of m from J to J and add the \n",
    "    # computed spherical harmonic to results\n",
    "    for m in range(-J, J + 1):\n",
    "        results.append(get_element(J, m, theta, phi))\n",
    "        \n",
    "    return torch.stack(results, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc31874f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m leg \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m \u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m, in \u001b[0;36mget\u001b[0;34m(J, theta, phi, refresh)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# loop over all possible values of m from J to J and add the \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# computed spherical harmonic to results\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m-\u001b[39mJ, J \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(results, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m, in \u001b[0;36mget_element\u001b[0;34m(J, m, theta, phi)\u001b[0m\n\u001b[1;32m      7\u001b[0m N \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mJ \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# stores the ALP term in leg\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m leg \u001b[38;5;241m=\u001b[39m \u001b[43mlpmv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# multiply by the phi dependent term depending on the value of m\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# when m = 0 the other fraction in the square root cancels \u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# and the phi dependent term is 1\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 26\u001b[0m, in \u001b[0;36mlpmv\u001b[0;34m(J, m, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     y \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m*\u001b[39mx, m_abs\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# negative_lpmv returns y if m is positive and y multiplied by \u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# the negative coefficient defined in step 4 if m is negative\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     leg[(l, m)] \u001b[38;5;241m=\u001b[39m negative_lpmv(\u001b[43ml\u001b[49m, m, y)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leg[(l, m)]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# retursive call to compute lower degree polynomials up to\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# boundary m = J\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "leg = {}\n",
    "\n",
    "get(3, torch.Tensor([0.5, 0.2, 0.1]), torch.Tensor([0.5, 0.2, 0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c3854bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_ij: the relative displacement between nodes in spherical\n",
    "# coordinates [radius, alpha, beta]\n",
    "# beta = pi - theta (beta is 0 at south pole and pi at north pole;\n",
    "# supplementary to theta\n",
    "# alpha = phi (ranges from 0 to 2 pi)\n",
    "# r_ij: shape (batch_size, nodes, neighbors, 3 (r_ij))\n",
    "def precompute_sh(r_ij, max_J):\n",
    "    # initialize dictionary where keys correspond to J and values\n",
    "    # are tensors with shape (batch size, nodes, neighbors, 2J + 1)\n",
    "    Y_Js = {}\n",
    "    \n",
    "    # calculate (2J + 1)-dimensional spherical harmonics tensors for degrees up to\n",
    "    # max_J\n",
    "    for J in range(max_J + 1):\n",
    "        # r_ij[..., 2] extracts the values for beta for every edge in\n",
    "        # the graph\n",
    "        # r_ij[..., 1] extracts the values for alpha for every edge in the graph\n",
    "        Y_Js[J] = get(J, theta = math.pi - r_ij[..., 2], phi = r_ij[..., 1], refresh = False)\n",
    "        \n",
    "        \n",
    "    return Y_Js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df734f96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m leg \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m r_ij \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 5\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mprecompute_sh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_ij\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mkeys(), out[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m, in \u001b[0;36mprecompute_sh\u001b[0;34m(r_ij, max_J)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# calculate (2J + 1)-dimensional spherical harmonics tensors for degrees up to\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# max_J\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m J \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_J \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# r_ij[..., 2] extracts the values for beta for every edge in\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# the graph\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# r_ij[..., 1] extracts the values for alpha for every edge in the graph\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     Y_Js[J] \u001b[38;5;241m=\u001b[39m \u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr_ij\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr_ij\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Y_Js\n",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m, in \u001b[0;36mget\u001b[0;34m(J, theta, phi, refresh)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# loop over all possible values of m from J to J and add the \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# computed spherical harmonic to results\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m-\u001b[39mJ, J \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(results, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m, in \u001b[0;36mget_element\u001b[0;34m(J, m, theta, phi)\u001b[0m\n\u001b[1;32m      7\u001b[0m N \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mJ \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# stores the ALP term in leg\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m leg \u001b[38;5;241m=\u001b[39m \u001b[43mlpmv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# multiply by the phi dependent term depending on the value of m\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# when m = 0 the other fraction in the square root cancels \u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# and the phi dependent term is 1\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m, in \u001b[0;36mlpmv\u001b[0;34m(J, m, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# if J = 0, the associated Legendre polynomial is equal to 1\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m J \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# return tensor of 1s with the same shape as x\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     leg[(\u001b[43ml\u001b[49m, m)] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(x)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leg[(l, m)]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# if |m| = J, compute the polynomial using the equation from step 1\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "leg = {}\n",
    "\n",
    "r_ij = torch.randn((10, 1, 10, 3))/100\n",
    "\n",
    "out = precompute_sh(r_ij, 3)\n",
    "\n",
    "print(out.keys(), out[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea857ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basis_kernel(x_ij, max_degree = 2):\n",
    "\n",
    "    # compute all spherical harmonics for every edge up to 2*maximum \n",
    "    # feature type\n",
    "\n",
    "    Y = precompute_sh(x_ij, 2*max_degree)\n",
    "    device = Y[0].device\n",
    "\n",
    "    # initialize the dictionary where the key is the input and output degree \n",
    "    # pair and the values are all the basis kernels stored in an array of shape\n",
    "    # (edges, 1, 2l+1, 1, 2k+1, 2min(l, k) + 1)\n",
    "    basis = {}\n",
    "    # loop through input and output degree pairs up to max_degree\n",
    "    for di in range(max_degree + 1):\n",
    "        for do in range(max_degree + 1):\n",
    "            K_Js = [] # initialize set of basis kernels\n",
    "            # loop through all values of J from |k - l| to k + l\n",
    "            for J in range(abs(di - do), di + do + 1):\n",
    "                # get change-of-basis matrices with shape \n",
    "                # ((2l + 1)*(2k + 1), 2J + 1) that transforms the (2J + 1)-dim spherical\n",
    "                # tensor back to its original basis\n",
    "                Q_J = _basis_transformation_Q_J(J, di, do)\n",
    "                \n",
    "                Q_J = Q_J.float().to(device)\n",
    "                # Y[J] has shape (edges, 2J + 1)\n",
    "                # Q_J has shape ((2l + 1)*(2k+1), 2J + 1)\n",
    "                # matrix-vector multiplication to get K_J with shape\n",
    "                # (edges, (2l + 1)*(2k + 1)) of the vectorized type-J basis kernels\n",
    "                # W_lk = Q^lk_J @ Y_J = \\sum_J Q^lk_J Y_J\n",
    "                #print(Q_J.shape, Y[J].shape)\n",
    "                K_J = torch.matmul(Q_J, Y[J].t())\n",
    "                # Append to list of bases with shapes (2min(l, k) + 1, edges, (2l+1)*(2k+1))\n",
    "                K_Js.append(K_J)\n",
    "                \n",
    "            # reshape for dot product with radial weights\n",
    "            size = (-1, 1, 2*do + 1, 1, 2*di + 1, 2*min(di, do) + 1)\n",
    "            # stack reshapes to (edges, (2l+1)*(2k + 1), 2min(l, k) + 1)\n",
    "            # view reshapes to match size\n",
    "            basis[f'{di}, {do}'] = torch.stack(K_Js, -1).view(*size)\n",
    "            \n",
    "    return basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5da01d7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m leg \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m x_ij \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mget_basis_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_ij\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1, 1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m, in \u001b[0;36mget_basis_kernel\u001b[0;34m(x_ij, max_degree)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_basis_kernel\u001b[39m(x_ij, max_degree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# compute all spherical harmonics for every edge up to 2*maximum \u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# feature type\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mprecompute_sh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_ij\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmax_degree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     device \u001b[38;5;241m=\u001b[39m Y[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# initialize the dictionary where the key is the input and output degree \u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# pair and the values are all the basis kernels stored in an array of shape\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# (edges, 1, 2l+1, 1, 2k+1, 2min(l, k) + 1)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m, in \u001b[0;36mprecompute_sh\u001b[0;34m(r_ij, max_J)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# calculate (2J + 1)-dimensional spherical harmonics tensors for degrees up to\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# max_J\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m J \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_J \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# r_ij[..., 2] extracts the values for beta for every edge in\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# the graph\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# r_ij[..., 1] extracts the values for alpha for every edge in the graph\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     Y_Js[J] \u001b[38;5;241m=\u001b[39m \u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr_ij\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr_ij\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Y_Js\n",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m, in \u001b[0;36mget\u001b[0;34m(J, theta, phi, refresh)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# loop over all possible values of m from J to J and add the \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# computed spherical harmonic to results\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m-\u001b[39mJ, J \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(results, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m, in \u001b[0;36mget_element\u001b[0;34m(J, m, theta, phi)\u001b[0m\n\u001b[1;32m      7\u001b[0m N \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mJ \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# stores the ALP term in leg\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m leg \u001b[38;5;241m=\u001b[39m \u001b[43mlpmv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# multiply by the phi dependent term depending on the value of m\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# when m = 0 the other fraction in the square root cancels \u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# and the phi dependent term is 1\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m, in \u001b[0;36mlpmv\u001b[0;34m(J, m, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# if J = 0, the associated Legendre polynomial is equal to 1\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m J \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# return tensor of 1s with the same shape as x\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     leg[(\u001b[43ml\u001b[49m, m)] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(x)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leg[(l, m)]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# if |m| = J, compute the polynomial using the equation from step 1\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "leg = {}\n",
    "x_ij =  torch.randn((100, 3))/100\n",
    "\n",
    "get_basis_kernel(x_ij)['1, 1'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d34230",
   "metadata": {},
   "source": [
    "### Cartezian to spherical convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fd901c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spherical_from_cartesian_torch(cartesian, divide_radius_by=1.0):\n",
    "\n",
    "    ###################################################################################################################\n",
    "    # ON ANGLE CONVENTION\n",
    "    #\n",
    "    # sh has following convention for angles:\n",
    "    # :param theta: the colatitude / polar angle, ranging from 0(North Pole, (X, Y, Z) = (0, 0, 1)) to pi(South Pole, (X, Y, Z) = (0, 0, -1)).\n",
    "    # :param phi: the longitude / azimuthal angle, ranging from 0 to 2 pi.\n",
    "    #\n",
    "    # the 3D steerable CNN code therefore (probably) has the following convention for alpha and beta:\n",
    "    # beta = pi - theta; ranging from 0(South Pole, (X, Y, Z) = (0, 0, -1)) to pi(North Pole, (X, Y, Z) = (0, 0, 1)).\n",
    "    # alpha = phi\n",
    "    #\n",
    "    ###################################################################################################################\n",
    "\n",
    "    # initialise return array\n",
    "    # ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))\n",
    "    spherical = torch.zeros_like(cartesian)\n",
    "\n",
    "    # indices for return array\n",
    "    ind_radius = 0\n",
    "    ind_alpha = 1\n",
    "    ind_beta = 2\n",
    "\n",
    "    cartesian_x = 2\n",
    "    cartesian_y = 0\n",
    "    cartesian_z = 1\n",
    "\n",
    "    # get projected radius in xy plane\n",
    "    # xy = xyz[:,0]**2 + xyz[:,1]**2\n",
    "    r_xy = cartesian[..., cartesian_x] ** 2 + cartesian[..., cartesian_y] ** 2\n",
    "\n",
    "    # get second angle\n",
    "    # version 'elevation angle defined from Z-axis down'\n",
    "    spherical[..., ind_beta] = torch.atan2(torch.sqrt(r_xy), cartesian[..., cartesian_z])\n",
    "    # ptsnew[:,4] = np.arctan2(np.sqrt(xy), xyz[:,2])\n",
    "    # version 'elevation angle defined from XY-plane up'\n",
    "    #ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy))\n",
    "    # spherical[:, ind_beta] = np.arctan2(cartesian[:, 2], np.sqrt(r_xy))\n",
    "\n",
    "    # get angle in x-y plane\n",
    "    spherical[...,ind_alpha] = torch.atan2(cartesian[...,cartesian_y], cartesian[...,cartesian_x])\n",
    "\n",
    "    # get overall radius\n",
    "    # ptsnew[:,3] = np.sqrt(xy + xyz[:,2]**2)\n",
    "    if divide_radius_by == 1.0:\n",
    "        spherical[..., ind_radius] = torch.sqrt(r_xy + cartesian[...,cartesian_z]**2)\n",
    "    else:\n",
    "        spherical[..., ind_radius] = torch.sqrt(r_xy + cartesian[...,cartesian_z]**2)/divide_radius_by\n",
    "\n",
    "    return spherical\n",
    "\n",
    "\n",
    "# @profile\n",
    "def get_spherical_from_cartesian(cartesian):\n",
    "\n",
    "    ###################################################################################################################\n",
    "    # ON ANGLE CONVENTION\n",
    "    #\n",
    "    # sh has following convention for angles:\n",
    "    # :param theta: the colatitude / polar angle, ranging from 0(North Pole, (X, Y, Z) = (0, 0, 1)) to pi(South Pole, (X, Y, Z) = (0, 0, -1)).\n",
    "    # :param phi: the longitude / azimuthal angle, ranging from 0 to 2 pi.\n",
    "    #\n",
    "    # the 3D steerable CNN code therefore (probably) has the following convention for alpha and beta:\n",
    "    # beta = pi - theta; ranging from 0(South Pole, (X, Y, Z) = (0, 0, -1)) to pi(North Pole, (X, Y, Z) = (0, 0, 1)).\n",
    "    # alpha = phi\n",
    "    #\n",
    "    ###################################################################################################################\n",
    "\n",
    "    if torch.is_tensor(cartesian):\n",
    "        cartesian = np.array(cartesian.cpu())\n",
    "\n",
    "    # initialise return array\n",
    "    # ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))\n",
    "    spherical = np.zeros(cartesian.shape)\n",
    "\n",
    "    # indices for return array\n",
    "    ind_radius = 0\n",
    "    ind_alpha = 1\n",
    "    ind_beta = 2\n",
    "\n",
    "    cartesian_x = 2\n",
    "    cartesian_y = 0\n",
    "    cartesian_z = 1\n",
    "\n",
    "    # get projected radius in xy plane\n",
    "    # xy = xyz[:,0]**2 + xyz[:,1]**2\n",
    "    r_xy = cartesian[..., cartesian_x] ** 2 + cartesian[..., cartesian_y] ** 2\n",
    "\n",
    "    # get overall radius\n",
    "    # ptsnew[:,3] = np.sqrt(xy + xyz[:,2]**2)\n",
    "    spherical[..., ind_radius] = np.sqrt(r_xy + cartesian[...,cartesian_z]**2)\n",
    "\n",
    "    # get second angle\n",
    "    # version 'elevation angle defined from Z-axis down'\n",
    "    spherical[..., ind_beta] = np.arctan2(np.sqrt(r_xy), cartesian[..., cartesian_z])\n",
    "    # ptsnew[:,4] = np.arctan2(np.sqrt(xy), xyz[:,2])\n",
    "    # version 'elevation angle defined from XY-plane up'\n",
    "    #ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy))\n",
    "    # spherical[:, ind_beta] = np.arctan2(cartesian[:, 2], np.sqrt(r_xy))\n",
    "\n",
    "    # get angle in x-y plane\n",
    "    spherical[...,ind_alpha] = np.arctan2(cartesian[...,cartesian_y], cartesian[...,cartesian_x])\n",
    "\n",
    "    return spherical\n",
    "\n",
    "def test_coordinate_conversion():\n",
    "    p = np.array([0, 0, -1])\n",
    "    expected = np.array([1, 0, 0])\n",
    "    assert get_spherical_from_cartesian(p) == expected\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76425a47",
   "metadata": {},
   "source": [
    "### Reference implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39c38302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import lpmv as lpmv_scipy\n",
    "\n",
    "\n",
    "def semifactorial(x):\n",
    "    \"\"\"Compute the semifactorial function x!!.\n",
    "\n",
    "    x!! = x * (x-2) * (x-4) *...\n",
    "\n",
    "    Args:\n",
    "        x: positive int\n",
    "    Returns:\n",
    "        float for x!!\n",
    "    \"\"\"\n",
    "    y = 1.\n",
    "    for n in range(x, 1, -2):\n",
    "        y *= n\n",
    "    return y\n",
    "\n",
    "\n",
    "def pochhammer(x, k):\n",
    "    \"\"\"Compute the pochhammer symbol (x)_k.\n",
    "\n",
    "    (x)_k = x * (x+1) * (x+2) *...* (x+k-1)\n",
    "\n",
    "    Args:\n",
    "        x: positive int\n",
    "    Returns:\n",
    "        float for (x)_k\n",
    "    \"\"\"\n",
    "    xf = float(x)\n",
    "    for n in range(x+1, x+k):\n",
    "        xf *= n\n",
    "    return xf\n",
    "\n",
    "def lpmv(l, m, x):\n",
    "    \"\"\"Associated Legendre function including Condon-Shortley phase.\n",
    "\n",
    "    Args:\n",
    "        m: int order \n",
    "        l: int degree\n",
    "        x: float argument tensor\n",
    "    Returns:\n",
    "        tensor of x-shape\n",
    "    \"\"\"\n",
    "    m_abs = abs(m)\n",
    "    \n",
    "    # P^m_J = 0 forall m > J\n",
    "    if m_abs > l:\n",
    "        return torch.zeros_like(x)\n",
    "\n",
    "    # Compute P_m^m\n",
    "    # P_m^m = (-1)^J (1 - x^2)^(J/2) (2J - 1)!!\n",
    "    yold = ((-1)**m_abs * semifactorial(2*m_abs-1)) * torch.pow(1-x*x, m_abs/2)\n",
    "    \n",
    "    # Compute P_{m+1}^m\n",
    "    # P_m+1^m = x (2 m + 1) P^m_m\n",
    "    if m_abs != l:\n",
    "        y = x * (2*m_abs+1) * yold\n",
    "    else:\n",
    "        y = yold\n",
    "\n",
    "    # Compute P_{l}^m from recursion in P_{l-1}^m and P_{l-2}^m\n",
    "    # P_l^m (x) = [(2 l - 1 ) / ( l - m )] P^m_{l - 1} (x) - [(l + m - 1) / (l - m)] P^m_{l - 2} (x)\n",
    "    for i in range(m_abs+2, l+1):\n",
    "        tmp = y\n",
    "        # Inplace speedup\n",
    "        y = ((2*i-1) / (i-m_abs)) * x * y\n",
    "        y -= ((i+m_abs-1)/(i-m_abs)) * yold\n",
    "        yold = tmp\n",
    "\n",
    "    # P^-m_l (x) = (-1)^m (l - m)!/(l + m)! P^m_l (x)\n",
    "    if m < 0:\n",
    "        y *= ((-1)**m / pochhammer(l+m+1, -2*m))\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd20b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphericalHarmonics(object):\n",
    "    def __init__(self):\n",
    "        self.leg = {}\n",
    "\n",
    "    def clear(self):\n",
    "        self.leg = {}\n",
    "\n",
    "    def negative_lpmv(self, l, m, y):\n",
    "        \"\"\"Compute negative order coefficients\"\"\"\n",
    "        if m < 0:\n",
    "            y *= ((-1)**m / pochhammer(l+m+1, -2*m))\n",
    "        return y\n",
    "\n",
    "    def lpmv(self, l, m, x):\n",
    "        \"\"\"Associated Legendre function including Condon-Shortley phase.\n",
    "\n",
    "        Args:\n",
    "            m: int order \n",
    "            l: int degree\n",
    "            x: float argument tensor\n",
    "        Returns:\n",
    "            tensor of x-shape\n",
    "        \"\"\"\n",
    "        # Check memoized versions\n",
    "        m_abs = abs(m)\n",
    "        if (l,m) in self.leg:\n",
    "            return self.leg[(l,m)]\n",
    "        elif m_abs > l:\n",
    "            return None\n",
    "        elif l == 0:\n",
    "            self.leg[(l,m)] = torch.ones_like(x)\n",
    "            return self.leg[(l,m)]\n",
    "        \n",
    "        # Check if on boundary else recurse solution down to boundary\n",
    "        if m_abs == l:\n",
    "            # Compute P_m^m\n",
    "            y = (-1)**m_abs * semifactorial(2*m_abs-1)\n",
    "            y *= torch.pow(1-x*x, m_abs/2)\n",
    "            self.leg[(l,m)] = self.negative_lpmv(l, m, y)\n",
    "            return self.leg[(l,m)]\n",
    "        else:\n",
    "            # Recursively precompute lower degree harmonics\n",
    "            self.lpmv(l-1, m, x)\n",
    "\n",
    "        # Compute P_{l}^m from recursion in P_{l-1}^m and P_{l-2}^m\n",
    "        # Inplace speedup\n",
    "        y = ((2*l-1) / (l-m_abs)) * x * self.lpmv(l-1, m_abs, x)\n",
    "        if l - m_abs > 1:\n",
    "            y -= ((l+m_abs-1)/(l-m_abs)) * self.leg[(l-2, m_abs)]\n",
    "        #self.leg[(l, m_abs)] = y\n",
    "        \n",
    "        if m < 0:\n",
    "            y = self.negative_lpmv(l, m, y)\n",
    "        self.leg[(l,m)] = y\n",
    "\n",
    "        return self.leg[(l,m)]\n",
    "\n",
    "    def get_element(self, l, m, theta, phi):\n",
    "        \"\"\"Tesseral spherical harmonic with Condon-Shortley phase.\n",
    "\n",
    "        The Tesseral spherical harmonics are also known as the real spherical\n",
    "        harmonics.\n",
    "\n",
    "        Args:\n",
    "            l: int for degree\n",
    "            m: int for order, where -l <= m < l\n",
    "            theta: collatitude or polar angle\n",
    "            phi: longitude or azimuth\n",
    "        Returns:\n",
    "            tensor of shape theta\n",
    "        \"\"\"\n",
    "        assert abs(m) <= l, \"absolute value of order m must be <= degree l\"\n",
    "\n",
    "        N = np.sqrt((2*l+1) / (4*np.pi))\n",
    "        leg = self.lpmv(l, abs(m), torch.cos(theta))\n",
    "        if m == 0:\n",
    "            return N*leg\n",
    "        elif m > 0:\n",
    "            Y = torch.cos(m*phi) * leg\n",
    "        else:\n",
    "            Y = torch.sin(abs(m)*phi) * leg\n",
    "        N *= np.sqrt(2. / pochhammer(l-abs(m)+1, 2*abs(m)))\n",
    "        Y *= N\n",
    "        return Y\n",
    "\n",
    "    def get(self, l, theta, phi, refresh=True):\n",
    "        \"\"\"Tesseral harmonic with Condon-Shortley phase.\n",
    "\n",
    "        The Tesseral spherical harmonics are also known as the real spherical\n",
    "        harmonics.\n",
    "\n",
    "        Args:\n",
    "            l: int for degree\n",
    "            theta: collatitude or polar angle\n",
    "            phi: longitude or azimuth\n",
    "        Returns:\n",
    "            tensor of shape [*theta.shape, 2*l+1]\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        if refresh:\n",
    "            self.clear()\n",
    "        for m in range(-l, l+1):\n",
    "            results.append(self.get_element(l, m, theta, phi))\n",
    "        return torch.stack(results, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480bbd28",
   "metadata": {},
   "source": [
    "### Radial function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54ad7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BN(nn.Module):\n",
    "    \"\"\"SE(3)-equvariant batch/layer normalization\"\"\"\n",
    "    def __init__(self, m):\n",
    "        \"\"\"SE(3)-equvariant batch/layer normalization\n",
    "\n",
    "        Args:\n",
    "            m: int for number of output channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.bn = nn.LayerNorm(m)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bn(x)\n",
    "\n",
    "# num_freq = 2 min (l, k) + 1\n",
    "# mid_dim = 32\n",
    "class RadialFunc(nn.Module):\n",
    "    \"\"\"NN parameterized radial profile function\"\"\"\n",
    "    def __init__(self, num_bases, mi, mo, edge_dim: int = 0):\n",
    "        \"\"\" NN parametrized radial profile function.\n",
    "        \n",
    "        Args:\n",
    "            num_freq: number of output frequencies\n",
    "            in_dim: multiplicity of input (num input channels)\n",
    "            out_dim: multiplicity of output (num output channels)\n",
    "            edge_dim: number of dimensions for edge embedding\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_bases = num_bases\n",
    "        self.mi = mi\n",
    "        self.mid_dim = 32\n",
    "        self.mo = mo\n",
    "        self.edge_dim = edge_dim\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            # FFN transfroms from number of edges to mid_dim\n",
    "            nn.Linear(self.edge_dim + 1, self.mid_dim),\n",
    "            # Normalization of the layer output to zeros mean and std equal to 1\n",
    "            BN(self.mid_dim),\n",
    "            nn.ReLU(),\n",
    "            # Hidden layer that does not change dim\n",
    "            nn.Linear(self.mid_dim, self.mid_dim),\n",
    "            # Another Norm\n",
    "            BN(self.mid_dim),\n",
    "            # ReLU activation\n",
    "            nn.ReLU(),\n",
    "            # FFN transforms from dim_dim to (2min(l, k) + 1)*mi*mo\n",
    "            nn.Linear(self.mid_dim, self.num_bases*mi*mo)\n",
    "        )\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.net[0].weight)\n",
    "        nn.init.kaiming_uniform_(self.net[3].weight)\n",
    "        nn.init.kaiming_uniform_(self.net[6].weight)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"RadialFunc(edge_dim={self.edge_dim}, in_dim={self.mi}, out_dim={self.mo})\"\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # calculates a single vector of radial weights given the distance\n",
    "        # between nodes with the FFN\n",
    "        y = self.net(x)\n",
    "        # reshapes to separate the radial weights by output channels,\n",
    "        # input channel, and degree J to prepare for broadcasting and element-wise\n",
    "        # multiplication with the array of basis kernels of shape (-1, 1, 2l+1, 1, 2k+1, num_bases)\n",
    "        #print(y.shape)\n",
    "        return y.view(-1, self.mo, 1, self.mi, 1, self.num_bases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b2cde13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 15, 1, 10, 1, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single test\n",
    "\n",
    "dist_ij = torch.rand((10, 1))\n",
    "\n",
    "model_Radial = RadialFunc(3, 10, 15)\n",
    "\n",
    "model_Radial(dist_ij).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e63d729",
   "metadata": {},
   "source": [
    "### Tensor Field Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8aa12413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the radial network for type-k inputs and type-l outputs\n",
    "# the falue of edge_dim has a default value of 1 which determines\n",
    "# the dimension of the input to the radial function\n",
    "num_bases = 3\n",
    "mi = 1\n",
    "mo = 3\n",
    "edge_dim = 0\n",
    "rp = RadialFunc(num_bases, mi, mo, edge_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f540b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calls forward method of RadialFunc class which feeds the realtive\n",
    "# distance into radial network\n",
    "R = rp(dist_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad4470ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ij =  torch.randn((100, 3))/100\n",
    "\n",
    "r_ij = x_ij[..., 0, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ceef7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leg = {}\n",
    "x_ij =  torch.randn((100, 3))/100\n",
    "\n",
    "r_ij = x_ij[..., 0, None]\n",
    "\n",
    "do = 0\n",
    "di = 1\n",
    "\n",
    "basis = get_basis_kernel(x_ij)\n",
    "\n",
    "# 2 min(l, k) + 1\n",
    "num_bases = 2*min(do, di) + 1\n",
    "mi = 1\n",
    "mo = 3\n",
    "edge_dim = 0\n",
    "rp = RadialFunc(num_bases, mi, mo, edge_dim)\n",
    "R = rp(r_ij)\n",
    "\n",
    "\n",
    "# R: radial weights with shape (batch_size, mo, 1, mi, 1, 2 min(di, do) + 1)\n",
    "# basis[f'{self.di}, {self.do}']: tensor of basis kernels \n",
    "# basis_shape:                 (batch_size, 1, 2*do + 1, 1, 2*di + 1, 2*min(di, do) + 1)\n",
    "# for input deg di and output deg do\n",
    "# kernel output:               (batch_size, mo, 2*do + 1, mi, 2*di + 1)\n",
    "kernel = torch.sum(R*basis[f'{di}, {do}'], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46e12f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape kernel to (mo * (2*do + 1), mi * (2*di + 1)) to prepare for\n",
    "# matrix-vector multiplication with hte concatenated input channels of type\n",
    "# di\n",
    "kernel = kernel.view(kernel.shape[0], (2 * do + 1) * mo, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8bed4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseConv(nn.Module):\n",
    "    \"\"\"SE(3)-equivariant convolution between two single-type features\"\"\"\n",
    "    def __init__(self, degree_in: int, nc_in: int, degree_out: int,\n",
    "                 nc_out: int, edge_dim: int=0):\n",
    "        \"\"\"SE(3)-equivariant convolution between a pair of feature types.\n",
    "\n",
    "        This layer performs a convolution from nc_in features of type degree_in\n",
    "        to nc_out features of type degree_out.\n",
    "\n",
    "        Args:\n",
    "            degree_in: degree of input fiber\n",
    "            nc_in: number of channels on input\n",
    "            degree_out: degree of out order\n",
    "            nc_out: number of channels on output\n",
    "            edge_dim: number of dimensions for edge embedding\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Log settings\n",
    "        self.degree_in = degree_in\n",
    "        self.degree_out = degree_out\n",
    "        self.nc_in = nc_in\n",
    "        self.nc_out = nc_out\n",
    "\n",
    "        # Functions of the degree\n",
    "        self.num_freq = 2*min(degree_in, degree_out) + 1\n",
    "        self.d_out = 2*degree_out + 1\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        # Radial profile function\n",
    "        self.rp = RadialFunc(self.num_freq, nc_in, nc_out, self.edge_dim)\n",
    "        \n",
    "    @profile\n",
    "    def forward(self, feat, basis):\n",
    "        # Get radial weights\n",
    "        R = self.rp(feat)\n",
    "        kernel = torch.sum(R * basis[f'{self.degree_in},{self.degree_out}'], -1)\n",
    "        return kernel.view(kernel.shape[0], self.d_out*self.nc_out, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9753f7e6",
   "metadata": {},
   "source": [
    "### Fixing representation to apply fibers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e4fea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def get_basis(G, max_degree, compute_gradients):\n",
    "    \"\"\"Precompute the SE(3)-equivariant weight basis, W_J^lk(x)\n",
    "\n",
    "    This is called by get_basis_and_r().\n",
    "\n",
    "    Args:\n",
    "        G: DGL graph instance of type dgl.DGLGraph\n",
    "        max_degree: non-negative int for degree of highest feature type\n",
    "        compute_gradients: boolean, whether to compute gradients during basis construction\n",
    "    Returns:\n",
    "        dict of equivariant bases. Keys are in the form 'd_in,d_out'. Values are\n",
    "        tensors of shape (batch_size, 1, 2*d_out+1, 1, 2*d_in+1, number_of_bases)\n",
    "        where the 1's will later be broadcast to the number of output and input\n",
    "        channels\n",
    "    \"\"\"\n",
    "    if compute_gradients:\n",
    "        context = nullcontext()\n",
    "    else:\n",
    "        context = torch.no_grad()\n",
    "\n",
    "    with context:\n",
    "        cloned_d = torch.clone(G.edata['d'])\n",
    "\n",
    "        if G.edata['d'].requires_grad:\n",
    "            cloned_d.requires_grad_()\n",
    "            log_gradient_norm(cloned_d, 'Basis computation flow')\n",
    "\n",
    "        # Relative positional encodings (vector)\n",
    "        r_ij = get_spherical_from_cartesian_torch(cloned_d)\n",
    "        # Spherical harmonic basis\n",
    "        Y = precompute_sh(r_ij, 2*max_degree)\n",
    "        device = Y[0].device\n",
    "\n",
    "        basis = {}\n",
    "        for d_in in range(max_degree+1):\n",
    "            for d_out in range(max_degree+1):\n",
    "                K_Js = []\n",
    "                for J in range(abs(d_in-d_out), d_in+d_out+1):\n",
    "                    # Get spherical harmonic projection matrices\n",
    "                    Q_J = _basis_transformation_Q_J(J, d_in, d_out)\n",
    "                    Q_J = Q_J.float().T.to(device)\n",
    "\n",
    "                    # Create kernel from spherical harmonics\n",
    "                    K_J = torch.matmul(Y[J], Q_J)\n",
    "                    K_Js.append(K_J)\n",
    "\n",
    "                # Reshape so can take linear combinations with a dot product\n",
    "                size = (-1, 1, 2*d_out+1, 1, 2*d_in+1, 2*min(d_in, d_out)+1)\n",
    "                basis[f'{d_in},{d_out}'] = torch.stack(K_Js, -1).view(*size)\n",
    "        return basis\n",
    "\n",
    "\n",
    "def get_r(G):\n",
    "    \"\"\"Compute internodal distances\"\"\"\n",
    "    cloned_d = torch.clone(G.edata['d'])\n",
    "\n",
    "    if G.edata['d'].requires_grad:\n",
    "        cloned_d.requires_grad_()\n",
    "        log_gradient_norm(cloned_d, 'Neural networks flow')\n",
    "\n",
    "    return torch.sqrt(torch.sum(cloned_d**2, -1, keepdim=True))\n",
    "\n",
    "\n",
    "def get_basis_and_r(G, max_degree, compute_gradients=False):\n",
    "    \"\"\"Return equivariant weight basis (basis) and internodal distances (r).\n",
    "\n",
    "    Call this function *once* at the start of each forward pass of the model.\n",
    "    It computes the equivariant weight basis, W_J^lk(x), and internodal\n",
    "    distances, needed to compute varphi_J^lk(x), of eqn 8 of\n",
    "    https://arxiv.org/pdf/2006.10503.pdf. The return values of this function\n",
    "    can be shared as input across all SE(3)-Transformer layers in a model.\n",
    "\n",
    "    Args:\n",
    "        G: DGL graph instance of type dgl.DGLGraph()\n",
    "        max_degree: non-negative int for degree of highest feature-type\n",
    "        compute_gradients: controls whether to compute gradients during basis construction\n",
    "    Returns:\n",
    "        dict of equivariant bases, keys are in form '<d_in><d_out>'\n",
    "        vector of relative distances, ordered according to edge ordering of G\n",
    "    \"\"\"\n",
    "    basis = get_basis(G, max_degree, compute_gradients)\n",
    "    r = get_r(G)\n",
    "    return basis, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be425371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5254/2732476931.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.file_address)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train-set, task: homo, source: ./QM9_data/QM9_data.pt, length: 100000\n",
      "MINIBATCH\n",
      "Graph(num_nodes=591, num_edges=10696,\n",
      "      ndata_schemes={'x': Scheme(shape=(3,), dtype=torch.float32), 'f': Scheme(shape=(6, 1), dtype=torch.float32)}\n",
      "      edata_schemes={'d': Scheme(shape=(3,), dtype=torch.float32), 'w': Scheme(shape=(5,), dtype=torch.float32)})\n",
      "torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladygin/anaconda3/envs/torch_gcnn/lib/python3.9/site-packages/dgl/heterograph.py:92: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning(\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "leg = {}\n",
    "\n",
    "dataset = QM9Dataset('./QM9_data/QM9_data.pt', \"homo\", mode='train', fully_connected=True)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "\n",
    "iter_dataloader = iter(dataloader) # so I can use next\n",
    "for i in range(1):\n",
    "    data = next(iter_dataloader)\n",
    "    print(\"MINIBATCH\")\n",
    "    print(data[0]) \n",
    "    print(data[1].shape) # batch size -> connected graph of size batch\n",
    "\n",
    "\n",
    "atom_feature_size = dataset.atom_feature_size\n",
    "num_degrees = 4\n",
    "num_channels = 32\n",
    "num_channels_out = num_channels*num_degrees\n",
    "edge_dim = dataset.num_bonds\n",
    "\n",
    "connection = 'skip'\n",
    "\n",
    "# building fibers for input data\n",
    "fibers = {'in': Fiber(1, atom_feature_size),\n",
    "           'mid': Fiber(num_degrees, num_channels),\n",
    "           'out': Fiber(1, num_channels_out)}\n",
    "\n",
    "\n",
    "f_in = fibers['in']\n",
    "f_out = fibers['out']\n",
    "# initialize dgl graph\n",
    "G = copy.deepcopy(dataset[0][0])\n",
    "\n",
    "basis, r = get_basis_and_r(G, num_degrees - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a3a6ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 6, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.ndata['f'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6773adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = {'0': G.ndata['f']} # type 0 node feature\n",
    "\n",
    "kernel_unary = {}\n",
    "# loop over (multiplicity, degree) tuples in input fiber\n",
    "for (mi, di) in f_in.structure:\n",
    "    # loop over (multiplicity, degree) tuples in output fiber\n",
    "    for (mo, do) in f_out.structure:\n",
    "        # generate a (mi * mo) unique kernels corresponding to every input\n",
    "        # and output channel pair\n",
    "        # store in dictionary with key f'({di},{do})'\n",
    "        kernel_unary[f'({di},{do})'] = PairwiseConv(di, mi, do, mo, edge_dim=edge_dim)\n",
    "        \n",
    "        \n",
    "# center -> center self connections\n",
    "# skip connection consideres output connection \n",
    "# as linear combination of input connections\n",
    "kernel_self = {\n",
    "    'skip': nn.ParameterDict(),\n",
    "    'TFN': nn.ParameterDict(),\n",
    "}\n",
    "\n",
    "# in constructor\n",
    "# skip connection consideres output connection \n",
    "# as linear combination of input connections\n",
    "for mi, di in f_in.structure:\n",
    "    # proceed if input type is also an output type\n",
    "    if di in f_out.degrees:\n",
    "        # extract num of output channels of the type\n",
    "        mo = f_out.structure_dict[di]\n",
    "        # initialize learnable mi x mo weight matrix with random integers and scale down\n",
    "        # singleton dimension used to broadcast across nodes\n",
    "        W = nn.Parameter(torch.randn(1, mo, mi)/np.sqrt(mi))\n",
    "        kernel_self['skip'][f'{di}'] = W\n",
    "        \n",
    "        \n",
    "# in constructor\n",
    "# mixing connection consideres output self features\n",
    "# as linear combination of output connections\n",
    "for mo, do in f_in.structure:\n",
    "    # initialize square learnable weight matrix of random integers\n",
    "    # and scale down\n",
    "    W = nn.Parameter(torch.randn(1, mo, mo) / np.sqrt(mo))\n",
    "    kernel_self['TFN'][f\"{do}\"] = W\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df6f9c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[ 3.4800e-02,  1.3604e+00,  1.5080e-01],\n",
       "        [-9.5000e-03, -1.6100e-02,  5.3400e-02],\n",
       "        [-1.1400e+00, -7.4810e-01,  2.6900e-02],\n",
       "        [-1.1403e+00, -2.1319e+00, -1.2000e-02],\n",
       "        [ 3.7300e-02, -2.7655e+00, -1.5400e-02],\n",
       "        [-1.0070e-01, -4.0993e+00, -4.1100e-02],\n",
       "        [ 1.2330e+00, -2.1386e+00,  6.0000e-04],\n",
       "        [ 1.3055e+00, -6.9670e-01,  1.7000e-02],\n",
       "        [ 2.3546e+00,  5.4000e-02, -7.2000e-03],\n",
       "        [ 9.6010e-01,  1.7065e+00, -7.8600e-02],\n",
       "        [-7.2620e-01,  1.8749e+00, -2.6370e-01],\n",
       "        [-2.1488e+00, -3.6290e-01,  4.1400e-02],\n",
       "        [-1.0447e+00, -4.3020e+00, -4.4600e-02],\n",
       "        [ 2.1340e+00, -2.7379e+00, -1.4600e-02],\n",
       "        [ 3.2064e+00, -5.0600e-01, -4.0100e-02]]), 'f': tensor([[[0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [7.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [6.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [6.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [8.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [6.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [8.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [6.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [6.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [7.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]]])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77bf948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with G.local_scope():\n",
    "    # Add node features to local graph scope\n",
    "    for k, v in h.items():\n",
    "        G.ndata[k] = v\n",
    "\n",
    "    # Add edge features\n",
    "    if 'w' in G.edata.keys():\n",
    "        w = G.edata['w']\n",
    "        feat = torch.cat([w, r], -1)\n",
    "    else:\n",
    "        feat = torch.cat([r,], -1)\n",
    "\n",
    "    for (mi, di) in f_in.structure:\n",
    "        for (mo, do) in f_out.structure:\n",
    "            etype = f\"({di},{do})\"\n",
    "            G.edata[etype] = kernel_unary[etype](feat, basis) \n",
    "\n",
    "    # defining the function for reduction\n",
    "    # function is defined for each output feature type d\n",
    "    for do in f_out.degrees:\n",
    "\n",
    "        # edge user-defined function in DGL that computes the message for a single output feature type\n",
    "        # do\n",
    "        def udf_u_mul_e(do):\n",
    "            # calculate neighbor -> center message for type single output\n",
    "            # feature type do\n",
    "            def fnc(edges):\n",
    "                msg = 0\n",
    "                for mi, di in f_in.structure:\n",
    "                    # extract all feature channels of type di from the neighborhood\n",
    "                    # nodes and condense into single vector\n",
    "                    # src has shape (edges, mi*(2*di + 1), 1)\n",
    "                    src = edges.src[f'{di}'].view(-1, mi*(2*di + 1), 1)\n",
    "\n",
    "                    # extract kernel for input type di and output type do\n",
    "                    edge = edges.data[f\"({di},{do})\"]\n",
    "                    # matrix multiplication to get (mo*(2*do + 1))-dimentional vector and add to total msg\n",
    "                    msg += msg + torch.matmul(edge, src)\n",
    "\n",
    "                # reshape message to separate output channels\n",
    "                msg = msg.view(msg.shape[0], -1, 2*do + 1)\n",
    "\n",
    "\n",
    "                # center -> center message\n",
    "                if connection == 'skip':\n",
    "                    # extract all input features of type do from all nodes\n",
    "                    dst = edges.dst[f'{do}']\n",
    "                    # extract self-intecation weights for type do channels\n",
    "                    W = kernel_self[connection][f'{do}']\n",
    "                    # calculate the array of self-interaction tensors with shape (nodes, mo, 2*do +1)\n",
    "                    self_int = torch.matmul(W, dst)\n",
    "                    msg = msg + self_int\n",
    "\n",
    "                # in user-defined DGL edge -> node function\n",
    "                # extract weight array of shape (1, mo, mo)\n",
    "                if connection == 'TFN':\n",
    "                    W = kernel_self['TFN'][f'{do}']\n",
    "                    # matrix multiplication that generates output feature tensor for \n",
    "                    # for degree do\n",
    "                    msg = torch.matmul(W, msg)\n",
    "\n",
    "                return {'msg': msg.view(msg.shape[0], -1, 2*do + 1)}\n",
    "            return fnc\n",
    "\n",
    "        # call update all function that takes (message_func, reduce_func) as input\n",
    "        G.update_all(udf_u_mul_e(do), fn.mean('msg', f'out{do}'))\n",
    "\n",
    "    # return a dictionary of the output node features where every degree\n",
    "    # is linked to an array with shape (edges, mo, 2*do + 1) by extracting\n",
    "    # the node data stored from calling update_all\n",
    "\n",
    "    f_mid = {f'{do}': G.ndata[f'out{do}'] for do in f_out.degrees}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f79de794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['x', 'f']), dict_keys(['0']))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.ndata.keys(), f_mid.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b074fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mid_my = f_mid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045a439-0204-4ad4-8c69-86013897acd1",
   "metadata": {},
   "source": [
    "### Reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "419ba34e-53b3-4925-9e60-328b1d8366ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GConvSE3(nn.Module):\n",
    "    \"\"\"A tensor field network layer as a DGL module.\n",
    "\n",
    "    GConvSE3 stands for a Graph Convolution SE(3)-equivariant layer. It is the\n",
    "    equivalent of a linear layer in an MLP, a conv layer in a CNN, or a graph\n",
    "    conv layer in a GCN.\n",
    "\n",
    "    At each node, the activations are split into different \"feature types\",\n",
    "    indexed by the SE(3) representation type: non-negative integers 0, 1, 2, ..\n",
    "    \"\"\"\n",
    "    def __init__(self, f_in, f_out, self_interaction: bool=False, edge_dim: int=0, flavor='skip'):\n",
    "        \"\"\"SE(3)-equivariant Graph Conv Layer\n",
    "\n",
    "        Args:\n",
    "            f_in: list of tuples [(multiplicities, type),...]\n",
    "            f_out: list of tuples [(multiplicities, type),...]\n",
    "            self_interaction: include self-interaction in convolution\n",
    "            edge_dim: number of dimensions for edge embedding\n",
    "            flavor: allows ['TFN', 'skip'], where 'skip' adds a skip connection\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "        self.edge_dim = edge_dim\n",
    "        self.self_interaction = self_interaction\n",
    "        self.flavor = flavor\n",
    "\n",
    "        # Neighbor -> center weights\n",
    "        self.kernel_unary = nn.ModuleDict()\n",
    "        for (mi, di) in self.f_in.structure:\n",
    "            for (mo, do) in self.f_out.structure:\n",
    "                self.kernel_unary[f'({di},{do})'] = PairwiseConv(di, mi, do, mo, edge_dim=edge_dim)\n",
    "\n",
    "        # Center -> center weights\n",
    "        self.kernel_self = nn.ParameterDict()\n",
    "        if self_interaction:\n",
    "            assert self.flavor in ['TFN', 'skip']\n",
    "            if self.flavor == 'TFN':\n",
    "                for m_out, d_out in self.f_out.structure:\n",
    "                    W = nn.Parameter(torch.randn(1, m_out, m_out) / np.sqrt(m_out))\n",
    "                    self.kernel_self[f'{d_out}'] = W\n",
    "            elif self.flavor == 'skip':\n",
    "                for m_in, d_in in self.f_in.structure:\n",
    "                    if d_in in self.f_out.degrees:\n",
    "                        m_out = self.f_out.structure_dict[d_in]\n",
    "                        W = nn.Parameter(torch.randn(1, m_out, m_in) / np.sqrt(m_in))\n",
    "                        self.kernel_self[f'{d_in}'] = W\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'GConvSE3(structure={self.f_out}, self_interaction={self.self_interaction})'\n",
    "\n",
    "\n",
    "    def udf_u_mul_e(self, d_out):\n",
    "        \"\"\"Compute the convolution for a single output feature type.\n",
    "\n",
    "        This function is set up as a User Defined Function in DGL.\n",
    "\n",
    "        Args:\n",
    "            d_out: output feature type\n",
    "        Returns:\n",
    "            edge -> node function handle\n",
    "        \"\"\"\n",
    "        def fnc(edges):\n",
    "            # Neighbor -> center messages\n",
    "            msg = 0\n",
    "            for m_in, d_in in self.f_in.structure:\n",
    "                src = edges.src[f'{d_in}'].view(-1, m_in*(2*d_in+1), 1)\n",
    "                edge = edges.data[f'({d_in},{d_out})']\n",
    "                msg = msg + torch.matmul(edge, src)\n",
    "            msg = msg.view(msg.shape[0], -1, 2*d_out+1)\n",
    "\n",
    "            # Center -> center messages\n",
    "            if self.self_interaction:\n",
    "                if f'{d_out}' in self.kernel_self.keys():\n",
    "                    if self.flavor == 'TFN':\n",
    "                        W = self.kernel_self[f'{d_out}']\n",
    "                        msg = torch.matmul(W, msg)\n",
    "                    if self.flavor == 'skip':\n",
    "                        dst = edges.dst[f'{d_out}']\n",
    "                        W = self.kernel_self[f'{d_out}']\n",
    "                        msg = msg + torch.matmul(W, dst)\n",
    "\n",
    "            return {'msg': msg.view(msg.shape[0], -1, 2*d_out+1)}\n",
    "        return fnc\n",
    "\n",
    "    @profile\n",
    "    def forward(self, h, G=None, r=None, basis=None, **kwargs):\n",
    "        \"\"\"Forward pass of the linear layer\n",
    "\n",
    "        Args:\n",
    "            G: minibatch of (homo)graphs\n",
    "            h: dict of features\n",
    "            r: inter-atomic distances\n",
    "            basis: pre-computed Q * Y\n",
    "        Returns:\n",
    "            tensor with new features [B, n_points, n_features_out]\n",
    "        \"\"\"\n",
    "        with G.local_scope():\n",
    "            # Add node features to local graph scope\n",
    "            for k, v in h.items():\n",
    "                G.ndata[k] = v\n",
    "\n",
    "            # Add edge features\n",
    "            if 'w' in G.edata.keys():\n",
    "                w = G.edata['w']\n",
    "                feat = torch.cat([w, r], -1)\n",
    "            else:\n",
    "                feat = torch.cat([r, ], -1)\n",
    "\n",
    "            for (mi, di) in self.f_in.structure:\n",
    "                for (mo, do) in self.f_out.structure:\n",
    "                    etype = f'({di},{do})'\n",
    "                    G.edata[etype] = self.kernel_unary[etype](feat, basis)\n",
    "\n",
    "            # Perform message-passing for each output feature type\n",
    "            for d in self.f_out.degrees:\n",
    "                G.update_all(self.udf_u_mul_e(d), fn.mean('msg', f'out{d}'))\n",
    "\n",
    "            return {f'{d}': G.ndata[f'out{d}'] for d in self.f_out.degrees}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f232813b-3c45-4935-9cec-8dd855f9318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5254/2732476931.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.file_address)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train-set, task: homo, source: ./QM9_data/QM9_data.pt, length: 100000\n",
      "MINIBATCH\n",
      "Graph(num_nodes=591, num_edges=10696,\n",
      "      ndata_schemes={'x': Scheme(shape=(3,), dtype=torch.float32), 'f': Scheme(shape=(6, 1), dtype=torch.float32)}\n",
      "      edata_schemes={'d': Scheme(shape=(3,), dtype=torch.float32), 'w': Scheme(shape=(5,), dtype=torch.float32)})\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "leg = {}\n",
    "\n",
    "dataset = QM9Dataset('./QM9_data/QM9_data.pt', \"homo\", mode='train', fully_connected=True)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "\n",
    "iter_dataloader = iter(dataloader) # so I can use next\n",
    "for i in range(1):\n",
    "    data = next(iter_dataloader)\n",
    "    print(\"MINIBATCH\")\n",
    "    print(data[0]) \n",
    "    print(data[1].shape) # batch size -> connected graph of size batch\n",
    "\n",
    "\n",
    "atom_feature_size = dataset.atom_feature_size\n",
    "num_degrees = 4\n",
    "num_channels = 32\n",
    "num_channels_out = num_channels*num_degrees\n",
    "edge_dim = dataset.num_bonds\n",
    "\n",
    "connection = 'skip'\n",
    "\n",
    "# building fibers for input data\n",
    "fibers = {'in': Fiber(1, atom_feature_size),\n",
    "           'mid': Fiber(num_degrees, num_channels),\n",
    "           'out': Fiber(1, num_channels_out)}\n",
    "\n",
    "\n",
    "f_in = fibers['in']\n",
    "f_out = fibers['out']\n",
    "# initialize dgl graph\n",
    "G = copy.deepcopy(dataset[0][0])\n",
    "\n",
    "\n",
    "h = {'0': G.ndata['f']} # type 0 node feature\n",
    "basis, r = get_basis_and_r(G, num_degrees - 1)\n",
    "\n",
    "layer = GConvSE3(f_in = f_in, \n",
    "                 f_out = f_out, \n",
    "                 edge_dim=edge_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9be228c5-4a76-4398-9f1a-aad6bdc3b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mid_new = layer(h, G = G, r = r, basis = basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80f7dd95-a91a-4d24-88e6-1403aa58da60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 128, 1]), tensor(216.5136, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mid_new['0'].shape, f_mid_new['0'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "412b21b7-10c8-464e-adfe-d2143ba869f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 128, 1]), tensor(380.8578, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mid_my['0'].shape, f_mid_my['0'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32de5c14-cd83-480a-8cf6-746c4f9dc0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU test\n",
    "\n",
    "G_cu = G.to(device)\n",
    "\n",
    "h_cu = {'0': G_cu.ndata['f']} # type 0 node feature\n",
    "\n",
    "layer_cu = GConvSE3(f_in = f_in, \n",
    "                 f_out = f_out, \n",
    "                 edge_dim=edge_dim).to(device)\n",
    "\n",
    "basis_cu = {key: basis[key].to(device) for key in basis}\n",
    "r_cu = r.to(device)\n",
    "f_mid_new_cu = layer_cu(h_cu, G = G_cu, r = r_cu, basis = basis_cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db4ced2d-021c-46dd-b301-a6ca0a2ad97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(149.3905, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mid_new_cu['0'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af964ddd-4c30-495b-8101-b0c8b41b5912",
   "metadata": {},
   "source": [
    "## SE3 transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad5a2ae-da4a-4132-b3c0-2d9ded81eee8",
   "metadata": {},
   "source": [
    "### Query embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d9884bd-22c0-4caa-8101-48cc6f99866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(128, 0)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First define the fiber f_mid_in with same multiplicities as value msgs with\n",
    "# structure f_mid_out, \n",
    "# !!! but keep only degrees in input f_in\n",
    "\n",
    "# building fibers for input data\n",
    "fibers = {'in': Fiber(1, atom_feature_size),\n",
    "           'mid': Fiber(num_degrees, num_channels),\n",
    "           'out': Fiber(1, num_channels_out)}\n",
    "\n",
    "\n",
    "f_in = fibers['in']\n",
    "f_out = fibers['out']\n",
    "\n",
    "f_mid_out = copy.deepcopy(f_out).structure_dict\n",
    "\n",
    "f_mid_in = Fiber(dictionary={d: m for d, m in f_mid_out.items() if d in f_in.degrees})\n",
    "\n",
    "f_mid_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9c77ae56-b4a2-41f5-bf2b-83a9daa19517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing weights\n",
    "transform = nn.ParameterDict()\n",
    "# loop through all degrees in f_mid_in\n",
    "for m_mid, d_mid in f_mid_in.structure:\n",
    "    # extract number of input channels of degree d_mid to define\n",
    "    # dimensions of weight matrix\n",
    "    mi = f_in.structure_dict[d_mid]\n",
    "    # initialize m_mid x mi weight matrix with random integers and scale down\n",
    "    transform[str(d_mid)] = nn.Parameter(torch.randn(m_mid, mi) / np.sqrt(mi), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f0634af-da1d-4c8e-b45d-274d30e62044",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = {'0': G.ndata['f']} # type 0 node feature\n",
    "\n",
    "with G.local_scope():\n",
    "    # Add node features to local graph scope\n",
    "    for k, v in h.items():\n",
    "        G.ndata[k] = v\n",
    "\n",
    "    # Add edge features\n",
    "    if 'w' in G.edata.keys():\n",
    "        w = G.edata['w']\n",
    "        feat = torch.cat([w, r], -1)\n",
    "    else:\n",
    "        feat = torch.cat([r, ], -1)\n",
    "\n",
    "    # Perfoming linear self attention transformation\n",
    "    output = {}\n",
    "    # loop through output degrees in features dictionary and extract\n",
    "    # features f\n",
    "    for do, f in h.items():\n",
    "        # check if there is a query matrix corresponding to the degree do\n",
    "        if str(do) in transform.keys():\n",
    "            # calculate the query for every channel of degree do\n",
    "            # output has shape (mo, 2*do + 1)\n",
    "            output[do] = torch.matmul(transform[str(do)], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "557b441b-2fd6-46ee-b0a7-230e287c30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref from the code\n",
    "class G1x1SE3(nn.Module):\n",
    "    \"\"\"Graph Linear SE(3)-equivariant layer, equivalent to a 1x1 convolution.\n",
    "\n",
    "    This is equivalent to a self-interaction layer in TensorField Networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, f_in, f_out, learnable=True):\n",
    "        \"\"\"SE(3)-equivariant 1x1 convolution.\n",
    "\n",
    "        Args:\n",
    "            f_in: input Fiber() of feature multiplicities and types\n",
    "            f_out: output Fiber() of feature multiplicities and types\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "\n",
    "        # Linear mappings: 1 per output feature type\n",
    "        self.transform = nn.ParameterDict()\n",
    "        for m_out, d_out in self.f_out.structure:\n",
    "            m_in = self.f_in.structure_dict[d_out]\n",
    "            self.transform[str(d_out)] = nn.Parameter(torch.randn(m_out, m_in) / np.sqrt(m_in), requires_grad=learnable)\n",
    "\n",
    "    def __repr__(self):\n",
    "         return f\"G1x1SE3(structure={self.f_out})\"\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        output = {}\n",
    "        for k, v in features.items():\n",
    "            if str(k) in self.transform.keys():\n",
    "                output[k] = torch.matmul(self.transform[str(k)], v)\n",
    "        return output\n",
    "\n",
    "# initialize the function for generating the query that projects from f_in to f_mid_in\n",
    "GMAB = {}\n",
    "GMAB['q'] = G1x1SE3(f_in, f_mid_in)\n",
    "\n",
    "q = GMAB['q'](h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58009d3c-9f8b-4a30-ab7d-0447b5b28eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation along channels and moments of features\n",
    "# F: list where each element is an array with shape (m, 2*d + 1) for each feature degree d\n",
    "# assume for now that H = 1 (single attention head)\n",
    "def fiber2head(F, H, structure):\n",
    "    # squeeze each array in the list into a m * (2*d + 1)-dimentional vector \n",
    "    # of all channels concatenated along the last dimention\n",
    "    fibers = [F[f'{d}'].view(*F[f'{d}'].shape[:-2], H, -1) for d in structure.degrees]\n",
    "    # concatenate across the last dimension of every array in the list to get a single vector\n",
    "    fibers = torch.cat(fibers, -1)\n",
    "    return fibers\n",
    "\n",
    "n_heads = 1\n",
    "\n",
    "G.ndata['q'] = fiber2head(q, 1, f_mid_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ba8ab86-2707-4f40-ba09-11d2a423f70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 1, 128])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.ndata['q'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a8f65-df37-4fcc-9572-d5c189d3ea76",
   "metadata": {},
   "source": [
    "### Key embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e08c831-2021-4ebf-a071-d737c5508fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys are same as TFN conv layers but no self interaction and head attention dim is added to comp\n",
    "class GConvSE3Partial(nn.Module):\n",
    "    \"\"\"Graph SE(3)-equivariant node -> edge layer\"\"\"\n",
    "    def __init__(self, f_in, f_out, edge_dim: int=0, x_ij=None):\n",
    "        \"\"\"SE(3)-equivariant partial convolution.\n",
    "\n",
    "        A partial convolution computes the inner product between a kernel and\n",
    "        each input channel, without summing over the result from each input\n",
    "        channel. This unfolded structure makes it amenable to be used for\n",
    "        computing the value-embeddings of the attention mechanism.\n",
    "\n",
    "        Args:\n",
    "            f_in: list of tuples [(multiplicities, type),...]\n",
    "            f_out: list of tuples [(multiplicities, type),...]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_out = f_out\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        # adding/concatinating relative position to feature vectors\n",
    "        # 'cat' concatenates relative position & existing feature vector\n",
    "        # 'add' adds it, but only if multiplicity > 1\n",
    "        assert x_ij in [None, 'cat', 'add']\n",
    "        self.x_ij = x_ij\n",
    "        if x_ij == 'cat':\n",
    "            self.f_in = Fiber.combine(f_in, Fiber(structure=[(1,1)]))\n",
    "        else:\n",
    "            self.f_in = f_in\n",
    "\n",
    "        # Node -> edge weights\n",
    "        self.kernel_unary = nn.ModuleDict()\n",
    "        for (mi, di) in self.f_in.structure:\n",
    "            for (mo, do) in self.f_out.structure:\n",
    "                self.kernel_unary[f'({di},{do})'] = PairwiseConv(di, mi, do, mo, edge_dim=edge_dim)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'GConvSE3Partial(structure={self.f_out})'\n",
    "\n",
    "    def udf_u_mul_e(self, d_out):\n",
    "        \"\"\"Compute the partial convolution for a single output feature type.\n",
    "\n",
    "        This function is set up as a User Defined Function in DGL.\n",
    "\n",
    "        Args:\n",
    "            d_out: output feature type\n",
    "        Returns:\n",
    "            node -> edge function handle\n",
    "        \"\"\"\n",
    "        def fnc(edges):\n",
    "            # Neighbor -> center messages\n",
    "            msg = 0\n",
    "            for m_in, d_in in self.f_in.structure:\n",
    "                # if type 1 and flag set, add relative position as feature\n",
    "                if self.x_ij == 'cat' and d_in == 1:\n",
    "                    # relative positions\n",
    "                    rel = (edges.dst['x'] - edges.src['x']).view(-1, 3, 1)\n",
    "                    m_ori = m_in - 1\n",
    "                    if m_ori == 0:\n",
    "                        # no type 1 input feature, just use relative position\n",
    "                        src = rel\n",
    "                    else:\n",
    "                        # features of src node, shape [edges, m_in*(2l+1), 1]\n",
    "                        src = edges.src[f'{d_in}'].view(-1, m_ori*(2*d_in+1), 1)\n",
    "                        # add to feature vector\n",
    "                        src = torch.cat([src, rel], dim=1)\n",
    "                elif self.x_ij == 'add' and d_in == 1 and m_in > 1:\n",
    "                    src = edges.src[f'{d_in}'].view(-1, m_in*(2*d_in+1), 1)\n",
    "                    rel = (edges.dst['x'] - edges.src['x']).view(-1, 3, 1)\n",
    "                    src[..., :3, :1] = src[..., :3, :1] + rel\n",
    "                else:\n",
    "                    src = edges.src[f'{d_in}'].view(-1, m_in*(2*d_in+1), 1)\n",
    "                edge = edges.data[f'({d_in},{d_out})']\n",
    "                msg = msg + torch.matmul(edge, src)\n",
    "            msg = msg.view(msg.shape[0], -1, 2*d_out+1)\n",
    "\n",
    "            return {f'out{d_out}': msg.view(msg.shape[0], -1, 2*d_out+1)}\n",
    "        return fnc\n",
    "\n",
    "    @profile\n",
    "    def forward(self, h, G=None, r=None, basis=None, **kwargs):\n",
    "        \"\"\"Forward pass of the linear layer\n",
    "\n",
    "        Args:\n",
    "            h: dict of node-features\n",
    "            G: minibatch of (homo)graphs\n",
    "            r: inter-atomic distances\n",
    "            basis: pre-computed Q * Y\n",
    "        Returns:\n",
    "            tensor with new features [B, n_points, n_features_out]\n",
    "        \"\"\"\n",
    "        with G.local_scope():\n",
    "            # Add node features to local graph scope\n",
    "            for k, v in h.items():\n",
    "                G.ndata[k] = v\n",
    "\n",
    "            # Add edge features\n",
    "            if 'w' in G.edata.keys():\n",
    "                w = G.edata['w'] # shape: [#edges_in_batch, #bond_types]\n",
    "                feat = torch.cat([w, r], -1)\n",
    "            else:\n",
    "                feat = torch.cat([r, ], -1)\n",
    "            for (mi, di) in self.f_in.structure:\n",
    "                for (mo, do) in self.f_out.structure:\n",
    "                    etype = f'({di},{do})'\n",
    "                    G.edata[etype] = self.kernel_unary[etype](feat, basis)\n",
    "\n",
    "            # Perform message-passing for each output feature type\n",
    "            for d in self.f_out.degrees:\n",
    "                G.apply_edges(self.udf_u_mul_e(d))\n",
    "\n",
    "            return {f'{d}': G.edata[f'out{d}'] for d in self.f_out.degrees}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2630e701-b2cd-4057-894d-9b0f3d4766eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge dim : used to determine the dim of input (edge_dim + 1) to the radial function\n",
    "# if only radial distance, the edge_dim is 0\n",
    "# x_ij: type-1 displacement vector used as edge feature (more on this later)\n",
    "GMAB['k'] = GConvSE3Partial(f_in, f_mid_in, edge_dim=edge_dim, x_ij = 'cat')\n",
    "\n",
    "k = GMAB['k'](h, G = G, r = r, basis = basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "980d9f6d-23b6-47d9-8b93-6aa5bf2d81e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([210, 1, 128])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the result to edge feature\n",
    "G.edata['k'] = fiber2head(k, n_heads, f_mid_in)\n",
    "\n",
    "G.edata['k'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c92e6",
   "metadata": {},
   "source": [
    "### Calculating attention score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11119245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e_dot_v takes (first tensor, second tensor, output field in edge) for all nodes\n",
    "G.apply_edges(fn.e_dot_v('k', 'q', 'e'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "888265ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure is a list of (multiplicity, degree) tuples\n",
    "n_features = np.sum([m * (2*d+ 1) for (m, d) in f_mid_in.structure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de46404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing attntion score by softmax\n",
    "from dgl.nn.pytorch.softmax import edge_softmax\n",
    "\n",
    "# extract raw attention scores for all edges from edge data\n",
    "e = G.edata.pop('e')\n",
    "# scale down all scores by the dimension of the key embedding\n",
    "e = e / np.sqrt(f_mid_in.n_features)\n",
    "# apply softmax for each set of edges and store attention scores in an\n",
    "# array with shape (edges, heads = 1) labeled 'a' in the edge data\n",
    "G.edata['a'] = edge_softmax(G, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b13eaa",
   "metadata": {},
   "source": [
    "### Value message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81646d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is intermidiate layer that \n",
    "# adds fitting parameters computes the \n",
    "div = 4\n",
    "\n",
    "# extract the multiplicity of each degree in f_out and divide by div\n",
    "# // is the floor division operation\n",
    "f_mid_out = {do: int(mo // div) for do, mo in f_out.structure_dict.items()}\n",
    "\n",
    "f_mid_out = Fiber(dictionary=f_mid_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "963a48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GMAB['v'] = GConvSE3Partial(f_in, f_mid_out, edge_dim=edge_dim, x_ij = 'cat')\n",
    "\n",
    "v = GMAB['v'](h, G = G, r = r, basis = basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd695a",
   "metadata": {},
   "source": [
    "### Multiple heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee6778d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([210, 128, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b761b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce fibers into single tensor cell h (I guess)\n",
    "def fiber2head(F, h, structure, squeeze=False):\n",
    "    if squeeze:\n",
    "        fibers = [F[f'{i}'].view(*F[f'{i}'].shape[:-2], h, -1) for i in structure.degrees]\n",
    "        fibers = torch.cat(fibers, -1)\n",
    "    else:\n",
    "        fibers = [F[f'{i}'].view(*F[f'{i}'].shape[:-2], h, -1, 1) for i in structure.degrees]\n",
    "        fibers = torch.cat(fibers, -2)\n",
    "    return fibers\n",
    "\n",
    "n_heads = 8\n",
    "# reshape key and query into shape (edges, heads, d/H)\n",
    "G.edata['k'] = fiber2head(k, n_heads, f_mid_in, squeeze = True)\n",
    "G.ndata['q'] = fiber2head(q, n_heads, f_mid_in, squeeze = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "44805546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes H dot products for each edge and stores as array \n",
    "# with shape (edges, H) in edge with label 'e'\n",
    "G.apply_edges(fn.e_dot_v('k', 'q', 'e'))\n",
    "\n",
    "# extract raw attention scores for all edges from edge data\n",
    "e = G.edata.pop('e')\n",
    "# scale down all scores by the full dimension of the key embedding\n",
    "e = e / np.sqrt(f_mid_in.n_features)\n",
    "# apply softmax for each set of edges and store attention scores in an\n",
    "# array with shape (edges, heads = 1) labeled 'a' in the edge data\n",
    "G.edata['a'] = edge_softmax(G, e)\n",
    "\n",
    "G.edata['a'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa034180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same stuff for the value\n",
    "for m, d in f_mid_out.structure:\n",
    "    # extract the value embedding for degree d and reshape into\n",
    "    # (edges, H, chnnels per head, 2d+1)\n",
    "    G.edata[f'v{d}'] = v[f'{d}'].view(-1, n_heads, m // n_heads, 2*d + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ccf688ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for scaling values with attention scores\n",
    "def udf_u_mul_e(d):\n",
    "    def fnc(edges):\n",
    "        # extract attention scores from edge data\n",
    "        # shape (edges, H)\n",
    "        attn = edges.data['a']\n",
    "        \n",
    "        # extract value array with shape (edges, H, type do channels per head, 2d + 1)\n",
    "        value = edges.data[f'v{d}']\n",
    "        \n",
    "        \n",
    "        \n",
    "        # reshape attention scores to (edges, H, 1, 1) which will be \n",
    "        # broadcasted to match value array\n",
    "        attn = attn.unsqueeze(-1)#.unsqueeze(-1)\n",
    "        \n",
    "        print(value.shape)\n",
    "        print(attn.shape)\n",
    "        \n",
    "        \n",
    "        # broadcasts attn to have the same shape as value and\n",
    "        # performs element-wise multiplication\n",
    "        # every component of each channel that share the same head index\n",
    "        # will be multiplied by the same attn score\n",
    "        msg = attn * value\n",
    "        # return dict with msg array with shape (edges, H, type do channels per head, 2d + 1) with label 'm'\n",
    "        return {'m':msg}\n",
    "    \n",
    "    return fnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "586d2961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([210, 8, 4, 1])\n",
      "torch.Size([210, 8, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for do in f_out.degrees:\n",
    "    # generates msg and sums over attention heads and edges\n",
    "    G.update_all(udf_u_mul_e(do), fn.sum('m', f'out{do}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dee6be31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 32, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a dict of output degrees and the value arrays\n",
    "# inialize dict\n",
    "output = {}\n",
    "for mo, do in f_out.structure:\n",
    "    # extract weighted messages from node data and add dimension\n",
    "    # to separate channels of the same type\n",
    "    output[f'{do}'] = G.ndata[f'out{do}'].view(-1, mo//4, 2*do + 1)\n",
    "    \n",
    "    \n",
    "output[f'{do}'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc5efe",
   "metadata": {},
   "source": [
    "### Attentive self-interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6cdbfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixing of input and value features\n",
    "\n",
    "# Initialize dictionary of degree: multiplicity key:value pairs\n",
    "f_cat = {}\n",
    "# loop through all degrees in value message fiber\n",
    "for d in f_mid_out.degrees:\n",
    "    # add the multiplicity of type d in value msg fiber to cat\n",
    "    f_cat[d] = f_mid_out.dict[d]\n",
    "    # loop through all degrees in input fiber\n",
    "    if d in f_in.degrees:\n",
    "        # add the multiplicity of type d in input fiber to f_cat\n",
    "        f_cat[d] += f_in.dict[d]\n",
    "# set the instance variable to a fiber with structure f_cat\n",
    "f_cat = Fiber(dictionary=f_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76d22665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward function of GCat module\n",
    "def forward(msg, inpt):\n",
    "    # initialize dictionary of degree: (mcat, 2do + 1) key:value pairs\n",
    "    out = {}\n",
    "    # loop through all degrees in f_cat\n",
    "    for do in f_out.degrees:\n",
    "        do = str(do)\n",
    "        # if degree is in input fiber, concatenate all type-do input and msg\n",
    "        # features along the channel dimension\n",
    "        if do in inpt:\n",
    "            out[do] = torch.cat([inpt[do], msg[do]], 1)\n",
    "        # if degree is not input fiber, just set the features to\n",
    "        # msg features\n",
    "        else:\n",
    "            out[do] = msg[do]\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "81db4ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 38, 1]), torch.Size([15, 6, 1]), torch.Size([15, 32, 1]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = forward(output, h)\n",
    "\n",
    "res['0'].shape, h['0'].shape, output['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b0a66b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 38, 38])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f: array containing all type-l channels with shape\n",
    "# (nodes, mi, 2l + 1)\n",
    "# calculate the dot product of all channel pairs in f and stores\n",
    "# them in scalars\n",
    "# a, b: indexes along the channel axis\n",
    "# c: index along the tensor-component axis\n",
    "# !!! einsum interesting func\n",
    "scalars = torch.einsum('...ac,...bc->...ab', [res['0'], res['0']])\n",
    "\n",
    "\n",
    "scalars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18121b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the square matrix into a vector for each node\n",
    "scalars = scalars.view(scalars.shape[0], scalars.shape[1]*scalars.shape[1])\n",
    "# store the signs of each attention score\n",
    "sign = scalars.sign()\n",
    "# clamps the absolute value of each to a minimum of 1e-12 to prevent\n",
    "# vanishing gradients\n",
    "scalars = scalars.abs_().clamp_min(1e-12)\n",
    "# reapplies the sings to each score\n",
    "scalars *= sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1127b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# constryting FFN to transform\n",
    "# mcat x mcat -> mcat x mo\n",
    "def _build_net(mcat: int, mo: int):\n",
    "    \n",
    "    nonlin = nn.LeakyReLU()\n",
    "    # dimension of hidden layer\n",
    "    n_hidden = mcat * mo\n",
    "    # input dimension\n",
    "    cur_inpt = mcat * mcat\n",
    "    # initialize empty list to store network layers\n",
    "    net = []\n",
    "    # loop to construct num_layers - 1 linear layers\n",
    "    # num_layers defaulted to 2 to construct a single linear layer\n",
    "    num_layers = 2\n",
    "    for i in range(1, num_layers):\n",
    "        # layer normalization of input vector\n",
    "        net.append(nn.LayerNorm(int(cur_inpt)))\n",
    "        # leaky ReLU nonlinearity\n",
    "        net.append(nonlin)\n",
    "        # fully connected layer that transforms input dimension to n_hidden and adds bias\n",
    "        # term only to the last layer\n",
    "        net.append(\n",
    "            nn.Linear(cur_inpt, n_hidden, bias = (i == num_layers - 1))\n",
    "        )\n",
    "        # initializes weights matrix using Kaiming initialization\n",
    "        nn.init.kaiming_uniform_(net[-1].weight)\n",
    "        # sets the input to the next layer to be the output\n",
    "        # dimension of the current layer\n",
    "        cur_inpt = n_hidden\n",
    "        \n",
    "    return nn.Sequential(*net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6d38c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = nn.ModuleDict()\n",
    "# loop through every degree:multiplicity pair in f_cat\n",
    "for do, mcat in f_cat.structure_dict.items():\n",
    "    # extract number of output channels for degree do\n",
    "    mo = f_out.structure_dict[do]\n",
    "    # build FFN with hidden dimension mcat * mo\n",
    "    transform[str(do)] = _build_net(mcat, mo)\n",
    "    \n",
    "# extract the type do FFN feed the raw attn scores in as input\n",
    "att_weights = transform['0'](scalars)\n",
    "# reshape the output vector into a mo x mcat matrix\n",
    "att_weights = att_weights.view(scalars.shape[0], mo, mcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c38fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# apply softmax along the last dimension of the attn weights array of shape\n",
    "# (nodes, mo, mcat)\n",
    "att_weights = F.softmax(input = att_weights, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "399781f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 128, 1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attn_weights has shape (nodes, mo, mcat)\n",
    "# f has shape (nodes, mcat, 2do + 1)\n",
    "# each element of output has shape (nodes, mo, 2do + 1)\n",
    "final_value = torch.einsum('...nm,...md->...nd', [att_weights, res['0']])\n",
    "\n",
    "final_value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc070d",
   "metadata": {},
   "source": [
    "### Final module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6326ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "\n",
    "# ref from the code\n",
    "class G1x1SE3(nn.Module):\n",
    "    \"\"\"Graph Linear SE(3)-equivariant layer, equivalent to a 1x1 convolution.\n",
    "\n",
    "    This is equivalent to a self-interaction layer in TensorField Networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, f_in, f_out, learnable=True):\n",
    "        \"\"\"SE(3)-equivariant 1x1 convolution.\n",
    "\n",
    "        Args:\n",
    "            f_in: input Fiber() of feature multiplicities and types\n",
    "            f_out: output Fiber() of feature multiplicities and types\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "\n",
    "        # Linear mappings: 1 per output feature type\n",
    "        self.transform = nn.ParameterDict()\n",
    "        for m_out, d_out in self.f_out.structure:\n",
    "            m_in = self.f_in.structure_dict[d_out]\n",
    "            self.transform[str(d_out)] = nn.Parameter(torch.randn(m_out, m_in) / np.sqrt(m_in), requires_grad=learnable)\n",
    "\n",
    "    def __repr__(self):\n",
    "         return f\"G1x1SE3(structure={self.f_out})\"\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        output = {}\n",
    "        for k, v in features.items():\n",
    "            if str(k) in self.transform.keys():\n",
    "                output[k] = torch.matmul(self.transform[str(k)], v)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Keys are same as TFN conv layers but no self interaction and head attention dim is added to comp\n",
    "class GConvSE3Partial(nn.Module):\n",
    "    \"\"\"Graph SE(3)-equivariant node -> edge layer\"\"\"\n",
    "    def __init__(self, f_in, f_out, edge_dim: int=0, x_ij=None):\n",
    "        \"\"\"SE(3)-equivariant partial convolution.\n",
    "\n",
    "        A partial convolution computes the inner product between a kernel and\n",
    "        each input channel, without summing over the result from each input\n",
    "        channel. This unfolded structure makes it amenable to be used for\n",
    "        computing the value-embeddings of the attention mechanism.\n",
    "\n",
    "        Args:\n",
    "            f_in: list of tuples [(multiplicities, type),...]\n",
    "            f_out: list of tuples [(multiplicities, type),...]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_out = f_out\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        # adding/concatinating relative position to feature vectors\n",
    "        # 'cat' concatenates relative position & existing feature vector\n",
    "        # 'add' adds it, but only if multiplicity > 1\n",
    "        assert x_ij in [None, 'cat', 'add']\n",
    "        self.x_ij = x_ij\n",
    "        if x_ij == 'cat':\n",
    "            self.f_in = Fiber.combine(f_in, Fiber(structure=[(1,1)]))\n",
    "        else:\n",
    "            self.f_in = f_in\n",
    "\n",
    "        # Node -> edge weights\n",
    "        self.kernel_unary = nn.ModuleDict()\n",
    "        for (mi, di) in self.f_in.structure:\n",
    "            for (mo, do) in self.f_out.structure:\n",
    "                self.kernel_unary[f'({di},{do})'] = PairwiseConv(di, mi, do, mo, edge_dim=edge_dim)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'GConvSE3Partial(structure={self.f_out})'\n",
    "\n",
    "    def udf_u_mul_e(self, d_out):\n",
    "        \"\"\"Compute the partial convolution for a single output feature type.\n",
    "\n",
    "        This function is set up as a User Defined Function in DGL.\n",
    "\n",
    "        Args:\n",
    "            d_out: output feature type\n",
    "        Returns:\n",
    "            node -> edge function handle\n",
    "        \"\"\"\n",
    "        def fnc(edges):\n",
    "            # Neighbor -> center messages\n",
    "            msg = 0\n",
    "            for m_in, d_in in self.f_in.structure:\n",
    "                # if type 1 and flag set, add relative position as feature\n",
    "                if self.x_ij == 'cat' and d_in == 1:\n",
    "                    # relative positions\n",
    "                    rel = (edges.dst['x'] - edges.src['x']).view(-1, 3, 1)\n",
    "                    m_ori = m_in - 1\n",
    "                    if m_ori == 0:\n",
    "                        # no type 1 input feature, just use relative position\n",
    "                        src = rel\n",
    "                    else:\n",
    "                        # features of src node, shape [edges, m_in*(2l+1), 1]\n",
    "                        src = edges.src[f'{d_in}'].view(-1, m_ori*(2*d_in+1), 1)\n",
    "                        # add to feature vector\n",
    "                        src = torch.cat([src, rel], dim=1)\n",
    "                elif self.x_ij == 'add' and d_in == 1 and m_in > 1:\n",
    "                    src = edges.src[f'{d_in}'].view(-1, m_in*(2*d_in+1), 1)\n",
    "                    rel = (edges.dst['x'] - edges.src['x']).view(-1, 3, 1)\n",
    "                    src[..., :3, :1] = src[..., :3, :1] + rel\n",
    "                else:\n",
    "                    src = edges.src[f'{d_in}'].view(-1, m_in*(2*d_in+1), 1)\n",
    "                edge = edges.data[f'({d_in},{d_out})']\n",
    "                msg = msg + torch.matmul(edge, src)\n",
    "            msg = msg.view(msg.shape[0], -1, 2*d_out+1)\n",
    "\n",
    "            return {f'out{d_out}': msg.view(msg.shape[0], -1, 2*d_out+1)}\n",
    "        return fnc\n",
    "\n",
    "    @profile\n",
    "    def forward(self, h, G=None, r=None, basis=None, **kwargs):\n",
    "        \"\"\"Forward pass of the linear layer\n",
    "\n",
    "        Args:\n",
    "            h: dict of node-features\n",
    "            G: minibatch of (homo)graphs\n",
    "            r: inter-atomic distances\n",
    "            basis: pre-computed Q * Y\n",
    "        Returns:\n",
    "            tensor with new features [B, n_points, n_features_out]\n",
    "        \"\"\"\n",
    "        with G.local_scope():\n",
    "            # Add node features to local graph scope\n",
    "            for k, v in h.items():\n",
    "                G.ndata[k] = v\n",
    "\n",
    "            # Add edge features\n",
    "            if 'w' in G.edata.keys():\n",
    "                w = G.edata['w'] # shape: [#edges_in_batch, #bond_types]\n",
    "                feat = torch.cat([w, r], -1)\n",
    "            else:\n",
    "                feat = torch.cat([r, ], -1)\n",
    "            for (mi, di) in self.f_in.structure:\n",
    "                for (mo, do) in self.f_out.structure:\n",
    "                    etype = f'({di},{do})'\n",
    "                    G.edata[etype] = self.kernel_unary[etype](feat, basis)\n",
    "\n",
    "            # Perform message-passing for each output feature type\n",
    "            for d in self.f_out.degrees:\n",
    "                G.apply_edges(self.udf_u_mul_e(d))\n",
    "\n",
    "            return {f'{d}': G.edata[f'out{d}'] for d in self.f_out.degrees}\n",
    "        \n",
    "        \n",
    "class GMABSE3(nn.Module):\n",
    "    \"\"\"An SE(3)-equivariant multi-headed self-attention module for DGL graphs.\"\"\"\n",
    "    def __init__(self, f_value: Fiber, f_key: Fiber, n_heads: int):\n",
    "        \"\"\"SE(3)-equivariant MAB (multi-headed attention block) layer.\n",
    "\n",
    "        Args:\n",
    "            f_value: Fiber() object for value-embeddings\n",
    "            f_key: Fiber() object for key-embeddings\n",
    "            n_heads: number of heads\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_value = f_value\n",
    "        self.f_key = f_key\n",
    "        self.n_heads = n_heads\n",
    "        self.new_dgl = version.parse(dgl.__version__) > version.parse('0.4.4')\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'GMABSE3(n_heads={self.n_heads}, structure={self.f_value})'\n",
    "\n",
    "    def udf_u_mul_e(self, d_out):\n",
    "        \"\"\"Compute the weighted sum for a single output feature type.\n",
    "\n",
    "        This function is set up as a User Defined Function in DGL.\n",
    "\n",
    "        Args:\n",
    "            d_out: output feature type\n",
    "        Returns:\n",
    "            edge -> node function handle\n",
    "        \"\"\"\n",
    "        def fnc(edges):\n",
    "            # Neighbor -> center messages\n",
    "            attn = edges.data['a']\n",
    "            value = edges.data[f'v{d_out}']\n",
    "\n",
    "            # Apply attention weights\n",
    "            msg = attn.unsqueeze(-1).unsqueeze(-1) * value\n",
    "\n",
    "            return {'m': msg}\n",
    "        return fnc\n",
    "\n",
    "    @profile\n",
    "    def forward(self, v, k: Dict=None, q: Dict=None, G=None, **kwargs):\n",
    "        \"\"\"Forward pass of the linear layer\n",
    "\n",
    "        Args:\n",
    "            G: minibatch of (homo)graphs\n",
    "            v: dict of value edge-features\n",
    "            k: dict of key edge-features\n",
    "            q: dict of query node-features\n",
    "        Returns:\n",
    "            tensor with new features [B, n_points, n_features_out]\n",
    "        \"\"\"\n",
    "        with G.local_scope():\n",
    "            # Add node features to local graph scope\n",
    "            ## We use the stacked tensor representation for attention\n",
    "            for m, d in self.f_value.structure:\n",
    "                G.edata[f'v{d}'] = v[f'{d}'].view(-1, self.n_heads, m//self.n_heads, 2*d+1)\n",
    "            G.edata['k'] = fiber2head(k, self.n_heads, self.f_key, squeeze=True) # [edges, heads, channels](?)\n",
    "            G.ndata['q'] = fiber2head(q, self.n_heads, self.f_key, squeeze=True) # [nodes, heads, channels](?)\n",
    "\n",
    "            # Compute attention weights\n",
    "            ## Inner product between (key) neighborhood and (query) center\n",
    "            G.apply_edges(fn.e_dot_v('k', 'q', 'e'))\n",
    "\n",
    "            ## Apply softmax\n",
    "            e = G.edata.pop('e')\n",
    "            if self.new_dgl:\n",
    "                # in dgl 5.3, e has an extra dimension compared to dgl 4.3\n",
    "                # the following, we get rid of this be reshaping\n",
    "                n_edges = G.edata['k'].shape[0]\n",
    "                e = e.view([n_edges, self.n_heads])\n",
    "            e = e / np.sqrt(self.f_key.n_features)\n",
    "            G.edata['a'] = edge_softmax(G, e)\n",
    "\n",
    "            # Perform attention-weighted message-passing\n",
    "            for d in self.f_value.degrees:\n",
    "                G.update_all(self.udf_u_mul_e(d), fn.sum('m', f'out{d}'))\n",
    "\n",
    "            output = {}\n",
    "            for m, d in self.f_value.structure:\n",
    "                output[f'{d}'] = G.ndata[f'out{d}'].view(-1, m, 2*d+1)\n",
    "\n",
    "            return output\n",
    "        \n",
    "class GCat(nn.Module):\n",
    "    \"\"\"Concat only degrees which are in f_x\"\"\"\n",
    "    def __init__(self, f_x: Fiber, f_y: Fiber):\n",
    "        super().__init__()\n",
    "        self.f_x = f_x\n",
    "        self.f_y = f_y\n",
    "        f_out = {}\n",
    "        for k in f_x.degrees:\n",
    "            f_out[k] = f_x.dict[k]\n",
    "            if k in f_y.degrees:\n",
    "                f_out[k] += f_y.dict[k]\n",
    "        self.f_out = Fiber(dictionary=f_out)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"GCat(structure={self.f_out})\"\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = {}\n",
    "        for k in self.f_out.degrees:\n",
    "            k = str(k)\n",
    "            if k in y:\n",
    "                out[k] = torch.cat([x[k], y[k]], 1)\n",
    "            else:\n",
    "                out[k] = x[k]\n",
    "        return out\n",
    "    \n",
    "class GAttentiveSelfInt(nn.Module):\n",
    "\n",
    "    def __init__(self, f_in, f_out):\n",
    "        \"\"\"SE(3)-equivariant 1x1 convolution.\n",
    "\n",
    "        Args:\n",
    "            f_in: input Fiber() of feature multiplicities and types\n",
    "            f_out: output Fiber() of feature multiplicities and types\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "        self.nonlin = nn.LeakyReLU()\n",
    "        self.num_layers = 2\n",
    "        self.eps = 1e-12 # regularisation for phase: gradients explode otherwise\n",
    "\n",
    "        # one network for attention weights per degree\n",
    "        self.transform = nn.ModuleDict()\n",
    "        for o, m_in in self.f_in.structure_dict.items():\n",
    "            m_out = self.f_out.structure_dict[o]\n",
    "            self.transform[str(o)] = self._build_net(m_in, m_out)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"AttentiveSelfInteractionSE3(in={self.f_in}, out={self.f_out})\"\n",
    "\n",
    "    def _build_net(self, m_in: int, m_out):\n",
    "        n_hidden = m_in * m_out\n",
    "        cur_inpt = m_in * m_in\n",
    "        net = []\n",
    "        for i in range(1, self.num_layers):\n",
    "            net.append(nn.LayerNorm(int(cur_inpt)))\n",
    "            net.append(self.nonlin)\n",
    "            # TODO: implement cleaner init\n",
    "            net.append(\n",
    "                nn.Linear(cur_inpt, n_hidden, bias=(i == self.num_layers - 1)))\n",
    "            nn.init.kaiming_uniform_(net[-1].weight)\n",
    "            cur_inpt = n_hidden\n",
    "        return nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        output = {}\n",
    "        for k, v in features.items():\n",
    "            # v shape: [..., m, 2*k+1]\n",
    "            first_dims = v.shape[:-2]\n",
    "            m_in  = self.f_in.structure_dict[int(k)]\n",
    "            m_out = self.f_out.structure_dict[int(k)]\n",
    "            assert v.shape[-2] == m_in\n",
    "            assert v.shape[-1] == 2 * int(k) + 1\n",
    "\n",
    "            # Compute the norms and normalized features\n",
    "            #norm = v.norm(p=2, dim=-1, keepdim=True).clamp_min(self.eps).expand_as(v)\n",
    "            #phase = v / norm # [..., m, 2*k+1]\n",
    "            scalars = torch.einsum('...ac,...bc->...ab', [v, v]) # [..., m_in, m_in]\n",
    "            scalars = scalars.view(*first_dims, m_in*m_in) # [..., m_in*m_in]\n",
    "            sign = scalars.sign()\n",
    "            scalars = scalars.abs_().clamp_min(self.eps)\n",
    "            scalars *= sign\n",
    "\n",
    "            # perform attention\n",
    "            att_weights = self.transform[str(k)](scalars) # [..., m_out*m_in]\n",
    "            att_weights = att_weights.view(*first_dims, m_out, m_in) # [..., m_out, m_in]\n",
    "            att_weights = F.softmax(input=att_weights, dim=-1)\n",
    "            # shape [..., m_out, 2*k+1]\n",
    "            # output[k] = torch.einsum('...nm,...md->...nd', [att_weights, phase])\n",
    "            output[k] = torch.einsum('...nm,...md->...nd', [att_weights, v])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "88215383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5254/2732476931.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.file_address)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train-set, task: homo, source: ./QM9_data/QM9_data.pt, length: 100000\n",
      "MINIBATCH\n",
      "Graph(num_nodes=591, num_edges=10696,\n",
      "      ndata_schemes={'x': Scheme(shape=(3,), dtype=torch.float32), 'f': Scheme(shape=(6, 1), dtype=torch.float32)}\n",
      "      edata_schemes={'d': Scheme(shape=(3,), dtype=torch.float32), 'w': Scheme(shape=(5,), dtype=torch.float32)})\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "leg = {}\n",
    "\n",
    "dataset = QM9Dataset('./QM9_data/QM9_data.pt', \"homo\", mode='train', fully_connected=True)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "\n",
    "iter_dataloader = iter(dataloader) # so I can use next\n",
    "for i in range(1):\n",
    "    data = next(iter_dataloader)\n",
    "    print(\"MINIBATCH\")\n",
    "    print(data[0]) \n",
    "    print(data[1].shape) # batch size -> connected graph of size batch\n",
    "\n",
    "\n",
    "atom_feature_size = dataset.atom_feature_size\n",
    "num_degrees = 4\n",
    "num_channels = 32\n",
    "num_channels_out = num_channels*num_degrees\n",
    "edge_dim = dataset.num_bonds\n",
    "\n",
    "\n",
    "x_ij = 'cat'\n",
    "connection = 'skip'\n",
    "\n",
    "# building fibers for input data\n",
    "fibers = {'in': Fiber(1, atom_feature_size),\n",
    "           'mid': Fiber(num_degrees, num_channels),\n",
    "           'out': Fiber(1, num_channels_out)}\n",
    "\n",
    "\n",
    "f_in = fibers['in']\n",
    "f_out = fibers['out']\n",
    "# initialize dgl graph\n",
    "G = copy.deepcopy(dataset[0][0])\n",
    "\n",
    "\n",
    "h = {'0': G.ndata['f']} # type 0 node feature\n",
    "basis, r = get_basis_and_r(G, num_degrees - 1)\n",
    "\n",
    "n_heads = 8\n",
    "\n",
    "# there is intermidiate layer that \n",
    "# adds fitting parameters computes the \n",
    "div = 4\n",
    "\n",
    "# extract the multiplicity of each degree in f_out and divide by div\n",
    "# // is the floor division operation\n",
    "f_mid_out = {do: int(mo // div) for do, mo in f_out.structure_dict.items()}\n",
    "\n",
    "f_mid_out = Fiber(dictionary=f_mid_out)\n",
    "\n",
    "f_mid_in = Fiber(dictionary={d: m for d, m in f_mid_out.structure_dict.items() if d in f_in.degrees})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "82e1b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# in consturctor\n",
    "# initialize dictionary of attention modules\n",
    "GMAB = nn.ModuleDict()\n",
    "\n",
    "# modules for computing query, key, value embedding\n",
    "GMAB['v'] = GConvSE3Partial(f_in, f_mid_out, edge_dim = edge_dim, x_ij = x_ij)\n",
    "GMAB['k'] = GConvSE3Partial(f_in, f_mid_in, edge_dim = edge_dim, x_ij = x_ij)\n",
    "GMAB['q'] = G1x1SE3(f_in, f_mid_in)\n",
    "\n",
    "# module for attention with value fiber set to f_mid_out and key and query fiber set to f_mid_in\n",
    "GMAB['attn'] = GMABSE3(f_mid_out, f_mid_in, n_heads = n_heads)\n",
    "# define cat function to concatenate value fiber and input fiber\n",
    "cat = GCat(f_mid_out, f_in)\n",
    "# define project function to project f_cat to f_out with attentive self-interaction\n",
    "project = GAttentiveSelfInt(cat.f_out, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ae98a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(features, G, **kwargs):\n",
    "    # generate queries, keys, and values for all nodes and edges in G\n",
    "    v = GMAB['v'](features, G = G, **kwargs)\n",
    "    k = GMAB['k'](features, G = G, **kwargs)\n",
    "    q = GMAB['q'](features, G = G)\n",
    "    \n",
    "    # calculate attention value message\n",
    "    z = GMAB['attn'](v, k = k, q = q, G = G)\n",
    "    # concatenate the value message to the input features\n",
    "    z = cat(z, features)\n",
    "    # project concatenated messages to f_out\n",
    "    z = project(z)\n",
    "    \n",
    "    # return a dictionary with output degrees as labels linked to an array of the output\n",
    "    # feature tensor for every node in the graph with shape (nodes, mo, 2do + 1)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "70a112b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 128, 1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2 = forward(h, G = G, r = r, basis = basis)\n",
    "\n",
    "h2['0'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07749c5-2760-4bfa-a202-70fe63aa2b35",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b6ea4743-adff-4b4e-b7c3-043f0455aae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 128, 1])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f: array of type-l features with shape (mo, 2l + 1)\n",
    "# self.eps: small constant 1e-12 to avoid division by 0\n",
    "# clamps the norm values to a min value 1e-12 and then expands the norm \n",
    "# value across the last dimension of f \n",
    "eps = 1e-12\n",
    "\n",
    "norm = h2['0'].norm(2, -1, keepdim = True).clamp_min(eps).expand_as(h2['0'])\n",
    "\n",
    "norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "86679a99-8814-444e-b130-2d8ce2c8fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unit length features\n",
    "h2['0'] = h2['0'] / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "405441a6-ce3b-48bd-b23b-cf38a3aa659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming norms with FFN\n",
    "def _build_net(mo: int):\n",
    "    nonlin = nn.ReLU()\n",
    "    net = []\n",
    "    # if num_layers > 1 construct FFN with linear layers\n",
    "    num_layers = 2\n",
    "    for i in range(num_layers):\n",
    "        # normalize the norms across all channels of the same type\n",
    "        net.append(BN(int(mo)))\n",
    "        # ReLU nonlinearity\n",
    "        net.append(nonlin)\n",
    "        # linear layer with input and output dim set to mo\n",
    "        net.append(nn.Linear(mo, mo, bias = (i == num_layers - 1)))\n",
    "        nn.init.kaiming_uniform_(net[-1].weight)\n",
    "\n",
    "    # if num_layers = 0 construct FFN with only normalization and ReLU\n",
    "    # step\n",
    "    if num_layers == 0:\n",
    "        net.append(BN(int(mo)))\n",
    "        net.append(nonlin)\n",
    "    return nn.Sequential(*net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3fe85e1e-7af1-4835-bc42-d821d6f9003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = nn.ModuleDict()\n",
    "for mo, do in f_out.structure:\n",
    "    transform[str(do)] = _build_net(int(mo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1b1a4558-f0dc-4764-bdde-c5030a6d1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm[..., 0] converts the expanded norms back to a single vector \n",
    "# call transform function on the vector of norms and adda a singleton dim\n",
    "transformed = transform[str(do)](norm[..., 0]).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f188de16-0060-4483-b88c-b807e2fc13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcast transformed weights to have shape (mo, 2l + 1) and \n",
    "# multiply elementwise with normalized features\n",
    "h3 = {}\n",
    "h3[do] = (transformed * h2[str(do)]).view(*h2[str(do)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e170b0-c8da-4d7d-a8c6-64dc294d6819",
   "metadata": {},
   "source": [
    "### Incorporating edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5aebb880-939c-4576-89a8-12ae29960b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract type-0 features from edge data\n",
    "w = G.edata['w']\n",
    "# concatenate it with the radial distance along the last dimension\n",
    "# to form a vector of type-0 edge feature\n",
    "feat = torch.cat([w, r], -1)\n",
    "\n",
    "# use feat as input to radial functions to generate \n",
    "# weight kernels for each input and output degree pair\n",
    "for (mi, di) in f_in.structure:\n",
    "    for (mo, do) in f_out.structure:\n",
    "        etype = f'({di},{do})'\n",
    "        # this line generates a kernel using the radial function\n",
    "        # that takes feat as input\n",
    "        G.edata[etype] = kernel_unary[etype](feat, basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d5199c51-bb5d-4cff-8c62-271cd9831af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 0)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ad2f7349-f0ea-4d72-a44c-f63515f8cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in consturctor\n",
    "# adding/concatinating relative position input fiber to generate key/value embedding\n",
    "# 'cat' concatenates ralative position & existing feature vector\n",
    "# 'add' adds relative position to, but only if multiplicity is at least 1\n",
    "assert x_ij in [None, 'cat', 'add']\n",
    "x_ij = x_ij\n",
    "if x_ij == 'cat':\n",
    "    # increments the multiplicity of degree 1 in the input fiber by 1\n",
    "    # to account for type-1 relative position\n",
    "    f_in = Fiber.combine(f_in, Fiber(structure=[(1, 1)]))\n",
    "else:\n",
    "    f_in = f_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "68f372dd-c5a1-45b3-8862-20d43cdf6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in udf that generates the key and value arrays for a single output degree do\n",
    "def fnc(edges):\n",
    "    # neighbor -> center messages\n",
    "    msg = 0\n",
    "    # loop through all input degrees in the input fiber\n",
    "    for mi, di in f_in.structure:\n",
    "        # execute when loop reaches degree 1 and the flag is set to 'cat'\n",
    "        if x_ij == 'cat' and d_in == 1:\n",
    "            # calculate type-1 relative position vector between source and distination node\n",
    "            rel = (edges.dst['x'] - edges.src['x']).view(-1, 3, 1)\n",
    "            # since the multiplicity of degree 1 is incremented in the constructor, m_ori is the original num of type-1 channels\n",
    "            m_ori = mi - 1\n",
    "            if m_ori == 0:\n",
    "                # if there are no type-1 channels, just use relative position\n",
    "                src = rel\n",
    "            else:\n",
    "                # if other type-1 channels exist in source node concatenate rel to channels\n",
    "                # stack all channels into a single dimenstion\n",
    "                src = edges.src[f'{d_in}'].view(-1, m_ori*(2*di + 1), 1)\n",
    "                # concatenate the relative position vector to type-1 channels\n",
    "                src = torch.cat([src, rel], dim = 1)\n",
    "        # executes if flag is set to 'add' and at least 1 type-1 feature\n",
    "        elif x_ij == 'add' and d_in == 1 and m_in > 1:\n",
    "            src = edges.src[f'{d_in}'].view(-1, m_in * (2 * d_in + 1), 1)\n",
    "            # calculate relative position and reshape to (3, 1)\n",
    "            rel = (edges.dst['x'] - edges.src['x']).view(-1, 3, 1)\n",
    "            # add to the first type-1 feature at source node\n",
    "            # :3, :1 adds to the first three elements of the second last dim and first of the last dim\n",
    "            src[..., :3, :1] = src[..., :3, :1] + rel\n",
    "        else:\n",
    "            src = edges.src[f'{d_in}'].view(-1, m_in * (2 * d_in + 1), 1)\n",
    "        # extract key or value kernel that transforms types di to do\n",
    "        edge = edges.data[f'({di},{do})']\n",
    "        # multiply kernel with shape (do * mo, 2*do + 1) with the all input\n",
    "        # features of degree do of shape (mi * (2 * di + 1), 1)\n",
    "        msg = msg + torch.matmul(edge, src)\n",
    "    msg = msg.view(msg.shape[0], -1, 2*do + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643f1340-773b-4474-ac94-be927e9edd71",
   "metadata": {},
   "source": [
    "## Chemical property prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d188962-3ef2-426c-891f-7a40a14f120f",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a62497a-3086-4f37-9515-f213b02f21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch.glob import MaxPooling\n",
    "# computing attntion score by softmax\n",
    "from dgl.nn.pytorch.softmax import edge_softmax\n",
    "\n",
    "class GMaxPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = MaxPooling()\n",
    "\n",
    "    @profile\n",
    "    def forward(self, features, G, **kwargs):\n",
    "        # extracts the type-0 feature in the graph reshapes into an array\n",
    "        # with shape (nodes, type-0 channels)\n",
    "        h = features['0'][..., -1]\n",
    "        # returns the maximum scalar across nodes for each type-0\n",
    "        # channel\n",
    "        return self.pool(G, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f01fcd8c-5a33-4156-b32c-d53e811e235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def get_basis(G, max_degree, compute_gradients):\n",
    "    \"\"\"Precompute the SE(3)-equivariant weight basis, W_J^lk(x)\n",
    "\n",
    "    This is called by get_basis_and_r().\n",
    "\n",
    "    Args:\n",
    "        G: DGL graph instance of type dgl.DGLGraph\n",
    "        max_degree: non-negative int for degree of highest feature type\n",
    "        compute_gradients: boolean, whether to compute gradients during basis construction\n",
    "    Returns:\n",
    "        dict of equivariant bases. Keys are in the form 'd_in,d_out'. Values are\n",
    "        tensors of shape (batch_size, 1, 2*d_out+1, 1, 2*d_in+1, number_of_bases)\n",
    "        where the 1's will later be broadcast to the number of output and input\n",
    "        channels\n",
    "    \"\"\"\n",
    "    if compute_gradients:\n",
    "        context = nullcontext()\n",
    "    else:\n",
    "        context = torch.no_grad()\n",
    "\n",
    "    with context:\n",
    "        cloned_d = torch.clone(G.edata['d'])\n",
    "\n",
    "        if G.edata['d'].requires_grad:\n",
    "            cloned_d.requires_grad_()\n",
    "            log_gradient_norm(cloned_d, 'Basis computation flow')\n",
    "\n",
    "        # Relative positional encodings (vector)\n",
    "        r_ij = get_spherical_from_cartesian_torch(cloned_d)\n",
    "        # Spherical harmonic basis\n",
    "        Y = precompute_sh(r_ij, 2*max_degree)\n",
    "        device = Y[0].device\n",
    "\n",
    "        basis = {}\n",
    "        for d_in in range(max_degree+1):\n",
    "            for d_out in range(max_degree+1):\n",
    "                K_Js = []\n",
    "                for J in range(abs(d_in-d_out), d_in+d_out+1):\n",
    "                    # Get spherical harmonic projection matrices\n",
    "                    Q_J = _basis_transformation_Q_J(J, d_in, d_out)\n",
    "                    Q_J = Q_J.float().T.to(device)\n",
    "\n",
    "                    # Create kernel from spherical harmonics\n",
    "                    K_J = torch.matmul(Y[J], Q_J)\n",
    "                    K_Js.append(K_J)\n",
    "\n",
    "                # Reshape so can take linear combinations with a dot product\n",
    "                size = (-1, 1, 2*d_out+1, 1, 2*d_in+1, 2*min(d_in, d_out)+1)\n",
    "                basis[f'{d_in},{d_out}'] = torch.stack(K_Js, -1).view(*size)\n",
    "        return basis\n",
    "\n",
    "\n",
    "def get_r(G):\n",
    "    \"\"\"Compute internodal distances\"\"\"\n",
    "    cloned_d = torch.clone(G.edata['d'])\n",
    "\n",
    "    if G.edata['d'].requires_grad:\n",
    "        cloned_d.requires_grad_()\n",
    "        log_gradient_norm(cloned_d, 'Neural networks flow')\n",
    "\n",
    "    return torch.sqrt(torch.sum(cloned_d**2, -1, keepdim=True))\n",
    "\n",
    "\n",
    "def get_basis_and_r(G, max_degree, compute_gradients=False):\n",
    "    \"\"\"Return equivariant weight basis (basis) and internodal distances (r).\n",
    "\n",
    "    Call this function *once* at the start of each forward pass of the model.\n",
    "    It computes the equivariant weight basis, W_J^lk(x), and internodal\n",
    "    distances, needed to compute varphi_J^lk(x), of eqn 8 of\n",
    "    https://arxiv.org/pdf/2006.10503.pdf. The return values of this function\n",
    "    can be shared as input across all SE(3)-Transformer layers in a model.\n",
    "\n",
    "    Args:\n",
    "        G: DGL graph instance of type dgl.DGLGraph()\n",
    "        max_degree: non-negative int for degree of highest feature-type\n",
    "        compute_gradients: controls whether to compute gradients during basis construction\n",
    "    Returns:\n",
    "        dict of equivariant bases, keys are in form '<d_in><d_out>'\n",
    "        vector of relative distances, ordered according to edge ordering of G\n",
    "    \"\"\"\n",
    "    basis = get_basis(G, max_degree, compute_gradients)\n",
    "    r = get_r(G)\n",
    "    return basis, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f23fdc85-af6a-4fe9-b67c-2e52b7e61a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.utils_profiling import * # load before other local modules\n",
    "try:\n",
    "    profile\n",
    "except NameError:\n",
    "    def profile(func):\n",
    "        return func\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "class Fiber(object):\n",
    "    \"\"\"A Handy Data Structure for Fibers\"\"\"\n",
    "    def __init__(self, num_degrees: int=None, num_channels: int=None,\n",
    "                 structure: List[Tuple[int,int]]=None, dictionary=None):\n",
    "        \"\"\"\n",
    "        define fiber structure; use one num_degrees & num_channels OR structure\n",
    "        OR dictionary\n",
    "\n",
    "        :param num_degrees: degrees will be [0, ..., num_degrees-1]\n",
    "        :param num_channels: number of channels, same for each degree\n",
    "        :param structure: e.g. [(32, 0),(16, 1),(16,2)]\n",
    "        :param dictionary: e.g. {0:32, 1:16, 2:16}\n",
    "        \n",
    "        Structure in the form: List[(Tuple[int, int])]. In particular Features[(num_channels, feature_degree)]\n",
    "        \"\"\"\n",
    "        \n",
    "        if structure:\n",
    "            self.structure = structure\n",
    "        elif dictionary:\n",
    "            self.structure = [(dictionary[o], o) for o in sorted(dictionary.keys())]\n",
    "        else:\n",
    "            self.structure = [(num_channels, i) for i in range(num_degrees)]\n",
    "\n",
    "            \n",
    "        # assigning to dict format and computing cummulative variables\n",
    "        self.multiplicities, self.degrees = zip(*self.structure)\n",
    "        self.max_degree = max(self.degrees)\n",
    "        self.min_degree = min(self.degrees)\n",
    "        self.structure_dict = {k: v for v, k in self.structure}\n",
    "        self.dict = self.structure_dict\n",
    "        self.n_features = np.sum([i[0] * (2*i[1]+1) for i in self.structure])\n",
    "\n",
    "        \n",
    "        # Mapping to vec() case. f = [...] with starting ind saved in feature ind dict\n",
    "        # feature_ind = {degree: starting ind}\n",
    "        self.feature_indices = {}\n",
    "        idx = 0\n",
    "        for (num_channels, d) in self.structure:\n",
    "            length = num_channels * (2*d + 1)\n",
    "            self.feature_indices[d] = (idx, idx + length)\n",
    "            idx += length\n",
    "\n",
    "    def copy_me(self, multiplicity: int=None):\n",
    "        s = copy.deepcopy(self.structure)\n",
    "        if multiplicity is not None:\n",
    "            # overwrite multiplicities\n",
    "            s = [(multiplicity, o) for m, o in s]\n",
    "        return Fiber(structure=s)\n",
    "\n",
    "    @staticmethod\n",
    "    def combine(f1, f2):\n",
    "        new_dict = copy.deepcopy(f1.structure_dict)\n",
    "        for k, m in f2.structure_dict.items():\n",
    "            if k in new_dict.keys():\n",
    "                new_dict[k] += m\n",
    "            else:\n",
    "                new_dict[k] = m\n",
    "        structure = [(new_dict[k], k) for k in sorted(new_dict.keys())]\n",
    "        return Fiber(structure=structure)\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_max(f1, f2):\n",
    "        new_dict = copy.deepcopy(f1.structure_dict)\n",
    "        for k, m in f2.structure_dict.items():\n",
    "            if k in new_dict.keys():\n",
    "                new_dict[k] = max(m, new_dict[k])\n",
    "            else:\n",
    "                new_dict[k] = m\n",
    "        structure = [(new_dict[k], k) for k in sorted(new_dict.keys())]\n",
    "        return Fiber(structure=structure)\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_selectively(f1, f2):\n",
    "        # only use orders which occur in fiber f1\n",
    "\n",
    "        new_dict = copy.deepcopy(f1.structure_dict)\n",
    "        for k in f1.degrees:\n",
    "            if k in f2.degrees:\n",
    "                new_dict[k] += f2.structure_dict[k]\n",
    "        structure = [(new_dict[k], k) for k in sorted(new_dict.keys())]\n",
    "        return Fiber(structure=structure)\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_fibers(val1, struc1, val2, struc2):\n",
    "        \"\"\"\n",
    "        combine two fibers\n",
    "\n",
    "        :param val1/2: fiber tensors in dictionary form\n",
    "        :param struc1/2: structure of fiber\n",
    "        :return: fiber tensor in dictionary form\n",
    "        \"\"\"\n",
    "        struc_out = Fiber.combine(struc1, struc2)\n",
    "        val_out = {}\n",
    "        for k in struc_out.degrees:\n",
    "            if k in struc1.degrees:\n",
    "                if k in struc2.degrees:\n",
    "                    val_out[k] = torch.cat([val1[k], val2[k]], -2)\n",
    "                else:\n",
    "                    val_out[k] = val1[k]\n",
    "            else:\n",
    "                val_out[k] = val2[k]\n",
    "                \n",
    "            # number of channels is the second dimenstion from the end I guess\n",
    "            # might look like [tensor_axis = degree, channel axis, tensor-component axis]\n",
    "            assert val_out[k].shape[-2] == struc_out.structure_dict[k]\n",
    "        return val_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.structure}\"\n",
    "\n",
    "\n",
    "\n",
    "def get_fiber_dict(F, struc, mask=None, return_struc=False):\n",
    "    if mask is None: mask = struc\n",
    "    index = 0\n",
    "    fiber_dict = {}\n",
    "    first_dims = F.shape[:-1]\n",
    "    masked_dict = {}\n",
    "    for o, m in struc.structure_dict.items():\n",
    "        length = m * (2*o + 1)\n",
    "        if o in mask.degrees:\n",
    "            masked_dict[o] = m\n",
    "            fiber_dict[o] = F[...,index:index + length].view(list(first_dims) + [m, 2*o + 1])\n",
    "        index += length\n",
    "    assert F.shape[-1] == index\n",
    "    if return_struc:\n",
    "        return fiber_dict, Fiber(dictionary=masked_dict)\n",
    "    return fiber_dict\n",
    "\n",
    "\n",
    "def get_fiber_tensor(F, struc):\n",
    "    some_entry = tuple(F.values())[0]\n",
    "    first_dims = some_entry.shape[:-2]\n",
    "    res = some_entry.new_empty([*first_dims, struc.n_features])\n",
    "    index = 0\n",
    "    for o, m in struc.structure_dict.items():\n",
    "        length = m * (2*o + 1)\n",
    "        res[..., index: index + length] = F[o].view(*first_dims, length)\n",
    "        index += length\n",
    "    assert index == res.shape[-1]\n",
    "    return res\n",
    "\n",
    "\n",
    "def fiber2tensor(F, structure, squeeze=False):\n",
    "    if squeeze:\n",
    "        fibers = [F[f'{i}'].view(*F[f'{i}'].shape[:-2], -1) for i in structure.degrees]\n",
    "        fibers = torch.cat(fibers, -1)\n",
    "    else:\n",
    "        fibers = [F[f'{i}'].view(*F[f'{i}'].shape[:-2], -1, 1) for i in structure.degrees]\n",
    "        fibers = torch.cat(fibers, -2)\n",
    "    return fibers\n",
    "\n",
    "\n",
    "# Reduce fibers into single tensor cell h (I guess)\n",
    "def fiber2head(F, h, structure, squeeze=False):\n",
    "    if squeeze:\n",
    "        fibers = [F[f'{i}'].view(*F[f'{i}'].shape[:-2], h, -1) for i in structure.degrees]\n",
    "        fibers = torch.cat(fibers, -1)\n",
    "    else:\n",
    "        fibers = [F[f'{i}'].view(*F[f'{i}'].shape[:-2], h, -1, 1) for i in structure.degrees]\n",
    "        fibers = torch.cat(fibers, -2)\n",
    "    return fibers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea4d8c1d-5964-427c-903a-e3da29e9b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G1x1SE3(nn.Module):\n",
    "    \"\"\"Graph Linear SE(3)-equivariant layer, equivalent to a 1x1 convolution.\n",
    "\n",
    "    This is equivalent to a self-interaction layer in TensorField Networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, f_in, f_out, learnable=True):\n",
    "        \"\"\"SE(3)-equivariant 1x1 convolution.\n",
    "\n",
    "        Args:\n",
    "            f_in: input Fiber() of feature multiplicities and types\n",
    "            f_out: output Fiber() of feature multiplicities and types\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "\n",
    "        # Linear mappings: 1 per output feature type\n",
    "        self.transform = nn.ParameterDict()\n",
    "        for m_out, d_out in self.f_out.structure:\n",
    "            m_in = self.f_in.structure_dict[d_out]\n",
    "            self.transform[str(d_out)] = nn.Parameter(torch.randn(m_out, m_in) / np.sqrt(m_in), requires_grad=learnable)\n",
    "\n",
    "    def __repr__(self):\n",
    "         return f\"G1x1SE3(structure={self.f_out})\"\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        output = {}\n",
    "        for k, v in features.items():\n",
    "            if str(k) in self.transform.keys():\n",
    "                output[k] = torch.matmul(self.transform[str(k)], v)\n",
    "        return output\n",
    "\n",
    "class GConvSE3Partial(nn.Module):\n",
    "    \"\"\"Graph SE(3)-equivariant node -> edge layer\"\"\"\n",
    "    def __init__(self, f_in, f_out, edge_dim: int=0, x_ij=None):\n",
    "        \"\"\"SE(3)-equivariant partial convolution.\n",
    "\n",
    "        A partial convolution computes the inner product between a kernel and\n",
    "        each input channel, without summing over the result from each input\n",
    "        channel. This unfolded structure makes it amenable to be used for\n",
    "        computing the value-embeddings of the attention mechanism.\n",
    "\n",
    "        Args:\n",
    "            f_in: list of tuples [(multiplicities, type),...]\n",
    "            f_out: list of tuples [(multiplicities, type),...]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_out = f_out\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        # adding/concatinating relative position to feature vectors\n",
    "        # 'cat' concatenates relative position & existing feature vector\n",
    "        # 'add' adds it, but only if multiplicity > 1\n",
    "        assert x_ij in [None, 'cat', 'add']\n",
    "        self.x_ij = x_ij\n",
    "        if x_ij == 'cat':\n",
    "            self.f_in = Fiber.combine(f_in, Fiber(structure=[(1,1)]))\n",
    "        else:\n",
    "            self.f_in = f_in\n",
    "\n",
    "        # Node -> edge weights\n",
    "        self.kernel_unary = nn.ModuleDict()\n",
    "        for (mi, di) in self.f_in.structure:\n",
    "            for (mo, do) in self.f_out.structure:\n",
    "                self.kernel_unary[f'({di},{do})'] = PairwiseConv(di, mi, do, mo, edge_dim=edge_dim)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'GConvSE3Partial(structure={self.f_out})'\n",
    "\n",
    "    def udf_u_mul_e(self, d_out):\n",
    "        \"\"\"Compute the partial convolution for a single output feature type.\n",
    "\n",
    "        This function is set up as a User Defined Function in DGL.\n",
    "\n",
    "        Args:\n",
    "            d_out: output feature type\n",
    "        Returns:\n",
    "            node -> edge function handle\n",
    "        \"\"\"\n",
    "        def fnc(edges):\n",
    "            # Neighbor -> center messages\n",
    "            msg = 0\n",
    "            for m_in, d_in in self.f_in.structure:\n",
    "                # if type 1 and flag set, add relative position as feature\n",
    "                if self.x_ij == 'cat' and d_in == 1:\n",
    "                    # relative positions\n",
    "                    rel = (edges.dst['x'] - edges.src['x']).view(-1, 3, 1)\n",
    "                    m_ori = m_in - 1\n",
    "                    if m_ori == 0:\n",
    "                        # no type 1 input feature, just use relative position\n",
    "                        src = rel\n",
    "                    else:\n",
    "                        # features of src node, shape [edges, m_in*(2l+1), 1]\n",
    "                        src = edges.src[f'{d_in}'].view(-1, m_ori*(2*d_in+1), 1)\n",
    "                        # add to feature vector\n",
    "                        src = torch.cat([src, rel], dim=1)\n",
    "                elif self.x_ij == 'add' and d_in == 1 and m_in > 1:\n",
    "                    src = edges.src[f'{d_in}'].view(-1, m_in*(2*d_in+1), 1)\n",
    "                    rel = (edges.dst['x'] - edges.src['x']).view(-1, 3, 1)\n",
    "                    src[..., :3, :1] = src[..., :3, :1] + rel\n",
    "                else:\n",
    "                    src = edges.src[f'{d_in}'].view(-1, m_in*(2*d_in+1), 1)\n",
    "                edge = edges.data[f'({d_in},{d_out})']\n",
    "                msg = msg + torch.matmul(edge, src)\n",
    "            msg = msg.view(msg.shape[0], -1, 2*d_out+1)\n",
    "\n",
    "            return {f'out{d_out}': msg.view(msg.shape[0], -1, 2*d_out+1)}\n",
    "        return fnc\n",
    "\n",
    "    @profile\n",
    "    def forward(self, h, G=None, r=None, basis=None, **kwargs):\n",
    "        \"\"\"Forward pass of the linear layer\n",
    "\n",
    "        Args:\n",
    "            h: dict of node-features\n",
    "            G: minibatch of (homo)graphs\n",
    "            r: inter-atomic distances\n",
    "            basis: pre-computed Q * Y\n",
    "        Returns:\n",
    "            tensor with new features [B, n_points, n_features_out]\n",
    "        \"\"\"\n",
    "        with G.local_scope():\n",
    "            # Add node features to local graph scope\n",
    "            for k, v in h.items():\n",
    "                G.ndata[k] = v\n",
    "\n",
    "            # Add edge features\n",
    "            if 'w' in G.edata.keys():\n",
    "                w = G.edata['w'] # shape: [#edges_in_batch, #bond_types]\n",
    "                feat = torch.cat([w, r], -1)\n",
    "            else:\n",
    "                feat = torch.cat([r, ], -1)\n",
    "            for (mi, di) in self.f_in.structure:\n",
    "                for (mo, do) in self.f_out.structure:\n",
    "                    etype = f'({di},{do})'\n",
    "                    G.edata[etype] = self.kernel_unary[etype](feat, basis)\n",
    "\n",
    "            # Perform message-passing for each output feature type\n",
    "            for d in self.f_out.degrees:\n",
    "                G.apply_edges(self.udf_u_mul_e(d))\n",
    "\n",
    "            return {f'{d}': G.edata[f'out{d}'] for d in self.f_out.degrees}\n",
    "\n",
    "class GMABSE3(nn.Module):\n",
    "    \"\"\"An SE(3)-equivariant multi-headed self-attention module for DGL graphs.\"\"\"\n",
    "    def __init__(self, f_value: Fiber, f_key: Fiber, n_heads: int):\n",
    "        \"\"\"SE(3)-equivariant MAB (multi-headed attention block) layer.\n",
    "\n",
    "        Args:\n",
    "            f_value: Fiber() object for value-embeddings\n",
    "            f_key: Fiber() object for key-embeddings\n",
    "            n_heads: number of heads\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_value = f_value\n",
    "        self.f_key = f_key\n",
    "        self.n_heads = n_heads\n",
    "        self.new_dgl = version.parse(dgl.__version__) > version.parse('0.4.4')\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'GMABSE3(n_heads={self.n_heads}, structure={self.f_value})'\n",
    "\n",
    "    def udf_u_mul_e(self, d_out):\n",
    "        \"\"\"Compute the weighted sum for a single output feature type.\n",
    "\n",
    "        This function is set up as a User Defined Function in DGL.\n",
    "\n",
    "        Args:\n",
    "            d_out: output feature type\n",
    "        Returns:\n",
    "            edge -> node function handle\n",
    "        \"\"\"\n",
    "        def fnc(edges):\n",
    "            # Neighbor -> center messages\n",
    "            attn = edges.data['a']\n",
    "            value = edges.data[f'v{d_out}']\n",
    "\n",
    "            # Apply attention weights\n",
    "            msg = attn.unsqueeze(-1).unsqueeze(-1) * value\n",
    "\n",
    "            return {'m': msg}\n",
    "        return fnc\n",
    "\n",
    "    @profile\n",
    "    def forward(self, v, k: Dict=None, q: Dict=None, G=None, **kwargs):\n",
    "        \"\"\"Forward pass of the linear layer\n",
    "\n",
    "        Args:\n",
    "            G: minibatch of (homo)graphs\n",
    "            v: dict of value edge-features\n",
    "            k: dict of key edge-features\n",
    "            q: dict of query node-features\n",
    "        Returns:\n",
    "            tensor with new features [B, n_points, n_features_out]\n",
    "        \"\"\"\n",
    "        with G.local_scope():\n",
    "            # Add node features to local graph scope\n",
    "            ## We use the stacked tensor representation for attention\n",
    "            for m, d in self.f_value.structure:\n",
    "                G.edata[f'v{d}'] = v[f'{d}'].view(-1, self.n_heads, m//self.n_heads, 2*d+1)\n",
    "            G.edata['k'] = fiber2head(k, self.n_heads, self.f_key, squeeze=True) # [edges, heads, channels](?)\n",
    "            G.ndata['q'] = fiber2head(q, self.n_heads, self.f_key, squeeze=True) # [nodes, heads, channels](?)\n",
    "\n",
    "            # Compute attention weights\n",
    "            ## Inner product between (key) neighborhood and (query) center\n",
    "            G.apply_edges(fn.e_dot_v('k', 'q', 'e'))\n",
    "\n",
    "            ## Apply softmax\n",
    "            e = G.edata.pop('e')\n",
    "            if self.new_dgl:\n",
    "                # in dgl 5.3, e has an extra dimension compared to dgl 4.3\n",
    "                # the following, we get rid of this be reshaping\n",
    "                n_edges = G.edata['k'].shape[0]\n",
    "                e = e.view([n_edges, self.n_heads])\n",
    "            e = e / np.sqrt(self.f_key.n_features)\n",
    "            G.edata['a'] = edge_softmax(G, e)\n",
    "\n",
    "            # Perform attention-weighted message-passing\n",
    "            for d in self.f_value.degrees:\n",
    "                G.update_all(self.udf_u_mul_e(d), fn.sum('m', f'out{d}'))\n",
    "\n",
    "            output = {}\n",
    "            for m, d in self.f_value.structure:\n",
    "                output[f'{d}'] = G.ndata[f'out{d}'].view(-1, m, 2*d+1)\n",
    "\n",
    "            return output\n",
    "\n",
    "\n",
    "class GSE3Res(nn.Module):\n",
    "    \"\"\"Graph attention block with SE(3)-equivariance and skip connection\"\"\"\n",
    "    def __init__(self, f_in: Fiber, f_out: Fiber, edge_dim: int=0, div: float=4,\n",
    "                 n_heads: int=1, learnable_skip=True, skip='cat', selfint='1x1', x_ij=None):\n",
    "        super().__init__()\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "        self.div = div\n",
    "        self.n_heads = n_heads\n",
    "        self.skip = skip  # valid: 'cat', 'sum', None\n",
    "\n",
    "        # f_mid_out has same structure as 'f_out' but #channels divided by 'div'\n",
    "        # this will be used for the values\n",
    "        f_mid_out = {k: int(v // div) for k, v in self.f_out.structure_dict.items()}\n",
    "        self.f_mid_out = Fiber(dictionary=f_mid_out)\n",
    "\n",
    "        # f_mid_in has same structure as f_mid_out, but only degrees which are in f_in\n",
    "        # this will be used for keys and queries\n",
    "        # (queries are merely projected, hence degrees have to match input)\n",
    "        f_mid_in = {d: m for d, m in f_mid_out.items() if d in self.f_in.degrees}\n",
    "        self.f_mid_in = Fiber(dictionary=f_mid_in)\n",
    "\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        self.GMAB = nn.ModuleDict()\n",
    "\n",
    "        # Projections\n",
    "        self.GMAB['v'] = GConvSE3Partial(f_in, self.f_mid_out, edge_dim=edge_dim, x_ij=x_ij)\n",
    "        self.GMAB['k'] = GConvSE3Partial(f_in, self.f_mid_in, edge_dim=edge_dim, x_ij=x_ij)\n",
    "        self.GMAB['q'] = G1x1SE3(f_in, self.f_mid_in)\n",
    "\n",
    "        # Attention\n",
    "        self.GMAB['attn'] = GMABSE3(self.f_mid_out, self.f_mid_in, n_heads=n_heads)\n",
    "\n",
    "        # Skip connections\n",
    "        if self.skip == 'cat':\n",
    "            self.cat = GCat(self.f_mid_out, f_in)\n",
    "            if selfint == 'att':\n",
    "                self.project = GAttentiveSelfInt(self.cat.f_out, f_out)\n",
    "            elif selfint == '1x1':\n",
    "                self.project = G1x1SE3(self.cat.f_out, f_out, learnable=learnable_skip)\n",
    "        elif self.skip == 'sum':\n",
    "            self.project = G1x1SE3(self.f_mid_out, f_out, learnable=learnable_skip)\n",
    "            self.add = GSum(f_out, f_in)\n",
    "            # the following checks whether the skip connection would change\n",
    "            # the output fibre strucure; the reason can be that the input has\n",
    "            # more channels than the ouput (for at least one degree); this would\n",
    "            # then cause a (hard to debug) error in the next layer\n",
    "            assert self.add.f_out.structure_dict == f_out.structure_dict, \\\n",
    "                'skip connection would change output structure'\n",
    "\n",
    "    @profile\n",
    "    def forward(self, features, G, **kwargs):\n",
    "        # Embeddings\n",
    "        v = self.GMAB['v'](features, G=G, **kwargs)\n",
    "        k = self.GMAB['k'](features, G=G, **kwargs)\n",
    "        q = self.GMAB['q'](features, G=G)\n",
    "\n",
    "        # Attention\n",
    "        z = self.GMAB['attn'](v, k=k, q=q, G=G)\n",
    "\n",
    "        if self.skip == 'cat':\n",
    "            z = self.cat(z, features)\n",
    "            z = self.project(z)\n",
    "        elif self.skip == 'sum':\n",
    "            # Skip + residual\n",
    "            z = self.project(z)\n",
    "            z = self.add(z, features)\n",
    "        return z\n",
    "\n",
    "class GCat(nn.Module):\n",
    "    \"\"\"Concat only degrees which are in f_x\"\"\"\n",
    "    def __init__(self, f_x: Fiber, f_y: Fiber):\n",
    "        super().__init__()\n",
    "        self.f_x = f_x\n",
    "        self.f_y = f_y\n",
    "        f_out = {}\n",
    "        for k in f_x.degrees:\n",
    "            f_out[k] = f_x.dict[k]\n",
    "            if k in f_y.degrees:\n",
    "                f_out[k] += f_y.dict[k]\n",
    "        self.f_out = Fiber(dictionary=f_out)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"GCat(structure={self.f_out})\"\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = {}\n",
    "        for k in self.f_out.degrees:\n",
    "            k = str(k)\n",
    "            if k in y:\n",
    "                out[k] = torch.cat([x[k], y[k]], 1)\n",
    "            else:\n",
    "                out[k] = x[k]\n",
    "        return out\n",
    "\n",
    "class GSum(nn.Module):\n",
    "    \"\"\"SE(3)-equvariant graph residual sum function.\"\"\"\n",
    "    def __init__(self, f_x: Fiber, f_y: Fiber):\n",
    "        \"\"\"SE(3)-equvariant graph residual sum function.\n",
    "\n",
    "        Args:\n",
    "            f_x: Fiber() object for fiber of summands\n",
    "            f_y: Fiber() object for fiber of summands\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_x = f_x\n",
    "        self.f_y = f_y\n",
    "        self.f_out = Fiber.combine_max(f_x, f_y)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"GSum(structure={self.f_out})\"\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = {}\n",
    "        for k in self.f_out.degrees:\n",
    "            k = str(k)\n",
    "            if (k in x) and (k in y):\n",
    "                if x[k].shape[1] > y[k].shape[1]:\n",
    "                    diff = x[k].shape[1] - y[k].shape[1]\n",
    "                    zeros = torch.zeros(x[k].shape[0], diff, x[k].shape[2]).to(y[k].device)\n",
    "                    y[k] = torch.cat([y[k], zeros], 1)\n",
    "                elif x[k].shape[1] < y[k].shape[1]:\n",
    "                    diff = y[k].shape[1] - x[k].shape[1]\n",
    "                    zeros = torch.zeros(x[k].shape[0], diff, x[k].shape[2]).to(y[k].device)\n",
    "                    x[k] = torch.cat([x[k], zeros], 1)\n",
    "\n",
    "                out[k] = x[k] + y[k]\n",
    "            elif k in x:\n",
    "                out[k] = x[k]\n",
    "            elif k in y:\n",
    "                out[k] = y[k]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb5f60b8-8d8c-467b-8cd8-aefa8263a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadialFunc(nn.Module):\n",
    "    \"\"\"NN parameterized radial profile function.\"\"\"\n",
    "    def __init__(self, num_freq, in_dim, out_dim, edge_dim: int=0):\n",
    "        \"\"\"NN parameterized radial profile function.\n",
    "\n",
    "        Args:\n",
    "            num_freq: number of output frequencies\n",
    "            in_dim: multiplicity of input (num input channels)\n",
    "            out_dim: multiplicity of output (num output channels)\n",
    "            edge_dim: number of dimensions for edge embedding\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_freq = num_freq\n",
    "        self.in_dim = in_dim\n",
    "        self.mid_dim = 32\n",
    "        self.out_dim = out_dim\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        self.net = nn.Sequential(nn.Linear(self.edge_dim+1,self.mid_dim),\n",
    "                                 BN(self.mid_dim),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(self.mid_dim,self.mid_dim),\n",
    "                                 BN(self.mid_dim),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(self.mid_dim,self.num_freq*in_dim*out_dim))\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.net[0].weight)\n",
    "        nn.init.kaiming_uniform_(self.net[3].weight)\n",
    "        nn.init.kaiming_uniform_(self.net[6].weight)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"RadialFunc(edge_dim={self.edge_dim}, in_dim={self.in_dim}, out_dim={self.out_dim})\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y.view(-1, self.out_dim, 1, self.in_dim, 1, self.num_freq)\n",
    "\n",
    "\n",
    "class PairwiseConv(nn.Module):\n",
    "    \"\"\"SE(3)-equivariant convolution between two single-type features\"\"\"\n",
    "    def __init__(self, degree_in: int, nc_in: int, degree_out: int,\n",
    "                 nc_out: int, edge_dim: int=0):\n",
    "        \"\"\"SE(3)-equivariant convolution between a pair of feature types.\n",
    "\n",
    "        This layer performs a convolution from nc_in features of type degree_in\n",
    "        to nc_out features of type degree_out.\n",
    "\n",
    "        Args:\n",
    "            degree_in: degree of input fiber\n",
    "            nc_in: number of channels on input\n",
    "            degree_out: degree of out order\n",
    "            nc_out: number of channels on output\n",
    "            edge_dim: number of dimensions for edge embedding\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Log settings\n",
    "        self.degree_in = degree_in\n",
    "        self.degree_out = degree_out\n",
    "        self.nc_in = nc_in\n",
    "        self.nc_out = nc_out\n",
    "\n",
    "        # Functions of the degree\n",
    "        self.num_freq = 2*min(degree_in, degree_out) + 1\n",
    "        self.d_out = 2*degree_out + 1\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        # Radial profile function\n",
    "        self.rp = RadialFunc(self.num_freq, nc_in, nc_out, self.edge_dim)\n",
    "\n",
    "    @profile\n",
    "    def forward(self, feat, basis):\n",
    "        # Get radial weights\n",
    "        R = self.rp(feat)\n",
    "        kernel = torch.sum(R * basis[f'{self.degree_in},{self.degree_out}'], -1)\n",
    "        return kernel.view(kernel.shape[0], self.d_out*self.nc_out, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0cd805a-da71-43d4-95b8-0fd29f789eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAttentiveSelfInt(nn.Module):\n",
    "\n",
    "    def __init__(self, f_in, f_out):\n",
    "        \"\"\"SE(3)-equivariant 1x1 convolution.\n",
    "\n",
    "        Args:\n",
    "            f_in: input Fiber() of feature multiplicities and types\n",
    "            f_out: output Fiber() of feature multiplicities and types\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "        self.nonlin = nn.LeakyReLU()\n",
    "        self.num_layers = 2\n",
    "        self.eps = 1e-12 # regularisation for phase: gradients explode otherwise\n",
    "\n",
    "        # one network for attention weights per degree\n",
    "        self.transform = nn.ModuleDict()\n",
    "        for o, m_in in self.f_in.structure_dict.items():\n",
    "            m_out = self.f_out.structure_dict[o]\n",
    "            self.transform[str(o)] = self._build_net(m_in, m_out)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"AttentiveSelfInteractionSE3(in={self.f_in}, out={self.f_out})\"\n",
    "\n",
    "    def _build_net(self, m_in: int, m_out):\n",
    "        n_hidden = m_in * m_out\n",
    "        cur_inpt = m_in * m_in\n",
    "        net = []\n",
    "        for i in range(1, self.num_layers):\n",
    "            net.append(nn.LayerNorm(int(cur_inpt)))\n",
    "            net.append(self.nonlin)\n",
    "            # TODO: implement cleaner init\n",
    "            net.append(\n",
    "                nn.Linear(cur_inpt, n_hidden, bias=(i == self.num_layers - 1)))\n",
    "            nn.init.kaiming_uniform_(net[-1].weight)\n",
    "            cur_inpt = n_hidden\n",
    "        return nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        output = {}\n",
    "        for k, v in features.items():\n",
    "            # v shape: [..., m, 2*k+1]\n",
    "            first_dims = v.shape[:-2]\n",
    "            m_in  = self.f_in.structure_dict[int(k)]\n",
    "            m_out = self.f_out.structure_dict[int(k)]\n",
    "            assert v.shape[-2] == m_in\n",
    "            assert v.shape[-1] == 2 * int(k) + 1\n",
    "\n",
    "            # Compute the norms and normalized features\n",
    "            #norm = v.norm(p=2, dim=-1, keepdim=True).clamp_min(self.eps).expand_as(v)\n",
    "            #phase = v / norm # [..., m, 2*k+1]\n",
    "            scalars = torch.einsum('...ac,...bc->...ab', [v, v]) # [..., m_in, m_in]\n",
    "            scalars = scalars.view(*first_dims, m_in*m_in) # [..., m_in*m_in]\n",
    "            sign = scalars.sign()\n",
    "            scalars = scalars.abs_().clamp_min(self.eps)\n",
    "            scalars *= sign\n",
    "\n",
    "            # perform attention\n",
    "            att_weights = self.transform[str(k)](scalars) # [..., m_out*m_in]\n",
    "            att_weights = att_weights.view(*first_dims, m_out, m_in) # [..., m_out, m_in]\n",
    "            att_weights = F.softmax(input=att_weights, dim=-1)\n",
    "            # shape [..., m_out, 2*k+1]\n",
    "            # output[k] = torch.einsum('...nm,...md->...nd', [att_weights, phase])\n",
    "            output[k] = torch.einsum('...nm,...md->...nd', [att_weights, v])\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class GNormSE3(nn.Module):\n",
    "    \"\"\"Graph Norm-based SE(3)-equivariant nonlinearity.\n",
    "\n",
    "    Nonlinearities are important in SE(3) equivariant GCNs. They are also quite\n",
    "    expensive to compute, so it is convenient for them to share resources with\n",
    "    other layers, such as normalization. The general workflow is as follows:\n",
    "\n",
    "    > for feature type in features:\n",
    "    >    norm, phase <- feature\n",
    "    >    output = fnc(norm) * phase\n",
    "\n",
    "    where fnc: {R+}^m -> R^m is a learnable map from m norms to m scalars.\n",
    "    \"\"\"\n",
    "    def __init__(self, fiber, nonlin=nn.ReLU(inplace=True), num_layers: int=0):\n",
    "        \"\"\"Initializer.\n",
    "\n",
    "        Args:\n",
    "            fiber: Fiber() of feature multiplicities and types\n",
    "            nonlin: nonlinearity to use everywhere\n",
    "            num_layers: non-negative number of linear layers in fnc\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.fiber = fiber\n",
    "        self.nonlin = nonlin\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Regularization for computing phase: gradients explode otherwise\n",
    "        self.eps = 1e-12\n",
    "\n",
    "        # Norm mappings: 1 per feature type\n",
    "        self.transform = nn.ModuleDict()\n",
    "        for m, d in self.fiber.structure:\n",
    "            self.transform[str(d)] = self._build_net(int(m))\n",
    "\n",
    "    def __repr__(self):\n",
    "         return f\"GNormSE3(num_layers={self.num_layers}, nonlin={self.nonlin})\"\n",
    "\n",
    "    def _build_net(self, m: int):\n",
    "        net = []\n",
    "        for i in range(self.num_layers):\n",
    "            net.append(BN(int(m)))\n",
    "            net.append(self.nonlin)\n",
    "            # TODO: implement cleaner init\n",
    "            net.append(nn.Linear(m, m, bias=(i==self.num_layers-1)))\n",
    "            nn.init.kaiming_uniform_(net[-1].weight)\n",
    "        if self.num_layers == 0:\n",
    "            net.append(BN(int(m)))\n",
    "            net.append(self.nonlin)\n",
    "        return nn.Sequential(*net)\n",
    "\n",
    "    @profile\n",
    "    def forward(self, features, **kwargs):\n",
    "        output = {}\n",
    "        for k, v in features.items():\n",
    "            # Compute the norms and normalized features\n",
    "            # v shape: [...,m , 2*k+1]\n",
    "            norm = v.norm(2, -1, keepdim=True).clamp_min(self.eps).expand_as(v)\n",
    "            phase = v / norm\n",
    "\n",
    "            # Transform on norms\n",
    "            transformed = self.transform[str(k)](norm[...,0]).unsqueeze(-1)\n",
    "\n",
    "            # Nonlinearity on norm\n",
    "            output[k] = (transformed * phase).view(*v.shape)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class BN(nn.Module):\n",
    "    \"\"\"SE(3)-equvariant batch/layer normalization\"\"\"\n",
    "    def __init__(self, m):\n",
    "        \"\"\"SE(3)-equvariant batch/layer normalization\n",
    "\n",
    "        Args:\n",
    "            m: int for number of output channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.bn = nn.LayerNorm(m)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bn(x)\n",
    "\n",
    "\n",
    "class GConvSE3(nn.Module):\n",
    "    \"\"\"A tensor field network layer as a DGL module.\n",
    "\n",
    "    GConvSE3 stands for a Graph Convolution SE(3)-equivariant layer. It is the\n",
    "    equivalent of a linear layer in an MLP, a conv layer in a CNN, or a graph\n",
    "    conv layer in a GCN.\n",
    "\n",
    "    At each node, the activations are split into different \"feature types\",\n",
    "    indexed by the SE(3) representation type: non-negative integers 0, 1, 2, ..\n",
    "    \"\"\"\n",
    "    def __init__(self, f_in, f_out, self_interaction: bool=False, edge_dim: int=0, flavor='skip'):\n",
    "        \"\"\"SE(3)-equivariant Graph Conv Layer\n",
    "\n",
    "        Args:\n",
    "            f_in: list of tuples [(multiplicities, type),...]\n",
    "            f_out: list of tuples [(multiplicities, type),...]\n",
    "            self_interaction: include self-interaction in convolution\n",
    "            edge_dim: number of dimensions for edge embedding\n",
    "            flavor: allows ['TFN', 'skip'], where 'skip' adds a skip connection\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_in = f_in\n",
    "        self.f_out = f_out\n",
    "        self.edge_dim = edge_dim\n",
    "        self.self_interaction = self_interaction\n",
    "        self.flavor = flavor\n",
    "\n",
    "        # Neighbor -> center weights\n",
    "        self.kernel_unary = nn.ModuleDict()\n",
    "        for (mi, di) in self.f_in.structure:\n",
    "            for (mo, do) in self.f_out.structure:\n",
    "                self.kernel_unary[f'({di},{do})'] = PairwiseConv(di, mi, do, mo, edge_dim=edge_dim)\n",
    "\n",
    "        # Center -> center weights\n",
    "        self.kernel_self = nn.ParameterDict()\n",
    "        if self_interaction:\n",
    "            assert self.flavor in ['TFN', 'skip']\n",
    "            if self.flavor == 'TFN':\n",
    "                for m_out, d_out in self.f_out.structure:\n",
    "                    W = nn.Parameter(torch.randn(1, m_out, m_out) / np.sqrt(m_out))\n",
    "                    self.kernel_self[f'{d_out}'] = W\n",
    "            elif self.flavor == 'skip':\n",
    "                for m_in, d_in in self.f_in.structure:\n",
    "                    if d_in in self.f_out.degrees:\n",
    "                        m_out = self.f_out.structure_dict[d_in]\n",
    "                        W = nn.Parameter(torch.randn(1, m_out, m_in) / np.sqrt(m_in))\n",
    "                        self.kernel_self[f'{d_in}'] = W\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'GConvSE3(structure={self.f_out}, self_interaction={self.self_interaction})'\n",
    "\n",
    "\n",
    "    def udf_u_mul_e(self, d_out):\n",
    "        \"\"\"Compute the convolution for a single output feature type.\n",
    "\n",
    "        This function is set up as a User Defined Function in DGL.\n",
    "\n",
    "        Args:\n",
    "            d_out: output feature type\n",
    "        Returns:\n",
    "            edge -> node function handle\n",
    "        \"\"\"\n",
    "        def fnc(edges):\n",
    "            # Neighbor -> center messages\n",
    "            msg = 0\n",
    "            for m_in, d_in in self.f_in.structure:\n",
    "                src = edges.src[f'{d_in}'].view(-1, m_in*(2*d_in+1), 1)\n",
    "                edge = edges.data[f'({d_in},{d_out})']\n",
    "                msg = msg + torch.matmul(edge, src)\n",
    "            msg = msg.view(msg.shape[0], -1, 2*d_out+1)\n",
    "\n",
    "            # Center -> center messages\n",
    "            if self.self_interaction:\n",
    "                if f'{d_out}' in self.kernel_self.keys():\n",
    "                    if self.flavor == 'TFN':\n",
    "                        W = self.kernel_self[f'{d_out}']\n",
    "                        msg = torch.matmul(W, msg)\n",
    "                    if self.flavor == 'skip':\n",
    "                        dst = edges.dst[f'{d_out}']\n",
    "                        W = self.kernel_self[f'{d_out}']\n",
    "                        msg = msg + torch.matmul(W, dst)\n",
    "\n",
    "            return {'msg': msg.view(msg.shape[0], -1, 2*d_out+1)}\n",
    "        return fnc\n",
    "\n",
    "    @profile\n",
    "    def forward(self, h, G=None, r=None, basis=None, **kwargs):\n",
    "        \"\"\"Forward pass of the linear layer\n",
    "\n",
    "        Args:\n",
    "            G: minibatch of (homo)graphs\n",
    "            h: dict of features\n",
    "            r: inter-atomic distances\n",
    "            basis: pre-computed Q * Y\n",
    "        Returns:\n",
    "            tensor with new features [B, n_points, n_features_out]\n",
    "        \"\"\"\n",
    "        with G.local_scope():\n",
    "            # Add node features to local graph scope\n",
    "            for k, v in h.items():\n",
    "                G.ndata[k] = v\n",
    "\n",
    "            # Add edge features\n",
    "            if 'w' in G.edata.keys():\n",
    "                w = G.edata['w']\n",
    "                feat = torch.cat([w, r], -1)\n",
    "            else:\n",
    "                feat = torch.cat([r, ], -1)\n",
    "\n",
    "            for (mi, di) in self.f_in.structure:\n",
    "                for (mo, do) in self.f_out.structure:\n",
    "                    etype = f'({di},{do})'\n",
    "                    G.edata[etype] = self.kernel_unary[etype](feat, basis)\n",
    "\n",
    "            # Perform message-passing for each output feature type\n",
    "            for d in self.f_out.degrees:\n",
    "                G.update_all(self.udf_u_mul_e(d), fn.mean('msg', f'out{d}'))\n",
    "\n",
    "            return {f'{d}': G.ndata[f'out{d}'] for d in self.f_out.degrees}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb1b44d4-a71d-4b02-b7d2-12e25b860d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAvgPooling(nn.Module):\n",
    "    \"\"\"Graph Average Pooling module.\"\"\"\n",
    "    def __init__(self, type='0'):\n",
    "        super().__init__()\n",
    "        self.pool = AvgPooling()\n",
    "        self.type = type\n",
    "\n",
    "    @profile\n",
    "    def forward(self, features, G, **kwargs):\n",
    "        if self.type == '0':\n",
    "            h = features['0'][...,-1]\n",
    "            pooled = self.pool(G, h)\n",
    "        elif self.type == '1':\n",
    "            pooled = []\n",
    "            for i in range(3):\n",
    "                h_i = features['1'][..., i]\n",
    "                pooled.append(self.pool(G, h_i).unsqueeze(-1))\n",
    "            pooled = torch.cat(pooled, axis=-1)\n",
    "            pooled = {'1': pooled}\n",
    "        else:\n",
    "            print('GAvgPooling for type > 0 not implemented')\n",
    "            exit()\n",
    "        return pooled\n",
    "\n",
    "\n",
    "class GMaxPooling(nn.Module):\n",
    "    \"\"\"Graph Max Pooling module.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = MaxPooling()\n",
    "\n",
    "    @profile\n",
    "    def forward(self, features, G, **kwargs):\n",
    "        h = features['0'][...,-1]\n",
    "        return self.pool(G, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed2ea0ce-88c3-4b6e-92c9-96f8f0a486a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE3Transformer(nn.Module):\n",
    "    \"\"\"SE(3) equivariant GCN with attention\"\"\"\n",
    "    def __init__(self, num_layers: int, atom_feature_size: int, \n",
    "                 num_channels: int, num_nlayers: int=1, num_degrees: int=4, \n",
    "                 edge_dim: int=4, div: float=4, pooling: str='avg', n_heads: int=1, **kwargs):\n",
    "        super().__init__()\n",
    "        # Build the network\n",
    "        self.num_layers = num_layers\n",
    "        self.num_nlayers = num_nlayers\n",
    "        self.num_channels = num_channels\n",
    "        self.num_degrees = num_degrees\n",
    "        self.edge_dim = edge_dim\n",
    "        self.div = div\n",
    "        self.pooling = pooling\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.fibers = {'in': Fiber(1, atom_feature_size),\n",
    "                       'mid': Fiber(num_degrees, self.num_channels),\n",
    "                       'out': Fiber(1, num_degrees*self.num_channels)}\n",
    "\n",
    "        blocks = self._build_gcn(self.fibers, 1)\n",
    "        self.Gblock, self.FCblock = blocks # encoder, decoder\n",
    "        print(self.Gblock)\n",
    "        print(self.FCblock)\n",
    "\n",
    "    def _build_gcn(self, fibers, out_dim):\n",
    "        # Equivariant layers\n",
    "        Gblock = []\n",
    "        fin = fibers['in']\n",
    "        for i in range(self.num_layers):\n",
    "            Gblock.append(GSE3Res(fin, fibers['mid'], edge_dim=self.edge_dim, \n",
    "                                  div=self.div, n_heads=self.n_heads))\n",
    "            Gblock.append(GNormSE3(fibers['mid']))\n",
    "            fin = fibers['mid']\n",
    "        Gblock.append(GConvSE3(fibers['mid'], fibers['out'], self_interaction=True, edge_dim=self.edge_dim))\n",
    "\n",
    "        # Pooling\n",
    "        if self.pooling == 'avg':\n",
    "            Gblock.append(GAvgPooling())\n",
    "        elif self.pooling == 'max':\n",
    "            Gblock.append(GMaxPooling())\n",
    "\n",
    "        # FC layers\n",
    "        FCblock = []\n",
    "        FCblock.append(nn.Linear(self.fibers['out'].n_features, self.fibers['out'].n_features))\n",
    "        FCblock.append(nn.ReLU(inplace=True))\n",
    "        FCblock.append(nn.Linear(self.fibers['out'].n_features, out_dim))\n",
    "\n",
    "        return nn.ModuleList(Gblock), nn.ModuleList(FCblock)\n",
    "\n",
    "    def forward(self, G):\n",
    "        # Compute equivariant weight basis from relative positions\n",
    "        basis, r = get_basis_and_r(G, self.num_degrees-1)\n",
    "\n",
    "        # encoder (equivariant layers)\n",
    "        h = {'0': G.ndata['f']}\n",
    "        for layer in self.Gblock:\n",
    "            h = layer(h, G=G, r=r, basis=basis)\n",
    "\n",
    "        for layer in self.FCblock:\n",
    "            h = layer(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5db4cfad-bc29-4251-8680-943c69da8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, x):\n",
    "        M = np.random.randn(3,3)\n",
    "        Q, __ = np.linalg.qr(M)\n",
    "        return x @ Q\n",
    "\n",
    "def collate(samples):\n",
    "    graphs, y = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ce3f283-9207-4fff-a595-977339bd634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "n_epoch = 50\n",
    "lr = 1e-3\n",
    "batch_size = 32\n",
    "task = 'homo'\n",
    "\n",
    "print_interval = 1\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "879ee295-1b83-4308-88c8-9f08240d9556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36910/2732476931.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.file_address)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train-set, task: homo, source: ./QM9_data/QM9_data.pt, length: 100000\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "train_dataset = QM9Dataset('./QM9_data/QM9_data.pt', \n",
    "                           task,\n",
    "                           mode='train', \n",
    "                           transform=RandomRotation())\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True, \n",
    "                          collate_fn=collate, \n",
    "                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a202e051-fbeb-4385-9cc0-c4daef19ba01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "#class SE3Transformer(nn.Module):\n",
    "#    \"\"\"SE(3) equivariant GCN with attention\"\"\"\n",
    "#    def __init__(self, num_layers: int, atom_feature_size: int, \n",
    "#                 num_channels: int, num_nlayers: int=1, num_degrees: int=4, \n",
    "#                 edge_dim: int=4, div: float=4, pooling: str='avg', n_heads: int=1, **kwargs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0d03bb8-bf5a-41ee-b474-8d309ac3419d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix seed for random numbers\n",
    "seed = 1992\n",
    "\n",
    "torch.manual_seed(1992)\n",
    "np.random.seed(1992)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "206e30d9-80da-46d0-a7c9-d5c406dd6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "    return x.cpu().detach().numpy()\n",
    "\n",
    "def train_epoch(epoch, model, loss_fnc, dataloader, optimizer, scheduler):\n",
    "    model.train()\n",
    "\n",
    "    num_iters = len(dataloader)\n",
    "    for i, (g, y) in enumerate(dataloader):\n",
    "        g = g.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # run model forward and compute loss\n",
    "        pred = model(g)\n",
    "        l1_loss, __, rescale_loss = loss_fnc(pred, y)\n",
    "\n",
    "        # backprop\n",
    "        l1_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % print_interval == 0:\n",
    "            print(f\"[{epoch}|{i}] l1 loss: {l1_loss:.5f} rescale loss: {rescale_loss:.5f} [units]\")\n",
    "        #if i % log_interval == 0:\n",
    "        #    wandb.log({\"Train L1 loss\": to_np(l1_loss), \n",
    "        #               \"Rescale loss\": to_np(rescale_loss)})\n",
    "\n",
    "        #if FLAGS.profile and i == 10:\n",
    "        #    sys.exit()\n",
    "    \n",
    "        scheduler.step(epoch + i / num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a7708-82c3-40db-bb23-0a4508a968fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): GSE3Res(\n",
      "    (GMAB): ModuleDict(\n",
      "      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (k): GConvSE3Partial(structure=[(16, 0)])\n",
      "      (q): G1x1SE3(structure=[(16, 0)])\n",
      "      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "    )\n",
      "    (cat): GCat(structure=[(22, 0), (16, 1), (16, 2), (16, 3)])\n",
      "    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])\n",
      "  )\n",
      "  (1): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))\n",
      "  (2): GSE3Res(\n",
      "    (GMAB): ModuleDict(\n",
      "      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (k): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (q): G1x1SE3(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "    )\n",
      "    (cat): GCat(structure=[(48, 0), (48, 1), (48, 2), (48, 3)])\n",
      "    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])\n",
      "  )\n",
      "  (3): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))\n",
      "  (4): GSE3Res(\n",
      "    (GMAB): ModuleDict(\n",
      "      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (k): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (q): G1x1SE3(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "    )\n",
      "    (cat): GCat(structure=[(48, 0), (48, 1), (48, 2), (48, 3)])\n",
      "    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])\n",
      "  )\n",
      "  (5): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))\n",
      "  (6): GSE3Res(\n",
      "    (GMAB): ModuleDict(\n",
      "      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (k): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (q): G1x1SE3(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "    )\n",
      "    (cat): GCat(structure=[(48, 0), (48, 1), (48, 2), (48, 3)])\n",
      "    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])\n",
      "  )\n",
      "  (7): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))\n",
      "  (8): GSE3Res(\n",
      "    (GMAB): ModuleDict(\n",
      "      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (k): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (q): G1x1SE3(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])\n",
      "    )\n",
      "    (cat): GCat(structure=[(48, 0), (48, 1), (48, 2), (48, 3)])\n",
      "    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])\n",
      "  )\n",
      "  (9): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))\n",
      "  (10): GConvSE3(structure=[(128, 0)], self_interaction=True)\n",
      "  (11): GMaxPooling(\n",
      "    (pool): MaxPooling()\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Begin training\n",
      "Saved: ./saved_models/QM9_Vlad.pt\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from packaging import version\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = SE3Transformer(\n",
    "     num_layers = 5, \n",
    "     atom_feature_size=train_dataset.atom_feature_size, \n",
    "     num_channels = 32,\n",
    "     num_nlayers=1,\n",
    "     num_degrees=4,\n",
    "     edge_dim=train_dataset.num_bonds,\n",
    "     div=2,\n",
    "     pooling=\"max\",\n",
    "     n_heads=8\n",
    ")\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "#device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer settings\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, \n",
    "                                                           n_epoch, \n",
    "                                                           eta_min=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loss function\n",
    "def task_loss(pred, target, use_mean=True):\n",
    "    l1_loss = torch.sum(torch.abs(pred - target))\n",
    "    l2_loss = torch.sum((pred - target)**2)\n",
    "    if use_mean:\n",
    "        l1_loss /= pred.shape[0]\n",
    "        l2_loss /= pred.shape[0]\n",
    "\n",
    "    rescale_loss = train_dataset.norm2units(l1_loss, task)\n",
    "    return l1_loss, l2_loss, rescale_loss\n",
    "\n",
    "# Save path\n",
    "save_path = os.path.join('./saved_models/', 'QM9_Vlad' + '.pt')\n",
    "\n",
    "# Run training\n",
    "print('Begin training')\n",
    "for epoch in range(n_epoch):\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Saved: {save_path}\")\n",
    "\n",
    "    train_epoch(epoch, model, task_loss, train_loader, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b98005fd-d58e-4a85-8906-fe134ff2e485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   5756 MiB |   6665 MiB |  33010 MiB |  27253 MiB |\\n|       from large pool |   5530 MiB |   6429 MiB |  32106 MiB |  26575 MiB |\\n|       from small pool |    226 MiB |    236 MiB |    904 MiB |    677 MiB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   5756 MiB |   6665 MiB |  33010 MiB |  27253 MiB |\\n|       from large pool |   5530 MiB |   6429 MiB |  32106 MiB |  26575 MiB |\\n|       from small pool |    226 MiB |    236 MiB |    904 MiB |    677 MiB |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |   5748 MiB |   6656 MiB |  32991 MiB |  27243 MiB |\\n|       from large pool |   5522 MiB |   6421 MiB |  32088 MiB |  26566 MiB |\\n|       from small pool |    225 MiB |    236 MiB |    903 MiB |    677 MiB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   7098 MiB |   7100 MiB |   7100 MiB |   2048 KiB |\\n|       from large pool |   6860 MiB |   6860 MiB |   6860 MiB |      0 KiB |\\n|       from small pool |    238 MiB |    240 MiB |    240 MiB |   2048 KiB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory | 535568 KiB |   1254 MiB |  24067 MiB |  23544 MiB |\\n|       from large pool | 530162 KiB |   1246 MiB |  23178 MiB |  22660 MiB |\\n|       from small pool |   5406 KiB |      7 MiB |    888 MiB |    883 MiB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    4214    |    4350    |    6733    |    2519    |\\n|       from large pool |     187    |     203    |     526    |     339    |\\n|       from small pool |    4027    |    4148    |    6207    |    2180    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    4214    |    4350    |    6733    |    2519    |\\n|       from large pool |     187    |     203    |     526    |     339    |\\n|       from small pool |    4027    |    4148    |    6207    |    2180    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     139    |     140    |     140    |       1    |\\n|       from large pool |      20    |      20    |      20    |       0    |\\n|       from small pool |     119    |     120    |     120    |       1    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |     165    |     178    |    1590    |    1425    |\\n|       from large pool |      19    |      24    |     266    |     247    |\\n|       from small pool |     146    |     154    |    1324    |    1178    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d1a74-44f7-4482-a78c-519c505b17e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gcnn",
   "language": "python",
   "name": "torch_gcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
