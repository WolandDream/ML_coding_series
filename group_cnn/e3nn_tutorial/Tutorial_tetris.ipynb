{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8aa8c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This net uses the following modules of e3nn\n",
    "from e3nn import o3\n",
    "from e3nn.o3 import FullyConnectedTensorProduct\n",
    "\n",
    "# From pytorch_geometric\n",
    "from torch_cluster import radius_graph\n",
    "from torch_scatter import scatter\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab297b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tetris():\n",
    "    pos = [\n",
    "        [(0, 0, 0), (0, 0, 1), (1, 0, 0), (1, 1, 0)],  # chiral_shape_1\n",
    "        [(0, 0, 0), (0, 0, 1), (1, 0, 0), (1, -1, 0)],  # chiral_shape_2\n",
    "        [(0, 0, 0), (1, 0, 0), (0, 1, 0), (1, 1, 0)],  # square\n",
    "        [(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 0, 3)],  # line\n",
    "        [(0, 0, 0), (0, 0, 1), (0, 1, 0), (1, 0, 0)],  # corner\n",
    "        [(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 1, 0)],  # L\n",
    "        [(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 1, 1)],  # T\n",
    "        [(0, 0, 0), (1, 0, 0), (1, 1, 0), (2, 1, 0)],  # zigzag\n",
    "    ]\n",
    "    pos = torch.tensor(pos, dtype=torch.get_default_dtype())\n",
    "\n",
    "    # Since chiral shapes are the mirror of one another we need an *odd* scalar to distinguish them\n",
    "    labels = torch.tensor(\n",
    "        [\n",
    "            [+1, 0, 0, 0, 0, 0, 0],  # chiral_shape_1\n",
    "            [-1, 0, 0, 0, 0, 0, 0],  # chiral_shape_2\n",
    "            [0, 1, 0, 0, 0, 0, 0],  # square\n",
    "            [0, 0, 1, 0, 0, 0, 0],  # line\n",
    "            [0, 0, 0, 1, 0, 0, 0],  # corner\n",
    "            [0, 0, 0, 0, 1, 0, 0],  # L\n",
    "            [0, 0, 0, 0, 0, 1, 0],  # T\n",
    "            [0, 0, 0, 0, 0, 0, 1],  # zigzag\n",
    "        ],\n",
    "        dtype=torch.get_default_dtype(),\n",
    "    )\n",
    "\n",
    "    # apply random rotation\n",
    "    pos = torch.einsum(\"zij,zaj->zai\", o3.rand_matrix(len(pos)), pos)\n",
    "\n",
    "    # put in torch_geometric format\n",
    "    dataset = [Data(pos=pos) for pos in pos]\n",
    "    data = next(iter(DataLoader(dataset, batch_size=len(dataset))))\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e363b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InveriantPolynomial(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.irreps_sh: o3.Irreps = o3.Irreps.spherical_harmonics(3)\n",
    "            \n",
    "        irreps_mid = o3.Irreps(\"64x0e + 24x1e + 24x1o + 16x2e + 16x2o\")\n",
    "        irreps_out = o3.Irreps(\"0o + 6x0e\")\n",
    "        \n",
    "        self.tp1 = FullyConnectedTensorProduct(\n",
    "            irreps_in1 = self.irreps_sh,\n",
    "            irreps_in2 = self.irreps_sh,\n",
    "            irreps_out = irreps_mid,\n",
    "        )\n",
    "        \n",
    "        self.tp2 = FullyConnectedTensorProduct(\n",
    "            irreps_in1 = irreps_mid,\n",
    "            irreps_in2 = self.irreps_sh,\n",
    "            irreps_out = irreps_out,\n",
    "        )\n",
    "        \n",
    "        self.irreps_out = self.tp2.irreps_out\n",
    "        \n",
    "    def forward(self, data) -> torch.Tensor:\n",
    "        num_neighbors = 2 # typical_number of neighbors\n",
    "        num_nodes = 4 # typical number of nodes\n",
    "        \n",
    "        edge_src, edge_dst = radius_graph(x = data.pos, r = 1.1, batch = data.batch) #tensor of indices representing graph\n",
    "        edge_vec = data.pos[edge_src] - data.pos[edge_dst]\n",
    "        edge_sh = o3.spherical_harmonics(\n",
    "            l = self.irreps_sh,\n",
    "            x = edge_vec,\n",
    "            normalize=False, # here we don't normalize otherwise it would not be a polynomial\n",
    "            normalization='component'\n",
    "        )\n",
    "        \n",
    "        # For each node, the initial feature are the sum of the spherical harmonic of the neighbors\n",
    "        node_features = scatter(edge_sh, edge_dst, dim = 0).div(num_neighbors**0.5)\n",
    "        \n",
    "        # For each edge, tensor product the features on the source node with the spherical harmonic\n",
    "        edge_features = self.tp1(node_features[edge_src], edge_sh)\n",
    "        node_features = scatter(edge_features, edge_dst, dim = 0).div(num_neighbors**0.5)\n",
    "        \n",
    "        edge_features = self.tp2(node_features[edge_src], edge_sh)\n",
    "        node_features = scatter(edge_features, edge_dst, dim = 0).div(num_neighbors**0.5)\n",
    "        \n",
    "        \n",
    "        # For each graph, all the node's features are summed\n",
    "        return scatter(node_features, data.batch, dim = 0).div(num_nodes**0.5)\n",
    "    \n",
    "\n",
    "class InvariantPolynomial(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.irreps_sh: o3.Irreps = o3.Irreps.spherical_harmonics(3)\n",
    "        irreps_mid = o3.Irreps(\"64x0e + 24x1e + 24x1o + 16x2e + 16x2o\")\n",
    "        irreps_out = o3.Irreps(\"0o + 6x0e\")\n",
    "\n",
    "        self.tp1 = FullyConnectedTensorProduct(\n",
    "            irreps_in1=self.irreps_sh,\n",
    "            irreps_in2=self.irreps_sh,\n",
    "            irreps_out=irreps_mid,\n",
    "        )\n",
    "        self.tp2 = FullyConnectedTensorProduct(\n",
    "            irreps_in1=irreps_mid,\n",
    "            irreps_in2=self.irreps_sh,\n",
    "            irreps_out=irreps_out,\n",
    "        )\n",
    "        self.irreps_out = self.tp2.irreps_out\n",
    "\n",
    "    def forward(self, data) -> torch.Tensor:\n",
    "        num_neighbors = 2  # typical number of neighbors\n",
    "        num_nodes = 4  # typical number of nodes\n",
    "\n",
    "        edge_src, edge_dst = radius_graph(x=data.pos, r=1.1, batch=data.batch)  # tensors of indices representing the graph\n",
    "        edge_vec = data.pos[edge_src] - data.pos[edge_dst]\n",
    "        edge_sh = o3.spherical_harmonics(\n",
    "            l=self.irreps_sh,\n",
    "            x=edge_vec,\n",
    "            normalize=False,  # here we don't normalize otherwise it would not be a polynomial\n",
    "            normalization=\"component\",\n",
    "        )\n",
    "\n",
    "        # For each node, the initial features are the sum of the spherical harmonics of the neighbors\n",
    "        node_features = scatter(edge_sh, edge_dst, dim=0).div(num_neighbors**0.5)\n",
    "\n",
    "        # For each edge, tensor product the features on the source node with the spherical harmonics\n",
    "        edge_features = self.tp1(node_features[edge_src], edge_sh)\n",
    "        node_features = scatter(edge_features, edge_dst, dim=0).div(num_neighbors**0.5)\n",
    "\n",
    "        edge_features = self.tp2(node_features[edge_src], edge_sh)\n",
    "        node_features = scatter(edge_features, edge_dst, dim=0).div(num_neighbors**0.5)\n",
    "\n",
    "        # For each graph, all the node's features are summed\n",
    "        return scatter(node_features, data.batch, dim=0).div(num_nodes**0.5)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b59c2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 | loss 1013.1     |   0.0% accuracy\n",
      "Epoch    10 | loss 89.2       |   0.0% accuracy\n",
      "Epoch    20 | loss 90.5       |   0.0% accuracy\n",
      "Epoch    30 | loss 26.3       |   0.0% accuracy\n",
      "Epoch    40 | loss 22.8       |   0.0% accuracy\n",
      "Epoch    50 | loss 12.7       |  25.0% accuracy\n",
      "Epoch    60 | loss 10.9       |  12.5% accuracy\n",
      "Epoch    70 | loss 8.4        |  37.5% accuracy\n",
      "Epoch    80 | loss 7.4        |  37.5% accuracy\n",
      "Epoch    90 | loss 6.3        |  50.0% accuracy\n",
      "Epoch   100 | loss 5.6        |  50.0% accuracy\n",
      "Epoch   110 | loss 4.9        |  62.5% accuracy\n",
      "Epoch   120 | loss 4.4        |  62.5% accuracy\n",
      "Epoch   130 | loss 3.9        |  62.5% accuracy\n",
      "Epoch   140 | loss 3.6        |  75.0% accuracy\n",
      "Epoch   150 | loss 3.2        |  75.0% accuracy\n",
      "Epoch   160 | loss 2.9        |  75.0% accuracy\n",
      "Epoch   170 | loss 2.7        |  75.0% accuracy\n",
      "Epoch   180 | loss 2.5        |  75.0% accuracy\n",
      "Epoch   190 | loss 2.3        |  75.0% accuracy\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "data, labels = tetris()\n",
    "\n",
    "f = InveriantPolynomial()\n",
    "\n",
    "optim = torch.optim.Adam(f.parameters(), lr = 1e-2)\n",
    "\n",
    "# == Train ==\n",
    "for step in range(200):\n",
    "    pred = f(data)\n",
    "    loss = (pred - labels).pow(2).sum()\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        accuracy = pred.round().eq(labels).all(dim = 1).double().mean(dim = 0).item()\n",
    "        print(f\"Epoch {step:5d} | loss {loss:<10.1f} | {100 * accuracy:5.1f}% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e2f0c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:e3nn.util.test:Tested equivariance of `wrapper` -- max componentwise errors:\n",
      "(parity_k=0, did_translate=False) -> max error=8.941e-07 in argument 0\n",
      "(parity_k=0, did_translate=True) -> max error=1.490e-06 in argument 0\n",
      "(parity_k=1, did_translate=False) -> max error=6.557e-07 in argument 0\n",
      "(parity_k=1, did_translate=True) -> max error=4.016e-06 in argument 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing equivariance directly...\n",
      "Equivariance error = 1.3e-06\n",
      "Testing equivariance using 'assert equivariance'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(0, False): tensor([8.9407e-07]),\n",
       " (0, True): tensor([1.4901e-06]),\n",
       " (1, False): tensor([6.5565e-07]),\n",
       " (1, True): tensor([4.0159e-06])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "from e3nn.util.test import assert_equivariant\n",
    "# == Check equivariance ==\n",
    "# Because the model outputs (psuedo)scalars, we can easily directly \n",
    "# check its equivariance to the same data with new rotations\n",
    "print(\"Testing equivariance directly...\")\n",
    "rotated_data, _ = tetris()\n",
    "error = f(rotated_data) - f(data)\n",
    "print(f\"Equivariance error = {error.abs().max().item():.1e}\")\n",
    "\n",
    "print(\"Testing equivariance using 'assert equivariance'...\")\n",
    "\n",
    "# To \"interprit\" between assert_equivariance and torch_geometric, we use a small wrapper:\n",
    "def wrapper(pos, batch):\n",
    "    return f(Data(pos = pos, batch = batch))\n",
    "\n",
    "# `assert_equivariant` uses logging to print a summary of the equivariance error,\n",
    "# so we enable logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "assert_equivariant(\n",
    "    wrapper,\n",
    "    # We provide the original data that 'assert_equivariant' will transform...\n",
    "    args_in = [data.pos, data.batch],\n",
    "    # ...in accordance with these irreps...\n",
    "    irreps_in = [\n",
    "        'cartesian_points', # pos has vector 1o irreps, but is also translation equivariant\n",
    "        None, # 'None' indicates invariant, possibly non-floating-point data\n",
    "    ],\n",
    "    # ..and confirm that the outputs transform correspondingly for these irreps:\n",
    "    irreps_out=[f.irreps_out]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d419c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test() -> None:\n",
    "    data, labels = tetris()\n",
    "    f = InveriantPolynomial()\n",
    "    \n",
    "    pred = f(data)\n",
    "    loss = (pred - labels).pow(2).sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    rotated_data, _ = tetris()\n",
    "    error = f(rotated_data) - f(data)\n",
    "    assert error.abs().max() < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff59d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320883e1",
   "metadata": {},
   "source": [
    "### convolution network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ea253d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn import o3\n",
    "from e3nn.nn import FullyConnectedNet, Gate\n",
    "from e3nn.o3 import FullyConnectedTensorProduct\n",
    "from e3nn.math import soft_one_hot_linspace\n",
    "from e3nn.util.test import assert_equivariant\n",
    "\n",
    "def mean_std(name, x) -> None:\n",
    "    print(f\"{name} \\t{x.mean():.1f} +- ({x.var(0).mean().sqrt():.1f}|{x.std():.1f})\")\n",
    "    \n",
    "class Convolution(torch.nn.Module):\n",
    "    def __init__(self, irreps_in, irreps_sh, irreps_out, num_neighbors) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_neighbors = num_neighbors\n",
    "        \n",
    "        tp = FullyConnectedTensorProduct(\n",
    "            irreps_in1=irreps_in,\n",
    "            irreps_in2=irreps_sh,\n",
    "            irreps_out=irreps_out,\n",
    "            internal_weights = False,\n",
    "            shared_weights = False,\n",
    "        )\n",
    "        \n",
    "        self.fc = FullyConnectedNet([3, 256, tp.weight_numel], torch.relu)\n",
    "        self.tp = tp\n",
    "        self.irreps_out = self.tp.irreps_out\n",
    "        \n",
    "    def forward(self, node_features, edge_src, edge_dst, edge_attr, edge_scalars) -> torch.Tensor:\n",
    "        weight = self.fc(edge_scalars)\n",
    "        edge_features = self.tp(node_features[edge_src], edge_attr, weight)\n",
    "        node_features = scatter(edge_features, edge_dst, dim = 0).div(self.num_neighbors**0.5)\n",
    "        return node_features\n",
    "    \n",
    "    \n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.num_neighbors = 3.8 # typical number of neighbors\n",
    "        self.irreps_sh = o3.Irreps.spherical_harmonics(3)\n",
    "        \n",
    "        irreps = self.irreps_sh\n",
    "        \n",
    "        # First layer with gate\n",
    "        gate = Gate(\n",
    "            \"16x0e + 16x0o\",\n",
    "            [torch.relu, torch.abs], # scalar\n",
    "            \"8x0e + 8x0o + 8x0e + 8x0o\",\n",
    "            [torch.relu, torch.tanh, torch.relu, torch.tanh], # gates (scalars)\n",
    "            \"16x1o + 16x1e\", # gates tensors, num_irreps has to matrch with gates\n",
    "        )\n",
    "        \n",
    "        self.conv = Convolution(irreps, self.irreps_sh, gate.irreps_in, self.num_neighbors)\n",
    "        self.gate = gate\n",
    "        irreps = self.gate.irreps_out\n",
    "        \n",
    "        # Final layer\n",
    "        self.final = Convolution(irreps, self.irreps_sh, \"0o + 6x0e\", self.num_neighbors)\n",
    "        self.irreps_out = self.final.irreps_out\n",
    "        \n",
    "        \n",
    "    def forward(self, data) -> torch.Tensor:\n",
    "        num_nodes = 4 # typical number of nodes\n",
    "\n",
    "        edge_src, edge_dst = radius_graph(x=data.pos, r=2.5, batch=data.batch)  # tensors of indices representing the graph\n",
    "        edge_vec = data.pos[edge_src] - data.pos[edge_dst]\n",
    "        edge_attr = o3.spherical_harmonics(\n",
    "            l=self.irreps_sh,\n",
    "            x=edge_vec,\n",
    "            normalize=True,  # here we don't normalize otherwise it would not be a polynomial\n",
    "            normalization=\"component\",\n",
    "        )\n",
    "        edge_length_embedded = (\n",
    "            soft_one_hot_linspace(x = edge_vec.norm(dim = 1), \n",
    "                                  start = 0.5, \n",
    "                                  end = 2.5, \n",
    "                                  number = 3,\n",
    "                                  basis = \"smooth_finite\",\n",
    "                                  cutoff = True\n",
    "                                 ) * 3**0.5\n",
    "        )\n",
    "\n",
    "        x = scatter(edge_attr, edge_dst, dim = 0).div(self.num_neighbors**0.5)\n",
    "\n",
    "        x = self.conv(x, edge_src, edge_dst, edge_attr, edge_length_embedded)\n",
    "        x = self.gate(x)\n",
    "        x = self.final(x, edge_src, edge_dst, edge_attr, edge_length_embedded)\n",
    "\n",
    "        return scatter(x, data.batch, dim = 0).div(num_nodes**0.5)\n",
    "        \n",
    "def main() -> None:\n",
    "    data, labels = tetris()\n",
    "    f = Network()\n",
    "\n",
    "    print(\"Built a model:\")\n",
    "    print(f)\n",
    "\n",
    "    optim = torch.optim.Adam(f.parameters(), lr=1e-3)\n",
    "\n",
    "    # == Training ==\n",
    "    for step in range(200):\n",
    "        pred = f(data)\n",
    "        loss = (pred - labels).pow(2).sum()\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            accuracy = pred.round().eq(labels).all(dim=1).double().mean(dim=0).item()\n",
    "            print(f\"epoch {step:5d} | loss {loss:<10.1f} | {100 * accuracy:5.1f}% accuracy\")\n",
    "\n",
    "    # == Check equivariance ==\n",
    "    # Because the model outputs (psuedo)scalars, we can easily directly\n",
    "    # check its equivariance to the same data with new rotations:\n",
    "    print(\"Testing equivariance directly...\")\n",
    "    rotated_data, _ = tetris()\n",
    "    error = f(rotated_data) - f(data)\n",
    "    print(f\"Equivariance error = {error.abs().max().item():.1e}\")\n",
    "\n",
    "    print(\"Testing equivariance using `assert_equivariance`...\")\n",
    "    # We can also use the library's `assert_equivariant` helper\n",
    "    # `assert_equivariant` also tests parity and translation, and\n",
    "    # can handle non-(psuedo)scalar outputs.\n",
    "    # To \"interpret\" between it and torch_geometric, we use a small wrapper:\n",
    "\n",
    "    def wrapper(pos, batch):\n",
    "        return f(Data(pos=pos, batch=batch))\n",
    "\n",
    "    # `assert_equivariant` uses logging to print a summary of the equivariance error,\n",
    "    # so we enable logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    assert_equivariant(\n",
    "        wrapper,\n",
    "        # We provide the original data that `assert_equivariant` will transform...\n",
    "        args_in=[data.pos, data.batch],\n",
    "        # ...in accordance with these irreps...\n",
    "        irreps_in=[\n",
    "            \"cartesian_points\",  # pos has vector 1o irreps, but is also translation equivariant\n",
    "            None,  # `None` indicates invariant, possibly non-floating-point data\n",
    "        ],\n",
    "        # ...and confirm that the outputs transform correspondingly for these irreps:\n",
    "        irreps_out=[f.irreps_out],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "437d20c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built a model:\n",
      "Network(\n",
      "  (conv): Convolution(\n",
      "    (fc): FullyConnectedNet[3, 256, 272]\n",
      "    (tp): FullyConnectedTensorProduct(1x0e+1x1o+1x2e+1x3o x 1x0e+1x1o+1x2e+1x3o -> 32x0o+32x0e+16x1o+16x1e | 272 paths | 272 weights)\n",
      "  )\n",
      "  (gate): Gate (32x0o+32x0e+16x1o+16x1e -> 16x0e+16x0e+8x1o+8x1e+8x1e+8x1o)\n",
      "  (final): Convolution(\n",
      "    (fc): FullyConnectedNet[3, 256, 304]\n",
      "    (tp): FullyConnectedTensorProduct(32x0e+8x1o+16x1e+8x1o x 1x0e+1x1o+1x2e+1x3o -> 1x0o+6x0e | 304 paths | 304 weights)\n",
      "  )\n",
      ")\n",
      "epoch     0 | loss 200.9      |   0.0% accuracy\n",
      "epoch    10 | loss 36.4       |   0.0% accuracy\n",
      "epoch    20 | loss 12.4       |  37.5% accuracy\n",
      "epoch    30 | loss 6.6        |  50.0% accuracy\n",
      "epoch    40 | loss 4.8        |  50.0% accuracy\n",
      "epoch    50 | loss 3.6        |  62.5% accuracy\n",
      "epoch    60 | loss 2.9        |  75.0% accuracy\n",
      "epoch    70 | loss 2.4        |  75.0% accuracy\n",
      "epoch    80 | loss 2.0        |  75.0% accuracy\n",
      "epoch    90 | loss 1.7        |  87.5% accuracy\n",
      "epoch   100 | loss 1.5        |  87.5% accuracy\n",
      "epoch   110 | loss 1.2        |  87.5% accuracy\n",
      "epoch   120 | loss 1.0        | 100.0% accuracy\n",
      "epoch   130 | loss 0.9        | 100.0% accuracy\n",
      "epoch   140 | loss 0.7        | 100.0% accuracy\n",
      "epoch   150 | loss 0.6        | 100.0% accuracy\n",
      "epoch   160 | loss 0.4        | 100.0% accuracy\n",
      "epoch   170 | loss 0.3        | 100.0% accuracy\n",
      "epoch   180 | loss 0.2        | 100.0% accuracy\n",
      "epoch   190 | loss 0.1        | 100.0% accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:e3nn.util.test:Tested equivariance of `wrapper` -- max componentwise errors:\n",
      "(parity_k=0, did_translate=False) -> max error=8.866e-07 in argument 0\n",
      "(parity_k=0, did_translate=True) -> max error=3.906e-06 in argument 0\n",
      "(parity_k=1, did_translate=False) -> max error=5.737e-07 in argument 0\n",
      "(parity_k=1, did_translate=True) -> max error=1.490e-06 in argument 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing equivariance directly...\n",
      "Equivariance error = 9.4e-07\n",
      "Testing equivariance using `assert_equivariance`...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0effc125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile() -> None:\n",
    "    data, labels = tetris()\n",
    "    data = data.to(device=\"cpu\")\n",
    "    labels = labels.to(device=\"cpu\")\n",
    "\n",
    "    f = Network()\n",
    "    f.to(device=\"cpu\")\n",
    "\n",
    "    optim = torch.optim.Adam(f.parameters(), lr=1e-2)\n",
    "\n",
    "    called_num = [0]\n",
    "\n",
    "    def trace_handler(p) -> None:\n",
    "        print(p.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=-1))\n",
    "        p.export_chrome_trace(\"test_trace_\" + str(called_num[0]) + \".json\")\n",
    "        called_num[0] += 1\n",
    "\n",
    "    with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=50, warmup=1, active=1),\n",
    "        on_trace_ready=trace_handler,\n",
    "    ) as p:\n",
    "        for _ in range(52):\n",
    "            pred = f(data)\n",
    "            loss = (pred - labels).pow(2).sum()\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "afad5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac5cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mkl",
   "language": "python",
   "name": "torch_mkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
